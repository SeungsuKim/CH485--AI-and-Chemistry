{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#from utils import read_ZINC_smiles, smiles_to_onehot, partition, OneHotLogPDataSet\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paser = argparse.ArgumentParser()\n",
    "args = paser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.val_size = 0.15\n",
    "args.test_size = 0.15\n",
    "args.shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12de39fbe30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ZINC_smiles(file_name, num_mol):\n",
    "    f = open(file_name, 'r')\n",
    "    contents = f.readlines()\n",
    "\n",
    "    smi_list = []\n",
    "    logP_list = []\n",
    "\n",
    "    for i in tqdm_notebook(range(num_mol), desc='Reading Data'):\n",
    "        smi = contents[i].strip()\n",
    "        m = Chem.MolFromSmiles(smi)\n",
    "        smi_list.append(smi)\n",
    "        logP_list.append(MolLogP(m))\n",
    "\n",
    "    logP_list = np.asarray(logP_list).astype(float)\n",
    "\n",
    "    return smi_list, logP_list\n",
    "\n",
    "\n",
    "def smiles_to_onehot(smi_list):\n",
    "    def smiles_to_vector(smiles, vocab, max_length):\n",
    "        while len(smiles) < max_length:\n",
    "            smiles += \" \"\n",
    "        vector = [vocab.index(str(x)) for x in smiles]\n",
    "        one_hot = np.zeros((len(vocab), max_length), dtype=int)\n",
    "        for i, elm in enumerate(vector):\n",
    "            one_hot[elm][i] = 1\n",
    "        return one_hot\n",
    "\n",
    "    vocab = np.load('./vocab.npy')\n",
    "    smi_total = []\n",
    "\n",
    "    for i, smi in tqdm_notebook(enumerate(smi_list), desc='Converting to One Hot'):\n",
    "        smi_onehot = smiles_to_vector(smi, list(vocab), 120)\n",
    "        smi_total.append(smi_onehot)\n",
    "\n",
    "    return np.asarray(smi_total)\n",
    "\n",
    "def convert_to_graph(smiles_list):\n",
    "    adj = []\n",
    "    adj_norm = []\n",
    "    features = []\n",
    "    maxNumAtoms = 50\n",
    "    for i in tqdm_notebook(smiles_list, desc='Converting to Graph'):\n",
    "        # Mol\n",
    "        iMol = Chem.MolFromSmiles(i.strip())\n",
    "        #Adj\n",
    "        iAdjTmp = Chem.rdmolops.GetAdjacencyMatrix(iMol)\n",
    "        # Feature\n",
    "        if( iAdjTmp.shape[0] <= maxNumAtoms):\n",
    "            # Feature-preprocessing\n",
    "            iFeature = np.zeros((maxNumAtoms, 58))\n",
    "            iFeatureTmp = []\n",
    "            for atom in iMol.GetAtoms():\n",
    "                iFeatureTmp.append( atom_feature(atom) ) ### atom features only\n",
    "            iFeature[0:len(iFeatureTmp), 0:58] = iFeatureTmp ### 0 padding for feature-set\n",
    "            features.append(iFeature)\n",
    "\n",
    "            # Adj-preprocessing\n",
    "            iAdj = np.zeros((maxNumAtoms, maxNumAtoms))\n",
    "            iAdj[0:len(iFeatureTmp), 0:len(iFeatureTmp)] = iAdjTmp + np.eye(len(iFeatureTmp))\n",
    "            adj.append(np.asarray(iAdj))\n",
    "    features = np.asarray(features)\n",
    "\n",
    "    return features, adj\n",
    "    \n",
    "def atom_feature(atom):\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "                                      ['C', 'N', 'O', 'S', 'F', 'H', 'Si', 'P', 'Cl', 'Br',\n",
    "                                       'Li', 'Na', 'K', 'Mg', 'Ca', 'Fe', 'As', 'Al', 'I', 'B',\n",
    "                                       'V', 'Tl', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
    "                                       'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'Mn', 'Cr', 'Pt', 'Hg', 'Pb']) +\n",
    "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    [atom.GetIsAromatic()])    # (40, 6, 5, 6, 1)\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    #print list((map(lambda s: x == s, allowable_set)))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "class GCNDataset(Dataset):\n",
    "    def __init__(self, list_feature, list_adj, list_logP):\n",
    "        self.list_feature = list_feature\n",
    "        self.list_adj = list_adj\n",
    "        self.list_logP = list_logP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_feature)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.list_feature[index], self.list_adj[index], self.list_logP[index]\n",
    "\n",
    "\n",
    "def partition(list_feature, list_adj, list_logP, args):\n",
    "    num_total = list_feature.shape[0]\n",
    "    num_train = int(num_total * (1 - args.test_size - args.val_size))\n",
    "    num_val = int(num_total * args.val_size)\n",
    "    num_test = int(num_total * args.test_size)\n",
    "\n",
    "    feature_train = list_feature[:num_train]\n",
    "    adj_train = list_adj[:num_train]\n",
    "    logP_train = list_logP[:num_train]\n",
    "    feature_val = list_feature[num_train:num_train + num_val]\n",
    "    adj_val = list_adj[num_train:num_train + num_val]\n",
    "    logP_val = list_logP[num_train:num_train + num_val]\n",
    "    feature_test = list_feature[num_total - num_test:]\n",
    "    adj_test = list_adj[num_train:num_train + num_val]\n",
    "    logP_test = list_logP[num_total - num_test:]\n",
    "\n",
    "    train_set = GCNDataset(feature_train, adj_train, logP_train)\n",
    "    val_set = GCNDataset(feature_val, adj_val, logP_val)\n",
    "    test_set = GCNDataset(feature_test, adj_test, logP_test)\n",
    "\n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312138a71cb341529533c083aa7eebe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading Data', max=2000, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aae9b22c0b647c7a05356b8f0e3738a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting to Graph', max=2000, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_smi, list_logP = read_ZINC_smiles('ZINC.smiles', 2000)\n",
    "list_feature, list_adj = convert_to_graph(list_smi)\n",
    "args.dict_partition = partition(list_feature, list_adj, list_logP, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedSkipConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, new_dim, out_dim, activation):\n",
    "        super(GatedSkipConnection, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.new_dim = new_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.linear_in = nn.Linear(in_dim, out_dim)\n",
    "        self.linear_new = nn.Linear(new_dim, out_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_x, new_x):        \n",
    "        z = self.gate_coefficient(input_x, new_x)\n",
    "        \n",
    "        if (self.in_dim != self.out_dim):\n",
    "            input_x = self.linear_in(input_x)\n",
    "        if (self.new_dim != self.out_dim):\n",
    "            new_x = self.linear_new(new_x)\n",
    "            \n",
    "        out = torch.mul(new_x, z) + torch.mul(input_x, 1.0-z)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def gate_coefficient(self, input_x, new_x):\n",
    "        X1 = self.linear_in(input_x)\n",
    "        X2 = self.linear_new(new_x)\n",
    "        gate_coefficient = self.sigmoid(X1 + X2)\n",
    "        \n",
    "        return gate_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim, activation, sc='no'):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "        self.sc = sc\n",
    "\n",
    "        self.linear = nn.Linear(self.in_dim, \n",
    "                                self.hidden_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.gated_skip_connection = GatedSkipConnection(self.in_dim,\n",
    "                                                         self.hidden_dim,\n",
    "                                                         self.hidden_dim, \n",
    "                                                         self.activation)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        out = self.linear(x)\n",
    "        out = torch.matmul(adj, out)\n",
    "        \n",
    "        if (self.sc == 'gsc'):\n",
    "            out = self.gated_skip_connection(x, out)\n",
    "        elif (self.sc == 'no'):\n",
    "            out = self.activation(out)\n",
    "        else:\n",
    "            out = self.activation(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadOut(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, activation):\n",
    "        super(ReadOut, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim= out_dim\n",
    "        \n",
    "        self.linear = nn.Linear(self.in_dim, \n",
    "                                self.out_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, activation=None):\n",
    "        super(Predictor, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.linear = nn.Linear(self.in_dim,\n",
    "                                self.out_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        if self.activation != None:\n",
    "            out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogPPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_layer, \n",
    "                 in_dim, \n",
    "                 hidden_dim_1, \n",
    "                 hidden_dim_2,\n",
    "                 out_dim,\n",
    "                 sc='no'):\n",
    "        super(LogPPredictor, self).__init__()\n",
    "        \n",
    "        self.n_layer = n_layer\n",
    "        self.graph_convolution_1 = GraphConvolution(in_dim, hidden_dim_1, nn.ReLU(), sc)\n",
    "        self.graph_convolution_2 = GraphConvolution(hidden_dim_1, hidden_dim_1, nn.ReLU(), sc)\n",
    "        self.readout = ReadOut(hidden_dim_1, hidden_dim_2, nn.Sigmoid())\n",
    "        self.predictor_1 = Predictor(hidden_dim_2, hidden_dim_2, nn.ReLU())\n",
    "        self.predictor_2 = Predictor(hidden_dim_2, hidden_dim_2, nn.Tanh())\n",
    "        self.predictor_3 = Predictor(hidden_dim_2, out_dim)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        out = self.graph_convolution_1(x, adj)\n",
    "        for i in range(self.n_layer-1):\n",
    "            out = self.graph_convolution_2(out, adj)\n",
    "        out = self.readout(out)\n",
    "        out = self.predictor_1(out)\n",
    "        out = self.predictor_2(out)\n",
    "        out = self.predictor_3(out)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 10\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.001\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.MSELoss()\n",
    "args.epoch = 10\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6da2b80e844b1fa5602bb6223f73d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_gpu = lambda x=True: torch.set_default_tensor_type(torch.cuda.DoubleTensor if torch.cuda.is_available() and x else torch.FloatTensor)\n",
    "use_gpu()\n",
    "\n",
    "print(args.device)\n",
    "\n",
    "model = LogPPredictor(1, 58, 64, 128, 1, 'gsc')\n",
    "model.to(args.device)\n",
    "\n",
    "list_train_loss = list()\n",
    "list_val_loss = list()\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "optimizer = args.optim(model.parameters(),\n",
    "                       lr=args.lr,\n",
    "                       weight_decay=args.l2_coef)\n",
    "\n",
    "data_train = DataLoader(args.dict_partition['train'], \n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "data_val = DataLoader(args.dict_partition['val'],\n",
    "                     batch_size=args.batch_size,\n",
    "                     shuffle=args.shuffle)\n",
    "\n",
    "for epoch in tqdm_notebook(range(args.epoch), desc='Epoch'):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_feature = torch.tensor(batch[0])\n",
    "        list_adj = torch.tensor(batch[1])\n",
    "        list_logP = torch.tensor(batch[2])\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        list_pred_logP.require_grad = False\n",
    "        train_loss = args.criterion(list_pred_logP, list_logP)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    list_train_loss.append(epoch_train_loss/len(data_train))\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_feature = torch.tensor(batch[0])\n",
    "            list_adj = torch.tensor(batch[1])\n",
    "            list_logP = torch.tensor(batch[2])\n",
    "            list_logP = list_logP.view(-1,1)\n",
    "            list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "\n",
    "\n",
    "            list_pred_logP = model(list_feature, list_adj)\n",
    "            val_loss = args.criterion(list_pred_logP, list_logP)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "        \n",
    "    list_val_loss.append(epoch_val_loss/len(data_val))\n",
    "    \n",
    "data_test = DataLoader(args.dict_partition['test'],\n",
    "                       batch_size=args.batch_size,\n",
    "                       shuffle=args.shuffle)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logP_total = list()\n",
    "    pred_logP_total = list()\n",
    "    for i, batch in enumerate(data_val):\n",
    "        list_feature = torch.tensor(batch[0])\n",
    "        list_adj = torch.tensor(batch[1])\n",
    "        list_logP = torch.tensor(batch[2])\n",
    "        logP_total += list_logP.tolist()\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "\n",
    "        \n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        \n",
    "        pred_logP_total += list_pred_logP.tolist()\n",
    "    \n",
    "    mse = mean_squared_error(logP_total, pred_logP_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 10\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.001\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.MSELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogPPredictor(1, 58, 64, 128, 1, 'no')\n",
    "model.to(args.device)\n",
    "\n",
    "list_train_loss = list()\n",
    "list_val_loss = list()\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "optimizer = args.optim(model.parameters(),\n",
    "                       lr=args.lr,\n",
    "                       weight_decay=args.l2_coef)\n",
    "\n",
    "data_train = DataLoader(args.dict_partition['train'], \n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "data_val = DataLoader(args.dict_partition['val'],\n",
    "                     batch_size=args.batch_size,\n",
    "                     shuffle=args.shuffle)\n",
    "\n",
    "for epoch in tqdm_notebook(range(args.epoch), desc='Epoch'):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_feature = torch.tensor(batch[0],\n",
    "                                    dtype=torch.float,\n",
    "                                    device=args.device)\n",
    "        list_adj = torch.tensor(batch[1],\n",
    "                                dtype=torch.float,\n",
    "                                device=args.device)\n",
    "        list_logP = torch.tensor(batch[2],\n",
    "                                 dtype=torch.float,\n",
    "                                 device=args.device)\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        list_pred_logP.require_grad = False\n",
    "        train_loss = args.criterion(list_pred_logP, list_logP)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    list_train_loss.append(epoch_train_loss/len(data_train))\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_feature = torch.tensor(batch[0],\n",
    "                                        dtype=torch.float,\n",
    "                                        device=args.device)\n",
    "            list_adj = torch.tensor(batch[1],\n",
    "                                    dtype=torch.float,\n",
    "                                    device=args.device)\n",
    "            list_logP = torch.tensor(batch[2],\n",
    "                                     dtype=torch.float,\n",
    "                                     device=args.device)\n",
    "            list_logP = list_logP.view(-1,1)\n",
    "\n",
    "            list_pred_logP = model(list_feature, list_adj)\n",
    "            val_loss = args.criterion(list_pred_logP, list_logP)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "        \n",
    "    list_val_loss.append(epoch_val_loss/len(data_val))\n",
    "    \n",
    "data_test = DataLoader(args.dict_partition['test'],\n",
    "                       batch_size=args.batch_size,\n",
    "                       shuffle=args.shuffle)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logP_total = list()\n",
    "    pred_logP_total = list()\n",
    "    for i, batch in enumerate(data_val):\n",
    "        list_feature = torch.tensor(batch[0],\n",
    "                                    dtype=torch.float,\n",
    "                                    device=args.device)\n",
    "        list_adj = torch.tensor(batch[1],\n",
    "                                dtype=torch.float,\n",
    "                                device=args.device)\n",
    "        list_logP = torch.tensor(batch[2],\n",
    "                                 dtype=torch.float,\n",
    "                                 device=args.device)\n",
    "        logP_total += list_logP.tolist()\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        \n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        \n",
    "        pred_logP_total += list_pred_logP.tolist()\n",
    "    \n",
    "    mse = mean_squared_error(logP_total, pred_logP_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(10), desc='1', leave=True, position=1):\n",
    "    for j in tqdm_notebook(range(100), desc='2', leave=False, position=2):\n",
    "        sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
