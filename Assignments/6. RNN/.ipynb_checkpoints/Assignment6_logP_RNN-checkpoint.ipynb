{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.val_size = 0.1\n",
    "args.test_size = 0.1\n",
    "args.shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f451d3a4230>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ZINC_smiles(file_name, num_mol):\n",
    "    f = open(file_name, 'r')\n",
    "    contents = f.readlines()\n",
    "\n",
    "    smi_list = []\n",
    "    logP_list = []\n",
    "\n",
    "    for i in tqdm_notebook(range(num_mol), desc='Reading Data'):\n",
    "        smi = contents[i].strip()\n",
    "        m = Chem.MolFromSmiles(smi)\n",
    "        smi_list.append(smi)\n",
    "        logP_list.append(MolLogP(m))\n",
    "\n",
    "    logP_list = np.asarray(logP_list).astype(float)\n",
    "\n",
    "    return smi_list, logP_list\n",
    "\n",
    "def smiles_to_onehot(list_smiles):\n",
    "    def smiles_to_vector(smiles, vocab, max_length):\n",
    "        while len(smiles) < max_length:\n",
    "            smiles += \" \"\n",
    "        vector = [vocab.index(str(x)) for x in smiles]\n",
    "        onehot = np.zeros((max_length, len(vocab)), dtype=float)\n",
    "        for i, elm in enumerate(vector):\n",
    "            onehot[i][elm] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    vocab = np.load('./vocab.npy')\n",
    "    onehot_total = list()\n",
    "    length_total = list()\n",
    "    for smiles in tqdm_notebook(list_smiles, desc='Converting Data'):\n",
    "        onehot = smiles_to_vector(smiles, list(vocab), 120)\n",
    "        onehot_total.append(onehot)\n",
    "        length_total.append(len(smiles))\n",
    "    \n",
    "    return np.asarray(onehot_total), np.asarray(length_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, list_smiles, list_length, list_logP):\n",
    "        self.list_smiles = list_smiles\n",
    "        self.list_length = list_length\n",
    "        self.list_logP = list_logP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_smiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.list_smiles[index], self.list_length[index], self.list_logP[index]\n",
    "    \n",
    "\n",
    "def partition(list_onehot, list_length, list_logP, args):\n",
    "    num_total = list_onehot.shape[0]\n",
    "    num_val = int(num_total * args.val_size)\n",
    "    num_test = int(num_total * args.test_size)\n",
    "    num_train = num_total - (num_val + num_test)\n",
    "\n",
    "    onehot_train = list_onehot[:num_train]\n",
    "    length_train = list_length[:num_train]\n",
    "    logP_trian = list_logP[:num_train]\n",
    "\n",
    "    onehot_val = list_onehot[num_train:num_train+num_val]\n",
    "    length_val = list_length[num_train:num_train+num_val]\n",
    "    logP_val = list_logP[num_train:num_train+num_val]\n",
    "\n",
    "    onehot_test = list_onehot[num_total-num_test:]\n",
    "    length_test = list_length[num_total-num_test:]\n",
    "    logP_test = list_logP[num_total-num_test:]\n",
    "\n",
    "    train_set = RNNDataset(onehot_train, length_train, logP_trian)\n",
    "    val_set = RNNDataset(onehot_val, length_val, logP_val)\n",
    "    test_set = RNNDataset(onehot_test, length_test, logP_test)\n",
    "\n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227dfbd23a8542c8b7b6584692f70307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading Data', max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc0ea849c434abeac00981927f626fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting Data', max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_smiles, list_logP = read_ZINC_smiles(\"ZINC.smiles\", 10000)\n",
    "list_onehot, list_length = smiles_to_onehot(list_smiles)\n",
    "dict_partition = partition(list_onehot, list_length, list_logP, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, num_layer=1, dropout=0):\n",
    "        super(RNNBlock, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layer = num_layer\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hidden_dim, num_layer, dropout)\n",
    "\n",
    "    def forward(self, onehot, length):\n",
    "        batch_size = onehot.shape[0]\n",
    "        \n",
    "        h_in = nn.Parameter(torch.randn(self.num_layer, batch_size, self.hidden_dim))\n",
    "        c_in = nn.Parameter(torch.randn(self.num_layer, batch_size, self.hidden_dim))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(onehot, length, batch_first=True)\n",
    "        \n",
    "        output, (h_out, c_out) = self.lstm(packed, (h_in, c_in))\n",
    "        unpacked, unpacked_length = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        vectors = list()\n",
    "        for i, vector in enumerate(unpacked):\n",
    "            vectors.append(unpacked[i, unpacked_length[i]-1, :].view(1, -1))\n",
    "        out = nn.Parameter(torch.cat(vectors, 0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, act=None):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        nn.init.xavier_normal_(self.linear.weight)\n",
    "        self.activation = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        if self.activation != None:\n",
    "            out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(RNNNet, self).__init__()\n",
    "\n",
    "        self.rnnBlock = RNNBlock(args.in_dim, args.hidden_dim, args.num_layer, args.dropout)\n",
    "        self.pred1 = Predictor(args.hidden_dim, args.pred_dim1, act=nn.ReLU())\n",
    "        self.pred2 = Predictor(args.pred_dim1, args.pred_dim2, act=nn.ReLU())\n",
    "        self.pred3 = Predictor(args.pred_dim2, args.out_dim)\n",
    "\n",
    "    def forward(self, onehot, length):\n",
    "        out = self.rnnBlock(onehot, length)\n",
    "        out = self.pred1(out)\n",
    "        out = self.pred2(out)\n",
    "        out = self.pred3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train, Validate, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, optimizer, criterion, data_train, bar, args):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_mae = 0\n",
    "\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_onehot = torch.tensor(batch[0]).cuda().float()\n",
    "        list_length = torch.tensor(batch[1]).cuda()\n",
    "        list_logP = torch.tensor(batch[2]).cuda().float()\n",
    "        # Sort onehot tensor with respect to the sequence length.\n",
    "        list_length, list_index = torch.sort(list_length, descending=True)\n",
    "        list_length.cuda()\n",
    "        list_index.cuda()\n",
    "        list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).cuda().float()\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        list_pred_logP = model(list_onehot, list_length).squeeze().cuda()\n",
    "        list_pred_logP.require_grad = False\n",
    "\n",
    "        train_loss = criterion(list_pred_logP, list_logP)\n",
    "        train_mae = mean_absolute_error(list_pred_logP.tolist(), list_logP.tolist())\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        epoch_train_mae += train_mae\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bar.update(len(list_onehot))\n",
    "\n",
    "    epoch_train_loss /= len(data_train)\n",
    "    epoch_train_mae /= len(data_train)\n",
    "\n",
    "    return model, epoch_train_loss, epoch_train_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, criterion, data_val, bar, args):\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_onehot = torch.tensor(batch[0]).cuda().float()\n",
    "            list_length = torch.tensor(batch[1]).cuda()\n",
    "            list_logP = torch.tensor(batch[2]).cuda().float()\n",
    "\n",
    "            # Sort onehot tensor with respect to the sequence length.\n",
    "            list_length, list_index = torch.sort(list_length, descending=True)\n",
    "            list_length.cuda()\n",
    "            list_index.cuda()\n",
    "            list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).cuda().float()\n",
    "\n",
    "            model.eval()\n",
    "            list_pred_logP = model(list_onehot, list_length).squeeze().cuda()\n",
    "            list_pred_logP.require_grad = False\n",
    "\n",
    "            val_loss = criterion(list_pred_logP, list_logP)\n",
    "            val_mae = mean_absolute_error(list_pred_logP.tolist(), list_logP.tolist())\n",
    "            epoch_val_loss += val_loss.item()\n",
    "            epoch_val_mae += val_mae\n",
    "\n",
    "            bar.update(len(list_onehot))\n",
    "\n",
    "    epoch_val_loss /= len(data_val)\n",
    "    epoch_val_mae /= len(data_val)\n",
    "    \n",
    "    return model, epoch_val_loss, epoch_val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, data_test, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_logP_total = list()\n",
    "        logP_total = list()\n",
    "        for i, batch in enumerate(data_test):\n",
    "            list_onehot = torch.tensor(batch[0]).cuda().float()\n",
    "            list_length = torch.tensor(batch[1]).cuda()\n",
    "            list_logP = torch.tensor(batch[2]).cuda().float()\n",
    "\n",
    "            # Sort onehot tensor with respect to the sequence length.\n",
    "            list_length, list_index = torch.sort(list_length, descending=True)\n",
    "            list_length.cuda()\n",
    "            list_index.cuda()\n",
    "            list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).cuda().float()\n",
    "\n",
    "            list_pred_logP = model(list_onehot, list_length).squeeze().cuda()\n",
    "\n",
    "            pred_logP_total += list_pred_logP.tolist()\n",
    "            logP_total += list_logP.tolist()\n",
    "\n",
    "        mae = mean_absolute_error(logP_total, pred_logP_total)\n",
    "        std = np.std(np.array(logP_total) - np.array(pred_logP_total))\n",
    "\n",
    "    return mae, std, logP_total, pred_logP_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dict_partition, device, bar, args):\n",
    "    time_start = time.time()\n",
    "\n",
    "    model = RNNNet(args)\n",
    "    model.cuda()\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, 'Undefined Optimizer Type'\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "    list_train_mae = list()\n",
    "    list_val_mae = list()\n",
    "\n",
    "    data_train = DataLoader(dict_partition['train'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "    data_val = DataLoader(dict_partition['val'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        scheduler.step()\n",
    "        \n",
    "        model, train_loss, train_mae = train(model, device, optimizer, criterion, data_train, bar, args)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_train_mae.append(train_mae)\n",
    "\n",
    "        mode, val_loss, val_mae = validate(model, device, criterion, data_val, bar, args)\n",
    "        list_val_loss.append(val_loss)\n",
    "        list_val_mae.append(val_mae)\n",
    "\n",
    "    data_test = DataLoader(dict_partition['test'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    mae, std, logP_total, pred_logP_total = test(model, device, data_test, args)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_required = time_end - time_start\n",
    "\n",
    "    args.list_train_loss = list_train_loss\n",
    "    args.list_val_loss = list_val_loss\n",
    "    args.list_train_mae = list_train_mae\n",
    "    args.list_val_mae = list_val_mae\n",
    "    args.logP_total = logP_total\n",
    "    args.pred_logP_total = pred_logP_total\n",
    "    args.mae = mae\n",
    "    args.std = std\n",
    "    args.time_required = time_required\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(df_result, var1, var2):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    df_mae = df_result.pivot(var1, var2, 'mae')\n",
    "    df_std = df_result.pivot(var1, var2, 'std')\n",
    "    df_mae = df_mae[df_mae.columns].astype(float)\n",
    "    df_std = df_std[df_std.columns].astype(float)\n",
    "    \n",
    "    hm_mae = sns.heatmap(df_mae, ax=ax[0], annot=True, fmt='f', linewidths=.5, cmap='YlGnBu')\n",
    "    hm_std = sns.heatmap(df_std, ax=ax[1], annot=True, fmt='f', linewidths=.5, cmap='YlGnBu')\n",
    "    \n",
    "    fig.suptitle('Performance depends on ' + var1 + ' vs ' + var2)\n",
    "    hm_mae.set_title('MAE depends on ' + var1 + ' vs ' + var2)\n",
    "    hm_std.set_title('Std depends on ' + var1 + ' vs ' + var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_bar(df_result, var1, var2):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    bar_mae = sns.barplot(x=var1, y='mae', hue=var2, data=df_result, ax=ax[0])\n",
    "    bar_std = sns.barplot(x=var1, y='std', hue=var2, data=df_result, ax=ax[1])\n",
    "    \n",
    "    bar_mae.set_title('MAE depends on ' + var1 + ' vs ' + var2)\n",
    "    bar_std.set_title('Std depends on ' + var1 + ' vs ' + var2)\n",
    "    fig.suptitle('Performance depends on ' + var1 + ' vs ' + var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(df_result, var1, var2, ylim):\n",
    "    def plot(x, ylim=1.0, **kwargs):\n",
    "        plt.plot(x[0], **kwargs)\n",
    "        plt.ylim(0.0, ylim)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\n",
    "    g.map(plot, 'list_train_loss', ylim=ylim, label='Train Loss')\n",
    "    g.map(plot, 'list_val_loss', ylim=ylim, color='r', label='Validation Loss')\n",
    "    g.fig.suptitle('Loss vs Epochs depends on ' + var1 + ' vs ' + var2, size=16)\n",
    "    g.fig.subplots_adjust(top=.9)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df_result, var1, var2):\n",
    "    def scatter(x, y, **kwargs):\n",
    "        plt.scatter(x[0], y[0], alpha=0.3, s=2)\n",
    "    def identity(x, y, **kwargs):\n",
    "        plt.plot(x[0], x[0], alpha=0.4, color='black')\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\n",
    "    g.map(scatter, 'logP_total', 'pred_logP_total')\n",
    "    g.map(identity, 'logP_total', 'logP_total')\n",
    "    g.fig.suptitle('Truth Distribution depends on ' + var1 + ' vs ' + var2, size=16)\n",
    "    g.fig.subplots_adjust(top=.9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0\n",
    "args.optim = 'Adam'\n",
    "args.epoch = 5\n",
    "args.num_layer = 1\n",
    "args.dropout = 0\n",
    "args.in_dim = 32\n",
    "args.hidden_dim = 64\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.out_dim = 1\n",
    "args.step_size = 10\n",
    "args.gamma = 1\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a38bd693cc41829e7858d300397201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_result = dict()\n",
    "n_iter = args.epoch*(len(dict_partition['train'])+len(dict_partition['val']))\n",
    "bar = tqdm_notebook(total=n_iter, file=sys.stdout, position=0)\n",
    "\n",
    "args.exp_name = \"test\"\n",
    "result = vars(experiment(dict_partition, device, bar, args))\n",
    "dict_result[args.exp_name] = copy.deepcopy(result)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bar.close()\n",
    "\n",
    "df_result = pd.DataFrame(dict_result).transpose()\n",
    "df_result.to_json('test.JSON', orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.0244891264\n",
      "Std: 1.3048248907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44df573ac8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = pd.read_json('test.JSON', orient='table')\n",
    "\n",
    "print(\"MAE: \" + str(df_result['mae'][0]))\n",
    "print(\"Std: \" + str(df_result['std'][0]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 5)\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "ax[0].plot(df_result['list_train_loss'][0], label='Train Loss')\n",
    "ax[0].plot(df_result['list_val_loss'][0], label='Validation Loss')\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].legend()\n",
    "ax[1].scatter(df_result['logP_total'][0], df_result['pred_logP_total'][0], alpha=0.3, s=2)\n",
    "ax[1].plot(df_result['logP_total'][0], df_result['logP_total'][0], color='black', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test    [1.6958310008000002]\n",
       "Name: list_val_loss, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['list_val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'c', 'C', '(', ')', 'O', '1', '2', 'N', '=', '[', ']', '@', '3', 'H', 'n', '4', 'F', '+', 'S', 'l', 's', '/', 'o', '-', '5', '#', 'B', 'r', '\\\\', '6', 'I']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(np.load('./vocab.npy'))\n",
    "smiles = \"C(=O)Cl\"\n",
    "smiles_onehot = [vocab.index(str(x)) for x in smiles]\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "[22 20 23 26 30 24 33 33 24 29 21 22 22 24 37 30 27 34 37 41 33 30 28 27\n",
      " 32 26 30 28 26 26 28 32 26 25 29 37 21 24 21 26 36 33 30 29 33 23 31 29\n",
      " 34 35 40 25 29 34 26 32 17 25 25 30 17 38 27 26 31 36 37 27 30 27 33 31\n",
      " 27 12 17 30 22 27 24 31 25 37 29 31 32 27 29 27 15 35 11 36 32 28 35 28\n",
      " 29 29 20 31 31 30 31 28 31 26 29 28 27 17 23 16 24 34 30 32 27 28 17 30\n",
      " 25 32 26 26 24 19 25 31 25 24 34 25 30 19 27 30 27 27 24 31 25 22 31 31\n",
      " 31 31 23 37 27 26 25 30 21 24 29 33 38 20 33 24 33 22 26 28 25 28 31 26\n",
      " 23 32 21 34 35 30 19 35 31 30 35 36 29 30 21 33 36 28 28 30 29 26 29 22\n",
      " 21 19 23 36 33 33 27 24 33 26 30 32 31 35 38 25 25 25 22 32 14 27 26 31\n",
      " 36 32 31 33 32 35 28 22 25 26 33 14 30 15 14 22 28 27 32 31 31 27 24 28\n",
      " 26 26 22 16 29 28 28 31 35 34 24 29 29 21 35 36 24 27 23 20 22 16 21 26\n",
      " 24 30 30 35 33 33 27 28 21 25 32 28 26 25 31 27 28 29 19 26 25 37 24 32\n",
      " 23 24 31 31 26 18 25 28 29 29 32 30 22 26 31 30 30 29 35 36 29 26 30 22\n",
      " 25 24 25 28 27 37 28 28 33 34 30 27 23 36 24 27 25 34 18 24 31 29 30 23\n",
      " 26 34 29 30 32 27 22 23 23 24 36 33 30 27 29 30 30 31 31 27 32 35 38 25\n",
      " 29 23 25 31 27 17 22 26 16 30 30 31 36 34 27 25 26 25 26 30 15 22 22 26\n",
      " 28 30 22 27 37 23 28 27 30 25 29 27 29 25 35 29 27 28 28 21 24 31 29 36\n",
      " 19 29 20 19 28 28 27 21 31 20 16 24 33 34 25 27 33 27 27 26 28 34 34 32\n",
      " 31 27 26 25 27 19 31 27 24 30 25 28 22 16 23 31 28 28 31 32 32 29 22 27\n",
      " 30 22 31 30 24 35 25 27 26 29 22 31 28 28 26 29 30 21 31 24 27 35 29 35\n",
      " 39 27 29 27 22 23 22 21 32 23 29 33 26 31 33 46 35 29 33 22 26 30 34 33\n",
      " 35 31 27 35 20 21 16 29 12 31 21 16 31 31 23 29 26 34 31 31 32 24 22 18\n",
      " 35 17 37 26 33 20 26 28 33 24 36 23 22 30 23 24 21 16 24 24 24 30 30 34\n",
      " 31 30 32 31 27 28 33 29 25 28 27 30 31 31 27 32 30 31 29 28 34 37 37 29\n",
      " 31 33 27 27 17 28 30 21 30 35 23 29 26 27 25 21 22 20 31 28 28 32 22 21\n",
      " 39 35 37 27 32 35 31 33 30 23 28 24 26 31 36 23 23 36 31 28 33 25 28 25\n",
      " 22 19 21 24 23 30 27 24 27 29 33 31 31 27 35 25 24 25 34 18 21 22 30 27\n",
      " 26 34 33 35 24 31 26 20 25 25 22 25 27 15 23 15 19 29 31 26 25 29 30 22\n",
      " 30 19 18 21 27 23 24 29 36 25 17 30 31 23 21 26 28 32 32 25 36 35 22 27\n",
      " 23 27 27 27 29 20 24 25 33 28 24 29 31 24 28 23 34 30 28 26 28 29 22 29\n",
      " 19 27 19 30 28 26 24 30 23 31 29 28 31 28 35 22 19 28 31 24 27 30 36 31\n",
      " 24 26 30 31 30 24 35 36 27 29 22 17 19 25 31 27 34 26 34 27 27 35 25 32\n",
      " 25 29 23 23 33 34 27 26 32 23 21 24 24 27 32 34 29 32 33 26 30 35 31 27\n",
      " 31 32 35 40 27 29 28 25 21 26 26 34 41 32 33 26 20 25 17 28 23 22 30 31\n",
      " 23 14 26 29 25 24 32 22 31 37 22 27 28 26 20 28 26 15 23 32 30 22 25 22\n",
      " 31 29 29 32 21 35 33 27 23 31 30 31 20 30 29 29 31 28 31 26 29 26 21 23\n",
      " 28 22 18 30 27 26 26 23 34 28 33 26 29 29 23 31 30 17 27 27 26 22 21 24\n",
      " 29 25 24 31 22 34 33 30 28 24 33 23 28 27 24 28 28 25 24 20 25 30 36 31\n",
      " 34 28 15 27 32 24 14 27 24 31 33 29 29 26 23 30 28 27 33 19 25 23 25 34\n",
      " 29 33 30 26 30 31 15 35 40 25 25 29 29 31 26 20 24 21 30 26 33 34 41 26\n",
      " 32 24 27 31 22 20 27 32 26 31 22 26 26 30 29 22 30 29 33 35 26 30 22 23\n",
      " 23 37 26 31 28 32 30 41 22 23 30 17 28 29 30 25]\n"
     ]
    }
   ],
   "source": [
    "print(list_onehot[1])\n",
    "print(list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22., 20., 23., 26., 30.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " tensor([30., 26., 23., 22., 20.]),\n",
       " tensor([4, 3, 2, 0, 1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_onehot = torch.Tensor(list_onehot[:5])\n",
    "tensor_length = torch.Tensor(list_length[:5])\n",
    "print(tensor_length)\n",
    "tensor_length, tensor_index = torch.sort(tensor_length, descending=True)\n",
    "tensor_onehot, tensor_length, tensor_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor_onehot = tensor_onehot.tolist()\n",
    "tensor_onehot = torch.Tensor([tensor_onehot.tolist()[i] for i in tensor_index])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(2, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.Tensor([[[1, 2], [2, 3], [3, 4], [4, 5]]])\n",
    "lstm(input1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.Tensor([[[1], [2], [3], [4], [5]]])\n",
    "\n",
    "lstm(input2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.in_dim = 32\n",
    "args.hidden_dim = 64\n",
    "args.out_dim = 1\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.num_layer = 2\n",
    "args.dropout = 0\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNNet(args)\n",
    "model.cuda()\n",
    "\n",
    "data_train = DataLoader(dict_partition['train'],\n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "for i, batch in enumerate(data_train):\n",
    "    if i==0:\n",
    "        list_onehot = torch.tensor(batch[0]).cuda()\n",
    "        list_length = torch.tensor(batch[1]).cuda()\n",
    "        list_logP = torch.tensor(batch[2]).cuda().view(-1, 1).float()\n",
    "        \n",
    "        # Sort onehot tensor with respect to the sequence length.\n",
    "        list_length, list_index = torch.sort(list_length, descending=True)\n",
    "        list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index])\n",
    "\n",
    "        list_pred_logP = model(list_onehot, list_length).to(device)\n",
    "        list_pred_logP.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_logP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0005, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "mse(list_pred_logP, list_logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0005, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_logP = list_pred_logP.squeeze()\n",
    "list_logP = list_logP.squeeze()\n",
    "mse(list_pred_logP, list_logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3664387083612617"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.array(list_pred_logP.tolist())-np.array(list_logP.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4918543050880544"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.array(list_pred_logP.tolist()), np.array(list_logP.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
