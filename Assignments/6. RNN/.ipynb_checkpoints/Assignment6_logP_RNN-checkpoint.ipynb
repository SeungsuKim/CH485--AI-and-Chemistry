{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.val_size = 0.1\n",
    "args.test_size = 0.1\n",
    "args.shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7feb3fad90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ZINC_smiles(file_name, num_mol):\n",
    "    f = open(file_name, 'r')\n",
    "    contents = f.readlines()\n",
    "\n",
    "    smi_list = []\n",
    "    logP_list = []\n",
    "\n",
    "    for i in tqdm_notebook(range(num_mol), desc='Reading Data'):\n",
    "        smi = contents[i].strip()\n",
    "        m = Chem.MolFromSmiles(smi)\n",
    "        smi_list.append(smi)\n",
    "        logP_list.append(MolLogP(m))\n",
    "\n",
    "    logP_list = np.asarray(logP_list).astype(float)\n",
    "\n",
    "    return smi_list, logP_list\n",
    "\n",
    "def smiles_to_onehot(list_smiles):\n",
    "    def smiles_to_vector(smiles, vocab, max_length):\n",
    "        while len(smiles) < max_length:\n",
    "            smiles += \" \"\n",
    "        vector = [vocab.index(str(x)) for x in smiles]\n",
    "        onehot = np.zeros((max_length, len(vocab)), dtype=float)\n",
    "        for i, elm in enumerate(vector):\n",
    "            onehot[i][elm] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    vocab = np.load('./vocab.npy')\n",
    "    onehot_total = list()\n",
    "    length_total = list()\n",
    "    for smiles in tqdm_notebook(list_smiles, desc='Converting Data'):\n",
    "        onehot = smiles_to_vector(smiles, list(vocab), 120)\n",
    "        onehot_total.append(onehot)\n",
    "        length_total.append(len(smiles))\n",
    "    \n",
    "    return np.asarray(onehot_total), np.asarray(length_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, list_smiles, list_length, list_logP):\n",
    "        self.list_smiles = list_smiles\n",
    "        self.list_length = list_length\n",
    "        self.list_logP = list_logP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_smiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.list_smiles[index], self.list_length[index], self.list_logP[index]\n",
    "    \n",
    "\n",
    "def partition(list_onehot, list_length, list_logP, args):\n",
    "    num_total = list_onehot.shape[0]\n",
    "    num_val = int(num_total * args.val_size)\n",
    "    num_test = int(num_total * args.test_size)\n",
    "    num_train = num_total - (num_val + num_test)\n",
    "\n",
    "    onehot_train = list_onehot[:num_train]\n",
    "    length_train = list_length[:num_train]\n",
    "    logP_trian = list_logP[:num_train]\n",
    "\n",
    "    onehot_val = list_onehot[num_train:num_train+num_val]\n",
    "    length_val = list_length[num_train:num_train+num_val]\n",
    "    logP_val = list_logP[num_train:num_train+num_val]\n",
    "\n",
    "    onehot_test = list_onehot[num_total-num_test:]\n",
    "    length_test = list_length[num_total-num_test:]\n",
    "    logP_test = list_logP[num_total-num_test:]\n",
    "\n",
    "    train_set = RNNDataset(onehot_train, length_train, logP_trian)\n",
    "    val_set = RNNDataset(onehot_val, length_val, logP_val)\n",
    "    test_set = RNNDataset(onehot_test, length_test, logP_test)\n",
    "\n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0865dbc957a44951a6ed1277cdce482f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading Data', max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726ef204e7464e04aab9d33f335c9d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting Data', max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_smiles, list_logP = read_ZINC_smiles(\"ZINC.smiles\", 50000)\n",
    "list_onehot, list_length = smiles_to_onehot(list_smiles)\n",
    "dict_partition = partition(list_onehot, list_length, list_logP, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, num_layer=1, dropout=0):\n",
    "        super(RNNBlock, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layer = num_layer\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hidden_dim, num_layer, dropout)\n",
    "\n",
    "    def forward(self, onehot, length):\n",
    "        batch_size = onehot.shape[0]\n",
    "        \n",
    "        h_in = autograd.Variable(torch.randn(self.num_layer, batch_size, self.hidden_dim).cuda())\n",
    "        c_in = autograd.Variable(torch.randn(self.num_layer, batch_size, self.hidden_dim).cuda())\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(onehot, length, batch_first=True).cuda()\n",
    "        \n",
    "        output, _ = self.lstm(packed)\n",
    "        unpacked, unpacked_length = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        vectors = list()\n",
    "        for i, vector in enumerate(unpacked):\n",
    "            vectors.append(unpacked[i, unpacked_length[i]-1, :].view(1, -1))\n",
    "        out = torch.cat(vectors, 0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, act=None):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        nn.init.xavier_normal_(self.linear.weight)\n",
    "        self.activation = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        if self.activation != None:\n",
    "            out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(RNNNet, self).__init__()\n",
    "\n",
    "        self.rnnBlock = RNNBlock(args.in_dim, args.hidden_dim, args.num_layer, args.dropout)\n",
    "        self.pred1 = Predictor(args.hidden_dim, args.pred_dim1, act=nn.ReLU())\n",
    "        self.pred2 = Predictor(args.pred_dim1, args.pred_dim2, act=nn.ReLU())\n",
    "        self.pred3 = Predictor(args.pred_dim2, args.out_dim)\n",
    "\n",
    "    def forward(self, onehot, length):\n",
    "        out = self.rnnBlock(onehot, length)\n",
    "        out = self.pred1(out)\n",
    "        out = self.pred2(out)\n",
    "        out = self.pred3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train, Validate, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, optimizer, criterion, data_train, bar, args):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_mae = 0\n",
    "\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_onehot = torch.tensor(batch[0]).to(device).float()\n",
    "        list_length = torch.tensor(batch[1]).to(device)\n",
    "        list_logP = torch.tensor(batch[2]).to(device).float()\n",
    "        # Sort onehot tensor with respect to the sequence length.\n",
    "        list_length, list_index = torch.sort(list_length, descending=True)\n",
    "        list_length.to(device)\n",
    "        list_index.to(device)\n",
    "        list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).to(device).float()\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        list_pred_logP = model(list_onehot, list_length).squeeze().to(device)\n",
    "        list_pred_logP.require_grad = False\n",
    "\n",
    "        train_loss = criterion(list_pred_logP, list_logP)\n",
    "        train_mae = mean_absolute_error(list_pred_logP.tolist(), list_logP.tolist())\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        epoch_train_mae += train_mae\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bar.update(len(list_onehot))\n",
    "\n",
    "    epoch_train_loss /= len(data_train)\n",
    "    epoch_train_mae /= len(data_train)\n",
    "\n",
    "    return model, epoch_train_loss, epoch_train_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, criterion, data_val, bar, args):\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_onehot = torch.tensor(batch[0]).to(device).float()\n",
    "            list_length = torch.tensor(batch[1]).to(device)\n",
    "            list_logP = torch.tensor(batch[2]).to(device).float()\n",
    "\n",
    "            # Sort onehot tensor with respect to the sequence length.\n",
    "            list_length, list_index = torch.sort(list_length, descending=True)\n",
    "            list_length.to(device)\n",
    "            list_index.to(device)\n",
    "            list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).to(device).float()\n",
    "\n",
    "            model.eval()\n",
    "            list_pred_logP = model(list_onehot, list_length).squeeze().to(device)\n",
    "            list_pred_logP.require_grad = False\n",
    "\n",
    "            val_loss = criterion(list_pred_logP, list_logP)\n",
    "            val_mae = mean_absolute_error(list_pred_logP.tolist(), list_logP.tolist())\n",
    "            epoch_val_loss += val_loss.item()\n",
    "            epoch_val_mae += val_mae\n",
    "\n",
    "            bar.update(len(list_onehot))\n",
    "\n",
    "    epoch_val_loss /= len(data_val)\n",
    "    epoch_val_mae /= len(data_val)\n",
    "    \n",
    "    return model, epoch_val_loss, epoch_val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, data_test, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_logP_total = list()\n",
    "        logP_total = list()\n",
    "        for i, batch in enumerate(data_test):\n",
    "            list_onehot = torch.tensor(batch[0]).to(device).float()\n",
    "            list_length = torch.tensor(batch[1]).to(device)\n",
    "            list_logP = torch.tensor(batch[2]).to(device).float()\n",
    "\n",
    "            # Sort onehot tensor with respect to the sequence length.\n",
    "            list_length, list_index = torch.sort(list_length, descending=True)\n",
    "            list_length.to(device)\n",
    "            list_index.to(device)\n",
    "            list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).to(device).float()\n",
    "\n",
    "            list_pred_logP = model(list_onehot, list_length).squeeze().to(device)\n",
    "\n",
    "            pred_logP_total += list_pred_logP.tolist()\n",
    "            logP_total += list_logP.tolist()\n",
    "\n",
    "        mae = mean_absolute_error(logP_total, pred_logP_total)\n",
    "        std = np.std(np.array(logP_total) - np.array(pred_logP_total))\n",
    "\n",
    "    return mae, std, logP_total, pred_logP_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dict_partition, device, bar, args):\n",
    "    time_start = time.time()\n",
    "\n",
    "    model = RNNNet(args)\n",
    "    model.to(device)\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, 'Undefined Optimizer Type'\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "    list_train_mae = list()\n",
    "    list_val_mae = list()\n",
    "\n",
    "    data_train = DataLoader(dict_partition['train'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "    data_val = DataLoader(dict_partition['val'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        scheduler.step()\n",
    "        \n",
    "        model, train_loss, train_mae = train(model, device, optimizer, criterion, data_train, bar, args)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_train_mae.append(train_mae)\n",
    "\n",
    "        mode, val_loss, val_mae = validate(model, device, criterion, data_val, bar, args)\n",
    "        list_val_loss.append(val_loss)\n",
    "        list_val_mae.append(val_mae)\n",
    "\n",
    "    data_test = DataLoader(dict_partition['test'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    mae, std, logP_total, pred_logP_total = test(model, device, data_test, args)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_required = time_end - time_start\n",
    "\n",
    "    args.list_train_loss = list_train_loss\n",
    "    args.list_val_loss = list_val_loss\n",
    "    args.list_train_mae = list_train_mae\n",
    "    args.list_val_mae = list_val_mae\n",
    "    args.logP_total = logP_total\n",
    "    args.pred_logP_total = pred_logP_total\n",
    "    args.mae = mae\n",
    "    args.std = std\n",
    "    args.time_required = time_required\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(df_result, var1, var2):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    df_mae = df_result.pivot(var1, var2, 'mae')\n",
    "    df_std = df_result.pivot(var1, var2, 'std')\n",
    "    df_mae = df_mae[df_mae.columns].astype(float)\n",
    "    df_std = df_std[df_std.columns].astype(float)\n",
    "    \n",
    "    hm_mae = sns.heatmap(df_mae, ax=ax[0], annot=True, fmt='f', linewidths=.5, cmap='YlGnBu')\n",
    "    hm_std = sns.heatmap(df_std, ax=ax[1], annot=True, fmt='f', linewidths=.5, cmap='YlGnBu')\n",
    "    \n",
    "    fig.suptitle('Performance depends on ' + var1 + ' vs ' + var2)\n",
    "    hm_mae.set_title('MAE depends on ' + var1 + ' vs ' + var2)\n",
    "    hm_std.set_title('Std depends on ' + var1 + ' vs ' + var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_bar(df_result, var1, var2):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    bar_mae = sns.barplot(x=var1, y='mae', hue=var2, data=df_result, ax=ax[0])\n",
    "    bar_std = sns.barplot(x=var1, y='std', hue=var2, data=df_result, ax=ax[1])\n",
    "    \n",
    "    bar_mae.set_title('MAE depends on ' + var1 + ' vs ' + var2)\n",
    "    bar_std.set_title('Std depends on ' + var1 + ' vs ' + var2)\n",
    "    fig.suptitle('Performance depends on ' + var1 + ' vs ' + var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(df_result, var1, var2, ylim):\n",
    "    def plot(x, ylim=1.0, **kwargs):\n",
    "        plt.plot(x[0], **kwargs)\n",
    "        plt.ylim(0.0, ylim)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\n",
    "    g.map(plot, 'list_train_loss', ylim=ylim, label='Train Loss')\n",
    "    g.map(plot, 'list_val_loss', ylim=ylim, color='r', label='Validation Loss')\n",
    "    g.fig.suptitle('Loss vs Epochs depends on ' + var1 + ' vs ' + var2, size=16)\n",
    "    g.fig.subplots_adjust(top=.9)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df_result, var1, var2):\n",
    "    def scatter(x, y, **kwargs):\n",
    "        plt.scatter(x[0], y[0], alpha=0.3, s=2)\n",
    "    def identity(x, y, **kwargs):\n",
    "        plt.plot(x[0], x[0], alpha=0.4, color='black')\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\n",
    "    g.map(scatter, 'logP_total', 'pred_logP_total')\n",
    "    g.map(identity, 'logP_total', 'logP_total')\n",
    "    g.fig.suptitle('Truth Distribution depends on ' + var1 + ' vs ' + var2, size=16)\n",
    "    g.fig.subplots_adjust(top=.9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0\n",
    "args.optim = 'Adam'\n",
    "args.epoch = 1\n",
    "args.n_layer = 1\n",
    "args.dropout = 0\n",
    "args.in_dim = 32\n",
    "args.hidden_dim = 64\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.out_dim = 1\n",
    "args.step_size = 10\n",
    "args.gamma = 1\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b1e066d5e641f1942a0a0652c5d287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-303-483e07570715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_partition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdict_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-228-1505ee7c4e8d>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(dict_partition, device, bar, args)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mlist_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlist_train_mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-262-ef486aff4c88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, optimizer, criterion, data_train, bar, args)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlist_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlist_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlist_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-262-ef486aff4c88>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlist_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlist_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlist_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict_result = dict()\n",
    "n_iter = args.epoch*(len(dict_partition['train'])+len(dict_partition['val']))\n",
    "bar = tqdm_notebook(total=n_iter, file=sys.stdout, position=0)\n",
    "\n",
    "args.exp_name = \"test\"\n",
    "result = vars(experiment(dict_partition, device, bar, args))\n",
    "dict_result[args.exp_name] = copy.deepcopy(result)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bar.close()\n",
    "\n",
    "df_result = pd.DataFrame(dict_result).transpose()\n",
    "df_result.to_json('test.JSON', orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_json('test.JSON', orient='table')\n",
    "\n",
    "print(\"MAE: \" + str(df_result['mae'][0]))\n",
    "print(\"Std: \" + str(df_result['std'][0]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 5)\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "ax[0].plot(df_result['list_train_loss'][0], label='Train Loss')\n",
    "ax[0].plot(df_result['list_val_loss'][0], label='Validation Loss')\n",
    "ax[0].set_ylim([0, 0.1])\n",
    "ax[0].legend()\n",
    "ax[1].scatter(df_result['logP_total'][0], df_result['pred_logP_total'][0], alpha=0.3, s=2)\n",
    "ax[1].plot(df_result['logP_total'][0], df_result['logP_total'][0], color='black', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'c', 'C', '(', ')', 'O', '1', '2', 'N', '=', '[', ']', '@', '3', 'H', 'n', '4', 'F', '+', 'S', 'l', 's', '/', 'o', '-', '5', '#', 'B', 'r', '\\\\', '6', 'I']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(np.load('./vocab.npy'))\n",
    "smiles = \"C(=O)Cl\"\n",
    "smiles_onehot = [vocab.index(str(x)) for x in smiles]\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "[22 20 23 26 30 24 33 33 24 29 21 22 22 24 37 30 27 34 37 41 33 30 28 27\n",
      " 32 26 30 28 26 26 28 32 26 25 29 37 21 24 21 26 36 33 30 29 33 23 31 29\n",
      " 34 35 40 25 29 34 26 32 17 25 25 30 17 38 27 26 31 36 37 27 30 27 33 31\n",
      " 27 12 17 30 22 27 24 31 25 37 29 31 32 27 29 27 15 35 11 36 32 28 35 28\n",
      " 29 29 20 31 31 30 31 28 31 26 29 28 27 17 23 16 24 34 30 32 27 28 17 30\n",
      " 25 32 26 26 24 19 25 31 25 24 34 25 30 19 27 30 27 27 24 31 25 22 31 31\n",
      " 31 31 23 37 27 26 25 30 21 24 29 33 38 20 33 24 33 22 26 28 25 28 31 26\n",
      " 23 32 21 34 35 30 19 35 31 30 35 36 29 30 21 33 36 28 28 30 29 26 29 22\n",
      " 21 19 23 36 33 33 27 24 33 26 30 32 31 35 38 25 25 25 22 32 14 27 26 31\n",
      " 36 32 31 33 32 35 28 22 25 26 33 14 30 15 14 22 28 27 32 31 31 27 24 28\n",
      " 26 26 22 16 29 28 28 31 35 34 24 29 29 21 35 36 24 27 23 20 22 16 21 26\n",
      " 24 30 30 35 33 33 27 28 21 25 32 28 26 25 31 27 28 29 19 26 25 37 24 32\n",
      " 23 24 31 31 26 18 25 28 29 29 32 30 22 26 31 30 30 29 35 36 29 26 30 22\n",
      " 25 24 25 28 27 37 28 28 33 34 30 27 23 36 24 27 25 34 18 24 31 29 30 23\n",
      " 26 34 29 30 32 27 22 23 23 24 36 33 30 27 29 30 30 31 31 27 32 35 38 25\n",
      " 29 23 25 31 27 17 22 26 16 30 30 31 36 34 27 25 26 25 26 30 15 22 22 26\n",
      " 28 30 22 27 37 23 28 27 30 25 29 27 29 25 35 29 27 28 28 21 24 31 29 36\n",
      " 19 29 20 19 28 28 27 21 31 20 16 24 33 34 25 27 33 27 27 26 28 34 34 32\n",
      " 31 27 26 25 27 19 31 27 24 30 25 28 22 16 23 31 28 28 31 32 32 29 22 27\n",
      " 30 22 31 30 24 35 25 27 26 29 22 31 28 28 26 29 30 21 31 24 27 35 29 35\n",
      " 39 27 29 27 22 23 22 21 32 23 29 33 26 31 33 46 35 29 33 22 26 30 34 33\n",
      " 35 31 27 35 20 21 16 29 12 31 21 16 31 31 23 29 26 34 31 31 32 24 22 18\n",
      " 35 17 37 26 33 20 26 28 33 24 36 23 22 30 23 24 21 16 24 24 24 30 30 34\n",
      " 31 30 32 31 27 28 33 29 25 28 27 30 31 31 27 32 30 31 29 28 34 37 37 29\n",
      " 31 33 27 27 17 28 30 21 30 35 23 29 26 27 25 21 22 20 31 28 28 32 22 21\n",
      " 39 35 37 27 32 35 31 33 30 23 28 24 26 31 36 23 23 36 31 28 33 25 28 25\n",
      " 22 19 21 24 23 30 27 24 27 29 33 31 31 27 35 25 24 25 34 18 21 22 30 27\n",
      " 26 34 33 35 24 31 26 20 25 25 22 25 27 15 23 15 19 29 31 26 25 29 30 22\n",
      " 30 19 18 21 27 23 24 29 36 25 17 30 31 23 21 26 28 32 32 25 36 35 22 27\n",
      " 23 27 27 27 29 20 24 25 33 28 24 29 31 24 28 23 34 30 28 26 28 29 22 29\n",
      " 19 27 19 30 28 26 24 30 23 31 29 28 31 28 35 22 19 28 31 24 27 30 36 31\n",
      " 24 26 30 31 30 24 35 36 27 29 22 17 19 25 31 27 34 26 34 27 27 35 25 32\n",
      " 25 29 23 23 33 34 27 26 32 23 21 24 24 27 32 34 29 32 33 26 30 35 31 27\n",
      " 31 32 35 40 27 29 28 25 21 26 26 34 41 32 33 26 20 25 17 28 23 22 30 31\n",
      " 23 14 26 29 25 24 32 22 31 37 22 27 28 26 20 28 26 15 23 32 30 22 25 22\n",
      " 31 29 29 32 21 35 33 27 23 31 30 31 20 30 29 29 31 28 31 26 29 26 21 23\n",
      " 28 22 18 30 27 26 26 23 34 28 33 26 29 29 23 31 30 17 27 27 26 22 21 24\n",
      " 29 25 24 31 22 34 33 30 28 24 33 23 28 27 24 28 28 25 24 20 25 30 36 31\n",
      " 34 28 15 27 32 24 14 27 24 31 33 29 29 26 23 30 28 27 33 19 25 23 25 34\n",
      " 29 33 30 26 30 31 15 35 40 25 25 29 29 31 26 20 24 21 30 26 33 34 41 26\n",
      " 32 24 27 31 22 20 27 32 26 31 22 26 26 30 29 22 30 29 33 35 26 30 22 23\n",
      " 23 37 26 31 28 32 30 41 22 23 30 17 28 29 30 25]\n"
     ]
    }
   ],
   "source": [
    "print(list_onehot[1])\n",
    "print(list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22., 20., 23., 26., 30.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " tensor([30., 26., 23., 22., 20.]),\n",
       " tensor([4, 3, 2, 0, 1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_onehot = torch.Tensor(list_onehot[:5])\n",
    "tensor_length = torch.Tensor(list_length[:5])\n",
    "print(tensor_length)\n",
    "tensor_length, tensor_index = torch.sort(tensor_length, descending=True)\n",
    "tensor_onehot, tensor_length, tensor_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor_onehot = tensor_onehot.tolist()\n",
    "tensor_onehot = torch.Tensor([tensor_onehot.tolist()[i] for i in tensor_index])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(2, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.Tensor([[[1, 2], [2, 3], [3, 4], [4, 5]]])\n",
    "lstm(input1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.Tensor([[[1], [2], [3], [4], [5]]])\n",
    "\n",
    "lstm(input2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.in_dim = 32\n",
    "args.hidden_dim = 64\n",
    "args.out_dim = 1\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.num_layer = 2\n",
    "args.dropout = 0\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNNet(args)\n",
    "model.to(device)\n",
    "\n",
    "data_train = DataLoader(dict_partition['train'],\n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "for i, batch in enumerate(data_train):\n",
    "    if i==0:\n",
    "        list_onehot = torch.tensor(batch[0]).to(device)\n",
    "        list_length = torch.tensor(batch[1]).to(device)\n",
    "        list_logP = torch.tensor(batch[2]).to(device).view(-1, 1).float()\n",
    "        \n",
    "        # Sort onehot tensor with respect to the sequence length.\n",
    "        list_length, list_index = torch.sort(list_length, descending=True)\n",
    "        list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index])\n",
    "\n",
    "        list_pred_logP = model(list_onehot, list_length).to(device)\n",
    "        list_pred_logP.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_logP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0005, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "mse(list_pred_logP, list_logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0005, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_logP = list_pred_logP.squeeze()\n",
    "list_logP = list_logP.squeeze()\n",
    "mse(list_pred_logP, list_logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3664387083612617"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.array(list_pred_logP.tolist())-np.array(list_logP.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4918543050880544"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.array(list_pred_logP.tolist()), np.array(list_logP.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
