{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.n_bits = 2\n",
    "args.val_size = 0.15\n",
    "args.test_size = 0.15\n",
    "args.shuffle = True\n",
    "args.dict_partition = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26b45c6c3d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_types = ['nr-ahr', 'nr-ar-lbd', \n",
    "             'nr-ar', 'nr-aromatase', \n",
    "             'nr-er-lbd', 'nr-er', \n",
    "             'nr-ppar-gamma', 'sr-are', \n",
    "             'sr-atad5', 'sr-hse', \n",
    "             'sr-mmp', 'sr-p53']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f = open(filename + '.smiles', 'r')\n",
    "    contents = f.readlines()\n",
    "    \n",
    "    smiles = list()\n",
    "    labels = list()\n",
    "    for content in contents:\n",
    "        smi = content.split()[0]\n",
    "        label = int(content.split()[2].strip())\n",
    "        \n",
    "        smiles.append(smi)\n",
    "        labels.append(label)\n",
    "        \n",
    "    num_total = len(smiles)\n",
    "    rand_int = np.random.randint(num_total, size=(num_total,))\n",
    "    \n",
    "    return np.asarray(smiles)[rand_int], np.asarray(labels)[rand_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fingerprint(smile, args):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    arr = np.zeros((1,))\n",
    "    \n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, args.n_bits)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(smiles, labels, args):\n",
    "    fps = list()\n",
    "    toxs = list()\n",
    "    for i, smile in enumerate(smiles):\n",
    "        try:\n",
    "            fp = get_fingerprint(smile, args)\n",
    "            fps.append(fp)\n",
    "            toxs.append(labels[i])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return np.asarray(fps), np.asarray(toxs) #(8161,2048), (8161,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxDataset(Dataset):\n",
    "    def __init__(self, fps, toxs):\n",
    "        self.fps = fps\n",
    "        self.toxs = toxs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fps)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.fps[index], self.toxs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(fps, toxs, args):\n",
    "    num_total = fps.shape[0]\n",
    "    num_train = int(num_total*(1-args.test_size-args.val_size))\n",
    "    num_val = int(num_total*args.val_size)\n",
    "    num_test = int(num_total*args.test_size)\n",
    "        \n",
    "    fps_train = fps[:num_train]\n",
    "    toxs_train = toxs[:num_train]\n",
    "    fps_val = fps[num_train:num_train+num_val]\n",
    "    toxs_val = toxs[num_train:num_train+num_val]\n",
    "    fps_test = fps[num_total-num_test:]\n",
    "    toxs_test = toxs[num_total-num_test:]\n",
    "    \n",
    "    train_set = ToxDataset(fps_train, toxs_train)\n",
    "    val_set = ToxDataset(fps_val, toxs_val)\n",
    "    test_set = ToxDataset(fps_test, toxs_test)\n",
    "    \n",
    "    #batch[0]: torch.Size([128, 2048])\n",
    "    #batch[1]: torch.Size([128])\n",
    "        \n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "    \n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated and saved partition for nr-ahr\n",
      "Generated and saved partition for nr-ar-lbd\n",
      "Generated and saved partition for nr-ar\n",
      "Generated and saved partition for nr-aromatase\n",
      "Generated and saved partition for nr-er-lbd\n",
      "Generated and saved partition for nr-er\n",
      "Generated and saved partition for nr-ppar-gamma\n",
      "Generated and saved partition for sr-are\n",
      "Generated and saved partition for sr-atad5\n",
      "Generated and saved partition for sr-hse\n",
      "Generated and saved partition for sr-mmp\n",
      "Generated and saved partition for sr-p53\n"
     ]
    }
   ],
   "source": [
    "for tox_type in tox_types:\n",
    "    args.tox_type = tox_type\n",
    "    smiles, labels = read_data('tox21/'+tox_type)\n",
    "    fps, toxs = make_dataset(smiles, labels, args)\n",
    "    args.dict_partition[args.tox_type] = partition(fps, toxs, args)\n",
    "    print(\"Generated and saved partition for \" + args.tox_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_result = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(args):\n",
    "    layers = list()\n",
    "    layers.append(nn.Linear(args.input_dim, args.hidden_dim))\n",
    "    layers.append(nn.ReLU())\n",
    "    \n",
    "    for i in range(args.n_layers-2):\n",
    "        layers.append(nn.Linear(args.hidden_dim, args.hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        if args.dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(args.dropout_rate))\n",
    "    \n",
    "    layers.append(nn.Linear(args.hidden_dim, args.output_dim))\n",
    "    layers.append(nn.Sigmoid())\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(args):\n",
    "    model = construct_model(args)\n",
    "    model.to(args.device)\n",
    "\n",
    "    dict_train_loss = dict()\n",
    "    dict_val_loss = dict()\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "\n",
    "    optimizer = args.optim(model.parameters(),\n",
    "                           lr = args.lr,\n",
    "                           weight_decay=args.l2_coef)\n",
    "\n",
    "    data_train = DataLoader(args.dict_partition[args.tox_type]['train'],\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=args.shuffle)\n",
    "\n",
    "    data_val = DataLoader(args.dict_partition[args.tox_type]['val'],\n",
    "                          batch_size=args.batch_size,\n",
    "                          shuffle=args.shuffle)\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for i, batch in enumerate(data_train):\n",
    "            fps = torch.tensor(batch[0], dtype=torch.float, device=args.device)\n",
    "            toxs = torch.tensor(batch[1], dtype=torch.float, device=args.device)\n",
    "            toxs = toxs.view(-1, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_toxs = model(fps)\n",
    "            pred_toxs.require_grad = False\n",
    "            train_loss = args.criterion(pred_toxs, toxs)\n",
    "            epoch_train_loss += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(\"Epoch: \", epoch, \"\\tbatch: \", i, \"\\tTraining\")\n",
    "\n",
    "        dict_train_loss[epoch] = epoch_train_loss/len(data_train)\n",
    "        list_train_loss.append(epoch_train_loss/len(data_train))\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(data_val):\n",
    "                fps = torch.tensor(batch[0], dtype=torch.float, device=args.device)\n",
    "                toxs = torch.tensor(batch[1], dtype=torch.float, device=args.device)\n",
    "                toxs = toxs.view(-1, 1)\n",
    "\n",
    "                pred_toxs = model(fps)\n",
    "                val_loss = args.criterion(pred_toxs, toxs)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "               \n",
    "\n",
    "        dict_val_loss[epoch] = epoch_val_loss/len(data_val)\n",
    "        list_val_loss.append(epoch_val_loss/len(data_val))\n",
    "\n",
    "    data_test = DataLoader(args.dict_partition[args.tox_type]['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=args.shuffle);\n",
    "\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        list_tox = list()\n",
    "        list_pred_tox = list()\n",
    "        list_output = list()\n",
    "        for i, batch in enumerate(data_test):\n",
    "            fps = torch.tensor(batch[0], dtype=torch.float, device=args.device)\n",
    "            toxs = torch.tensor(batch[1], dtype=torch.float, device=args.device)\n",
    "            toxs = toxs.view(-1, 1)\n",
    "\n",
    "            pred_toxs = model(fps)\n",
    "\n",
    "            list_tox += torch.squeeze(toxs).tolist()\n",
    "            list_pred_tox += pred_toxs.tolist()\n",
    "            list_output += [0 if x<0.5 else 1 for x in pred_toxs]\n",
    "\n",
    "            print(\"Batch: \", i, \"\\taccuracy: \", \"\\tTesting\")\n",
    "\n",
    "        acc = accuracy_score(list_tox, list_output)\n",
    "        roc_auc = roc_auc_score(list_tox, list_pred_tox)\n",
    "\n",
    "    return model, list_train_loss, list_val_loss, acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 1024\n",
    "args.output_dim = 1\n",
    "args.n_layers = 3\n",
    "args.dropout_rate = 0.5\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.01\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 \tbatch:  0 \tTraining\n",
      "Epoch:  0 \tbatch:  1 \tTraining\n",
      "Epoch:  0 \tbatch:  2 \tTraining\n",
      "Epoch:  0 \tbatch:  3 \tTraining\n",
      "Epoch:  0 \tbatch:  4 \tTraining\n",
      "Epoch:  0 \tbatch:  5 \tTraining\n",
      "Epoch:  0 \tbatch:  6 \tTraining\n",
      "Epoch:  0 \tbatch:  7 \tTraining\n",
      "Epoch:  0 \tbatch:  8 \tTraining\n",
      "Epoch:  0 \tbatch:  9 \tTraining\n",
      "Epoch:  0 \tbatch:  10 \tTraining\n",
      "Epoch:  0 \tbatch:  11 \tTraining\n",
      "Epoch:  0 \tbatch:  12 \tTraining\n",
      "Epoch:  0 \tbatch:  13 \tTraining\n",
      "Epoch:  0 \tbatch:  14 \tTraining\n",
      "Epoch:  0 \tbatch:  15 \tTraining\n",
      "Epoch:  0 \tbatch:  16 \tTraining\n",
      "Epoch:  0 \tbatch:  17 \tTraining\n",
      "Epoch:  0 \tbatch:  18 \tTraining\n",
      "Epoch:  0 \tbatch:  19 \tTraining\n",
      "Epoch:  0 \tbatch:  20 \tTraining\n",
      "Epoch:  0 \tbatch:  21 \tTraining\n",
      "Epoch:  0 \tbatch:  22 \tTraining\n",
      "Epoch:  0 \tbatch:  23 \tTraining\n",
      "Epoch:  0 \tbatch:  24 \tTraining\n",
      "Epoch:  0 \tbatch:  25 \tTraining\n",
      "Epoch:  0 \tbatch:  26 \tTraining\n",
      "Epoch:  0 \tbatch:  27 \tTraining\n",
      "Epoch:  0 \tbatch:  28 \tTraining\n",
      "Epoch:  0 \tbatch:  29 \tTraining\n",
      "Epoch:  0 \tbatch:  30 \tTraining\n",
      "Epoch:  0 \tbatch:  31 \tTraining\n",
      "Epoch:  0 \tbatch:  32 \tTraining\n",
      "Epoch:  0 \tbatch:  33 \tTraining\n",
      "Epoch:  0 \tbatch:  34 \tTraining\n",
      "Epoch:  0 \tbatch:  35 \tTraining\n",
      "Epoch:  0 \tbatch:  36 \tTraining\n",
      "Epoch:  0 \tbatch:  37 \tTraining\n",
      "Epoch:  0 \tbatch:  38 \tTraining\n",
      "Epoch:  0 \tbatch:  39 \tTraining\n",
      "Epoch:  0 \tbatch:  40 \tTraining\n",
      "Epoch:  0 \tbatch:  41 \tTraining\n",
      "Epoch:  0 \tbatch:  42 \tTraining\n",
      "Epoch:  0 \tbatch:  43 \tTraining\n",
      "Epoch:  0 \tbatch:  44 \tTraining\n",
      "Epoch:  0 \tbatch:  45 \tTraining\n",
      "Epoch:  0 \tbatch:  46 \tTraining\n",
      "Epoch:  0 \tbatch:  47 \tTraining\n",
      "Epoch:  1 \tbatch:  0 \tTraining\n",
      "Epoch:  1 \tbatch:  1 \tTraining\n",
      "Epoch:  1 \tbatch:  2 \tTraining\n",
      "Epoch:  1 \tbatch:  3 \tTraining\n",
      "Epoch:  1 \tbatch:  4 \tTraining\n",
      "Epoch:  1 \tbatch:  5 \tTraining\n",
      "Epoch:  1 \tbatch:  6 \tTraining\n",
      "Epoch:  1 \tbatch:  7 \tTraining\n",
      "Epoch:  1 \tbatch:  8 \tTraining\n",
      "Epoch:  1 \tbatch:  9 \tTraining\n",
      "Epoch:  1 \tbatch:  10 \tTraining\n",
      "Epoch:  1 \tbatch:  11 \tTraining\n",
      "Epoch:  1 \tbatch:  12 \tTraining\n",
      "Epoch:  1 \tbatch:  13 \tTraining\n",
      "Epoch:  1 \tbatch:  14 \tTraining\n",
      "Epoch:  1 \tbatch:  15 \tTraining\n",
      "Epoch:  1 \tbatch:  16 \tTraining\n",
      "Epoch:  1 \tbatch:  17 \tTraining\n",
      "Epoch:  1 \tbatch:  18 \tTraining\n",
      "Epoch:  1 \tbatch:  19 \tTraining\n",
      "Epoch:  1 \tbatch:  20 \tTraining\n",
      "Epoch:  1 \tbatch:  21 \tTraining\n",
      "Epoch:  1 \tbatch:  22 \tTraining\n",
      "Epoch:  1 \tbatch:  23 \tTraining\n",
      "Epoch:  1 \tbatch:  24 \tTraining\n",
      "Epoch:  1 \tbatch:  25 \tTraining\n",
      "Epoch:  1 \tbatch:  26 \tTraining\n",
      "Epoch:  1 \tbatch:  27 \tTraining\n",
      "Epoch:  1 \tbatch:  28 \tTraining\n",
      "Epoch:  1 \tbatch:  29 \tTraining\n",
      "Epoch:  1 \tbatch:  30 \tTraining\n",
      "Epoch:  1 \tbatch:  31 \tTraining\n",
      "Epoch:  1 \tbatch:  32 \tTraining\n",
      "Epoch:  1 \tbatch:  33 \tTraining\n",
      "Epoch:  1 \tbatch:  34 \tTraining\n",
      "Epoch:  1 \tbatch:  35 \tTraining\n",
      "Epoch:  1 \tbatch:  36 \tTraining\n",
      "Epoch:  1 \tbatch:  37 \tTraining\n",
      "Epoch:  1 \tbatch:  38 \tTraining\n",
      "Epoch:  1 \tbatch:  39 \tTraining\n",
      "Epoch:  1 \tbatch:  40 \tTraining\n",
      "Epoch:  1 \tbatch:  41 \tTraining\n",
      "Epoch:  1 \tbatch:  42 \tTraining\n",
      "Epoch:  1 \tbatch:  43 \tTraining\n",
      "Epoch:  1 \tbatch:  44 \tTraining\n",
      "Epoch:  1 \tbatch:  45 \tTraining\n",
      "Epoch:  1 \tbatch:  46 \tTraining\n",
      "Epoch:  1 \tbatch:  47 \tTraining\n",
      "Epoch:  2 \tbatch:  0 \tTraining\n",
      "Epoch:  2 \tbatch:  1 \tTraining\n",
      "Epoch:  2 \tbatch:  2 \tTraining\n",
      "Epoch:  2 \tbatch:  3 \tTraining\n",
      "Epoch:  2 \tbatch:  4 \tTraining\n",
      "Epoch:  2 \tbatch:  5 \tTraining\n",
      "Epoch:  2 \tbatch:  6 \tTraining\n",
      "Epoch:  2 \tbatch:  7 \tTraining\n",
      "Epoch:  2 \tbatch:  8 \tTraining\n",
      "Epoch:  2 \tbatch:  9 \tTraining\n",
      "Epoch:  2 \tbatch:  10 \tTraining\n",
      "Epoch:  2 \tbatch:  11 \tTraining\n",
      "Epoch:  2 \tbatch:  12 \tTraining\n",
      "Epoch:  2 \tbatch:  13 \tTraining\n",
      "Epoch:  2 \tbatch:  14 \tTraining\n",
      "Epoch:  2 \tbatch:  15 \tTraining\n",
      "Epoch:  2 \tbatch:  16 \tTraining\n",
      "Epoch:  2 \tbatch:  17 \tTraining\n",
      "Epoch:  2 \tbatch:  18 \tTraining\n",
      "Epoch:  2 \tbatch:  19 \tTraining\n",
      "Epoch:  2 \tbatch:  20 \tTraining\n",
      "Epoch:  2 \tbatch:  21 \tTraining\n",
      "Epoch:  2 \tbatch:  22 \tTraining\n",
      "Epoch:  2 \tbatch:  23 \tTraining\n",
      "Epoch:  2 \tbatch:  24 \tTraining\n",
      "Epoch:  2 \tbatch:  25 \tTraining\n",
      "Epoch:  2 \tbatch:  26 \tTraining\n",
      "Epoch:  2 \tbatch:  27 \tTraining\n",
      "Epoch:  2 \tbatch:  28 \tTraining\n",
      "Epoch:  2 \tbatch:  29 \tTraining\n",
      "Epoch:  2 \tbatch:  30 \tTraining\n",
      "Epoch:  2 \tbatch:  31 \tTraining\n",
      "Epoch:  2 \tbatch:  32 \tTraining\n",
      "Epoch:  2 \tbatch:  33 \tTraining\n",
      "Epoch:  2 \tbatch:  34 \tTraining\n",
      "Epoch:  2 \tbatch:  35 \tTraining\n",
      "Epoch:  2 \tbatch:  36 \tTraining\n",
      "Epoch:  2 \tbatch:  37 \tTraining\n",
      "Epoch:  2 \tbatch:  38 \tTraining\n",
      "Epoch:  2 \tbatch:  39 \tTraining\n",
      "Epoch:  2 \tbatch:  40 \tTraining\n",
      "Epoch:  2 \tbatch:  41 \tTraining\n",
      "Epoch:  2 \tbatch:  42 \tTraining\n",
      "Epoch:  2 \tbatch:  43 \tTraining\n",
      "Epoch:  2 \tbatch:  44 \tTraining\n",
      "Epoch:  2 \tbatch:  45 \tTraining\n",
      "Epoch:  2 \tbatch:  46 \tTraining\n",
      "Epoch:  2 \tbatch:  47 \tTraining\n",
      "Epoch:  3 \tbatch:  0 \tTraining\n",
      "Epoch:  3 \tbatch:  1 \tTraining\n",
      "Epoch:  3 \tbatch:  2 \tTraining\n",
      "Epoch:  3 \tbatch:  3 \tTraining\n",
      "Epoch:  3 \tbatch:  4 \tTraining\n",
      "Epoch:  3 \tbatch:  5 \tTraining\n",
      "Epoch:  3 \tbatch:  6 \tTraining\n",
      "Epoch:  3 \tbatch:  7 \tTraining\n",
      "Epoch:  3 \tbatch:  8 \tTraining\n",
      "Epoch:  3 \tbatch:  9 \tTraining\n",
      "Epoch:  3 \tbatch:  10 \tTraining\n",
      "Epoch:  3 \tbatch:  11 \tTraining\n",
      "Epoch:  3 \tbatch:  12 \tTraining\n",
      "Epoch:  3 \tbatch:  13 \tTraining\n",
      "Epoch:  3 \tbatch:  14 \tTraining\n",
      "Epoch:  3 \tbatch:  15 \tTraining\n",
      "Epoch:  3 \tbatch:  16 \tTraining\n",
      "Epoch:  3 \tbatch:  17 \tTraining\n",
      "Epoch:  3 \tbatch:  18 \tTraining\n",
      "Epoch:  3 \tbatch:  19 \tTraining\n",
      "Epoch:  3 \tbatch:  20 \tTraining\n",
      "Epoch:  3 \tbatch:  21 \tTraining\n",
      "Epoch:  3 \tbatch:  22 \tTraining\n",
      "Epoch:  3 \tbatch:  23 \tTraining\n",
      "Epoch:  3 \tbatch:  24 \tTraining\n",
      "Epoch:  3 \tbatch:  25 \tTraining\n",
      "Epoch:  3 \tbatch:  26 \tTraining\n",
      "Epoch:  3 \tbatch:  27 \tTraining\n",
      "Epoch:  3 \tbatch:  28 \tTraining\n",
      "Epoch:  3 \tbatch:  29 \tTraining\n",
      "Epoch:  3 \tbatch:  30 \tTraining\n",
      "Epoch:  3 \tbatch:  31 \tTraining\n",
      "Epoch:  3 \tbatch:  32 \tTraining\n",
      "Epoch:  3 \tbatch:  33 \tTraining\n",
      "Epoch:  3 \tbatch:  34 \tTraining\n",
      "Epoch:  3 \tbatch:  35 \tTraining\n",
      "Epoch:  3 \tbatch:  36 \tTraining\n",
      "Epoch:  3 \tbatch:  37 \tTraining\n",
      "Epoch:  3 \tbatch:  38 \tTraining\n",
      "Epoch:  3 \tbatch:  39 \tTraining\n",
      "Epoch:  3 \tbatch:  40 \tTraining\n",
      "Epoch:  3 \tbatch:  41 \tTraining\n",
      "Epoch:  3 \tbatch:  42 \tTraining\n",
      "Epoch:  3 \tbatch:  43 \tTraining\n",
      "Epoch:  3 \tbatch:  44 \tTraining\n",
      "Epoch:  3 \tbatch:  45 \tTraining\n",
      "Epoch:  3 \tbatch:  46 \tTraining\n",
      "Epoch:  3 \tbatch:  47 \tTraining\n",
      "Epoch:  4 \tbatch:  0 \tTraining\n",
      "Epoch:  4 \tbatch:  1 \tTraining\n",
      "Epoch:  4 \tbatch:  2 \tTraining\n",
      "Epoch:  4 \tbatch:  3 \tTraining\n",
      "Epoch:  4 \tbatch:  4 \tTraining\n",
      "Epoch:  4 \tbatch:  5 \tTraining\n",
      "Epoch:  4 \tbatch:  6 \tTraining\n",
      "Epoch:  4 \tbatch:  7 \tTraining\n",
      "Epoch:  4 \tbatch:  8 \tTraining\n",
      "Epoch:  4 \tbatch:  9 \tTraining\n",
      "Epoch:  4 \tbatch:  10 \tTraining\n",
      "Epoch:  4 \tbatch:  11 \tTraining\n",
      "Epoch:  4 \tbatch:  12 \tTraining\n",
      "Epoch:  4 \tbatch:  13 \tTraining\n",
      "Epoch:  4 \tbatch:  14 \tTraining\n",
      "Epoch:  4 \tbatch:  15 \tTraining\n",
      "Epoch:  4 \tbatch:  16 \tTraining\n",
      "Epoch:  4 \tbatch:  17 \tTraining\n",
      "Epoch:  4 \tbatch:  18 \tTraining\n",
      "Epoch:  4 \tbatch:  19 \tTraining\n",
      "Epoch:  4 \tbatch:  20 \tTraining\n",
      "Epoch:  4 \tbatch:  21 \tTraining\n",
      "Epoch:  4 \tbatch:  22 \tTraining\n",
      "Epoch:  4 \tbatch:  23 \tTraining\n",
      "Epoch:  4 \tbatch:  24 \tTraining\n",
      "Epoch:  4 \tbatch:  25 \tTraining\n",
      "Epoch:  4 \tbatch:  26 \tTraining\n",
      "Epoch:  4 \tbatch:  27 \tTraining\n",
      "Epoch:  4 \tbatch:  28 \tTraining\n",
      "Epoch:  4 \tbatch:  29 \tTraining\n",
      "Epoch:  4 \tbatch:  30 \tTraining\n",
      "Epoch:  4 \tbatch:  31 \tTraining\n",
      "Epoch:  4 \tbatch:  32 \tTraining\n",
      "Epoch:  4 \tbatch:  33 \tTraining\n",
      "Epoch:  4 \tbatch:  34 \tTraining\n",
      "Epoch:  4 \tbatch:  35 \tTraining\n",
      "Epoch:  4 \tbatch:  36 \tTraining\n",
      "Epoch:  4 \tbatch:  37 \tTraining\n",
      "Epoch:  4 \tbatch:  38 \tTraining\n",
      "Epoch:  4 \tbatch:  39 \tTraining\n",
      "Epoch:  4 \tbatch:  40 \tTraining\n",
      "Epoch:  4 \tbatch:  41 \tTraining\n",
      "Epoch:  4 \tbatch:  42 \tTraining\n",
      "Epoch:  4 \tbatch:  43 \tTraining\n",
      "Epoch:  4 \tbatch:  44 \tTraining\n",
      "Epoch:  4 \tbatch:  45 \tTraining\n",
      "Epoch:  4 \tbatch:  46 \tTraining\n",
      "Epoch:  4 \tbatch:  47 \tTraining\n",
      "Epoch:  5 \tbatch:  0 \tTraining\n",
      "Epoch:  5 \tbatch:  1 \tTraining\n",
      "Epoch:  5 \tbatch:  2 \tTraining\n",
      "Epoch:  5 \tbatch:  3 \tTraining\n",
      "Epoch:  5 \tbatch:  4 \tTraining\n",
      "Epoch:  5 \tbatch:  5 \tTraining\n",
      "Epoch:  5 \tbatch:  6 \tTraining\n",
      "Epoch:  5 \tbatch:  7 \tTraining\n",
      "Epoch:  5 \tbatch:  8 \tTraining\n",
      "Epoch:  5 \tbatch:  9 \tTraining\n",
      "Epoch:  5 \tbatch:  10 \tTraining\n",
      "Epoch:  5 \tbatch:  11 \tTraining\n",
      "Epoch:  5 \tbatch:  12 \tTraining\n",
      "Epoch:  5 \tbatch:  13 \tTraining\n",
      "Epoch:  5 \tbatch:  14 \tTraining\n",
      "Epoch:  5 \tbatch:  15 \tTraining\n",
      "Epoch:  5 \tbatch:  16 \tTraining\n",
      "Epoch:  5 \tbatch:  17 \tTraining\n",
      "Epoch:  5 \tbatch:  18 \tTraining\n",
      "Epoch:  5 \tbatch:  19 \tTraining\n",
      "Epoch:  5 \tbatch:  20 \tTraining\n",
      "Epoch:  5 \tbatch:  21 \tTraining\n",
      "Epoch:  5 \tbatch:  22 \tTraining\n",
      "Epoch:  5 \tbatch:  23 \tTraining\n",
      "Epoch:  5 \tbatch:  24 \tTraining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 \tbatch:  25 \tTraining\n",
      "Epoch:  5 \tbatch:  26 \tTraining\n",
      "Epoch:  5 \tbatch:  27 \tTraining\n",
      "Epoch:  5 \tbatch:  28 \tTraining\n",
      "Epoch:  5 \tbatch:  29 \tTraining\n",
      "Epoch:  5 \tbatch:  30 \tTraining\n",
      "Epoch:  5 \tbatch:  31 \tTraining\n",
      "Epoch:  5 \tbatch:  32 \tTraining\n",
      "Epoch:  5 \tbatch:  33 \tTraining\n",
      "Epoch:  5 \tbatch:  34 \tTraining\n",
      "Epoch:  5 \tbatch:  35 \tTraining\n",
      "Epoch:  5 \tbatch:  36 \tTraining\n",
      "Epoch:  5 \tbatch:  37 \tTraining\n",
      "Epoch:  5 \tbatch:  38 \tTraining\n",
      "Epoch:  5 \tbatch:  39 \tTraining\n",
      "Epoch:  5 \tbatch:  40 \tTraining\n",
      "Epoch:  5 \tbatch:  41 \tTraining\n",
      "Epoch:  5 \tbatch:  42 \tTraining\n",
      "Epoch:  5 \tbatch:  43 \tTraining\n",
      "Epoch:  5 \tbatch:  44 \tTraining\n",
      "Epoch:  5 \tbatch:  45 \tTraining\n",
      "Epoch:  5 \tbatch:  46 \tTraining\n",
      "Epoch:  5 \tbatch:  47 \tTraining\n",
      "Epoch:  6 \tbatch:  0 \tTraining\n",
      "Epoch:  6 \tbatch:  1 \tTraining\n",
      "Epoch:  6 \tbatch:  2 \tTraining\n",
      "Epoch:  6 \tbatch:  3 \tTraining\n",
      "Epoch:  6 \tbatch:  4 \tTraining\n",
      "Epoch:  6 \tbatch:  5 \tTraining\n",
      "Epoch:  6 \tbatch:  6 \tTraining\n",
      "Epoch:  6 \tbatch:  7 \tTraining\n",
      "Epoch:  6 \tbatch:  8 \tTraining\n",
      "Epoch:  6 \tbatch:  9 \tTraining\n",
      "Epoch:  6 \tbatch:  10 \tTraining\n",
      "Epoch:  6 \tbatch:  11 \tTraining\n",
      "Epoch:  6 \tbatch:  12 \tTraining\n",
      "Epoch:  6 \tbatch:  13 \tTraining\n",
      "Epoch:  6 \tbatch:  14 \tTraining\n",
      "Epoch:  6 \tbatch:  15 \tTraining\n",
      "Epoch:  6 \tbatch:  16 \tTraining\n",
      "Epoch:  6 \tbatch:  17 \tTraining\n",
      "Epoch:  6 \tbatch:  18 \tTraining\n",
      "Epoch:  6 \tbatch:  19 \tTraining\n",
      "Epoch:  6 \tbatch:  20 \tTraining\n",
      "Epoch:  6 \tbatch:  21 \tTraining\n",
      "Epoch:  6 \tbatch:  22 \tTraining\n",
      "Epoch:  6 \tbatch:  23 \tTraining\n",
      "Epoch:  6 \tbatch:  24 \tTraining\n",
      "Epoch:  6 \tbatch:  25 \tTraining\n",
      "Epoch:  6 \tbatch:  26 \tTraining\n",
      "Epoch:  6 \tbatch:  27 \tTraining\n",
      "Epoch:  6 \tbatch:  28 \tTraining\n",
      "Epoch:  6 \tbatch:  29 \tTraining\n",
      "Epoch:  6 \tbatch:  30 \tTraining\n",
      "Epoch:  6 \tbatch:  31 \tTraining\n",
      "Epoch:  6 \tbatch:  32 \tTraining\n",
      "Epoch:  6 \tbatch:  33 \tTraining\n",
      "Epoch:  6 \tbatch:  34 \tTraining\n",
      "Epoch:  6 \tbatch:  35 \tTraining\n",
      "Epoch:  6 \tbatch:  36 \tTraining\n",
      "Epoch:  6 \tbatch:  37 \tTraining\n",
      "Epoch:  6 \tbatch:  38 \tTraining\n",
      "Epoch:  6 \tbatch:  39 \tTraining\n",
      "Epoch:  6 \tbatch:  40 \tTraining\n",
      "Epoch:  6 \tbatch:  41 \tTraining\n",
      "Epoch:  6 \tbatch:  42 \tTraining\n",
      "Epoch:  6 \tbatch:  43 \tTraining\n",
      "Epoch:  6 \tbatch:  44 \tTraining\n",
      "Epoch:  6 \tbatch:  45 \tTraining\n",
      "Epoch:  6 \tbatch:  46 \tTraining\n",
      "Epoch:  6 \tbatch:  47 \tTraining\n",
      "Epoch:  7 \tbatch:  0 \tTraining\n",
      "Epoch:  7 \tbatch:  1 \tTraining\n",
      "Epoch:  7 \tbatch:  2 \tTraining\n",
      "Epoch:  7 \tbatch:  3 \tTraining\n",
      "Epoch:  7 \tbatch:  4 \tTraining\n",
      "Epoch:  7 \tbatch:  5 \tTraining\n",
      "Epoch:  7 \tbatch:  6 \tTraining\n",
      "Epoch:  7 \tbatch:  7 \tTraining\n",
      "Epoch:  7 \tbatch:  8 \tTraining\n",
      "Epoch:  7 \tbatch:  9 \tTraining\n",
      "Epoch:  7 \tbatch:  10 \tTraining\n",
      "Epoch:  7 \tbatch:  11 \tTraining\n",
      "Epoch:  7 \tbatch:  12 \tTraining\n",
      "Epoch:  7 \tbatch:  13 \tTraining\n",
      "Epoch:  7 \tbatch:  14 \tTraining\n",
      "Epoch:  7 \tbatch:  15 \tTraining\n",
      "Epoch:  7 \tbatch:  16 \tTraining\n",
      "Epoch:  7 \tbatch:  17 \tTraining\n",
      "Epoch:  7 \tbatch:  18 \tTraining\n",
      "Epoch:  7 \tbatch:  19 \tTraining\n",
      "Epoch:  7 \tbatch:  20 \tTraining\n",
      "Epoch:  7 \tbatch:  21 \tTraining\n",
      "Epoch:  7 \tbatch:  22 \tTraining\n",
      "Epoch:  7 \tbatch:  23 \tTraining\n",
      "Epoch:  7 \tbatch:  24 \tTraining\n",
      "Epoch:  7 \tbatch:  25 \tTraining\n",
      "Epoch:  7 \tbatch:  26 \tTraining\n",
      "Epoch:  7 \tbatch:  27 \tTraining\n",
      "Epoch:  7 \tbatch:  28 \tTraining\n",
      "Epoch:  7 \tbatch:  29 \tTraining\n",
      "Epoch:  7 \tbatch:  30 \tTraining\n",
      "Epoch:  7 \tbatch:  31 \tTraining\n",
      "Epoch:  7 \tbatch:  32 \tTraining\n",
      "Epoch:  7 \tbatch:  33 \tTraining\n",
      "Epoch:  7 \tbatch:  34 \tTraining\n",
      "Epoch:  7 \tbatch:  35 \tTraining\n",
      "Epoch:  7 \tbatch:  36 \tTraining\n",
      "Epoch:  7 \tbatch:  37 \tTraining\n",
      "Epoch:  7 \tbatch:  38 \tTraining\n",
      "Epoch:  7 \tbatch:  39 \tTraining\n",
      "Epoch:  7 \tbatch:  40 \tTraining\n",
      "Epoch:  7 \tbatch:  41 \tTraining\n",
      "Epoch:  7 \tbatch:  42 \tTraining\n",
      "Epoch:  7 \tbatch:  43 \tTraining\n",
      "Epoch:  7 \tbatch:  44 \tTraining\n",
      "Epoch:  7 \tbatch:  45 \tTraining\n",
      "Epoch:  7 \tbatch:  46 \tTraining\n",
      "Epoch:  7 \tbatch:  47 \tTraining\n",
      "Epoch:  8 \tbatch:  0 \tTraining\n",
      "Epoch:  8 \tbatch:  1 \tTraining\n",
      "Epoch:  8 \tbatch:  2 \tTraining\n",
      "Epoch:  8 \tbatch:  3 \tTraining\n",
      "Epoch:  8 \tbatch:  4 \tTraining\n",
      "Epoch:  8 \tbatch:  5 \tTraining\n",
      "Epoch:  8 \tbatch:  6 \tTraining\n",
      "Epoch:  8 \tbatch:  7 \tTraining\n",
      "Epoch:  8 \tbatch:  8 \tTraining\n",
      "Epoch:  8 \tbatch:  9 \tTraining\n",
      "Epoch:  8 \tbatch:  10 \tTraining\n",
      "Epoch:  8 \tbatch:  11 \tTraining\n",
      "Epoch:  8 \tbatch:  12 \tTraining\n",
      "Epoch:  8 \tbatch:  13 \tTraining\n",
      "Epoch:  8 \tbatch:  14 \tTraining\n",
      "Epoch:  8 \tbatch:  15 \tTraining\n",
      "Epoch:  8 \tbatch:  16 \tTraining\n",
      "Epoch:  8 \tbatch:  17 \tTraining\n",
      "Epoch:  8 \tbatch:  18 \tTraining\n",
      "Epoch:  8 \tbatch:  19 \tTraining\n",
      "Epoch:  8 \tbatch:  20 \tTraining\n",
      "Epoch:  8 \tbatch:  21 \tTraining\n",
      "Epoch:  8 \tbatch:  22 \tTraining\n",
      "Epoch:  8 \tbatch:  23 \tTraining\n",
      "Epoch:  8 \tbatch:  24 \tTraining\n",
      "Epoch:  8 \tbatch:  25 \tTraining\n",
      "Epoch:  8 \tbatch:  26 \tTraining\n",
      "Epoch:  8 \tbatch:  27 \tTraining\n",
      "Epoch:  8 \tbatch:  28 \tTraining\n",
      "Epoch:  8 \tbatch:  29 \tTraining\n",
      "Epoch:  8 \tbatch:  30 \tTraining\n",
      "Epoch:  8 \tbatch:  31 \tTraining\n",
      "Epoch:  8 \tbatch:  32 \tTraining\n",
      "Epoch:  8 \tbatch:  33 \tTraining\n",
      "Epoch:  8 \tbatch:  34 \tTraining\n",
      "Epoch:  8 \tbatch:  35 \tTraining\n",
      "Epoch:  8 \tbatch:  36 \tTraining\n",
      "Epoch:  8 \tbatch:  37 \tTraining\n",
      "Epoch:  8 \tbatch:  38 \tTraining\n",
      "Epoch:  8 \tbatch:  39 \tTraining\n",
      "Epoch:  8 \tbatch:  40 \tTraining\n",
      "Epoch:  8 \tbatch:  41 \tTraining\n",
      "Epoch:  8 \tbatch:  42 \tTraining\n",
      "Epoch:  8 \tbatch:  43 \tTraining\n",
      "Epoch:  8 \tbatch:  44 \tTraining\n",
      "Epoch:  8 \tbatch:  45 \tTraining\n",
      "Epoch:  8 \tbatch:  46 \tTraining\n",
      "Epoch:  8 \tbatch:  47 \tTraining\n",
      "Epoch:  9 \tbatch:  0 \tTraining\n",
      "Epoch:  9 \tbatch:  1 \tTraining\n",
      "Epoch:  9 \tbatch:  2 \tTraining\n",
      "Epoch:  9 \tbatch:  3 \tTraining\n",
      "Epoch:  9 \tbatch:  4 \tTraining\n",
      "Epoch:  9 \tbatch:  5 \tTraining\n",
      "Epoch:  9 \tbatch:  6 \tTraining\n",
      "Epoch:  9 \tbatch:  7 \tTraining\n",
      "Epoch:  9 \tbatch:  8 \tTraining\n",
      "Epoch:  9 \tbatch:  9 \tTraining\n",
      "Epoch:  9 \tbatch:  10 \tTraining\n",
      "Epoch:  9 \tbatch:  11 \tTraining\n",
      "Epoch:  9 \tbatch:  12 \tTraining\n",
      "Epoch:  9 \tbatch:  13 \tTraining\n",
      "Epoch:  9 \tbatch:  14 \tTraining\n",
      "Epoch:  9 \tbatch:  15 \tTraining\n",
      "Epoch:  9 \tbatch:  16 \tTraining\n",
      "Epoch:  9 \tbatch:  17 \tTraining\n",
      "Epoch:  9 \tbatch:  18 \tTraining\n",
      "Epoch:  9 \tbatch:  19 \tTraining\n",
      "Epoch:  9 \tbatch:  20 \tTraining\n",
      "Epoch:  9 \tbatch:  21 \tTraining\n",
      "Epoch:  9 \tbatch:  22 \tTraining\n",
      "Epoch:  9 \tbatch:  23 \tTraining\n",
      "Epoch:  9 \tbatch:  24 \tTraining\n",
      "Epoch:  9 \tbatch:  25 \tTraining\n",
      "Epoch:  9 \tbatch:  26 \tTraining\n",
      "Epoch:  9 \tbatch:  27 \tTraining\n",
      "Epoch:  9 \tbatch:  28 \tTraining\n",
      "Epoch:  9 \tbatch:  29 \tTraining\n",
      "Epoch:  9 \tbatch:  30 \tTraining\n",
      "Epoch:  9 \tbatch:  31 \tTraining\n",
      "Epoch:  9 \tbatch:  32 \tTraining\n",
      "Epoch:  9 \tbatch:  33 \tTraining\n",
      "Epoch:  9 \tbatch:  34 \tTraining\n",
      "Epoch:  9 \tbatch:  35 \tTraining\n",
      "Epoch:  9 \tbatch:  36 \tTraining\n",
      "Epoch:  9 \tbatch:  37 \tTraining\n",
      "Epoch:  9 \tbatch:  38 \tTraining\n",
      "Epoch:  9 \tbatch:  39 \tTraining\n",
      "Epoch:  9 \tbatch:  40 \tTraining\n",
      "Epoch:  9 \tbatch:  41 \tTraining\n",
      "Epoch:  9 \tbatch:  42 \tTraining\n",
      "Epoch:  9 \tbatch:  43 \tTraining\n",
      "Epoch:  9 \tbatch:  44 \tTraining\n",
      "Epoch:  9 \tbatch:  45 \tTraining\n",
      "Epoch:  9 \tbatch:  46 \tTraining\n",
      "Epoch:  9 \tbatch:  47 \tTraining\n",
      "Batch:  0 \taccuracy:  \tTesting\n",
      "Batch:  1 \taccuracy:  \tTesting\n",
      "Batch:  2 \taccuracy:  \tTesting\n",
      "Batch:  3 \taccuracy:  \tTesting\n",
      "Batch:  4 \taccuracy:  \tTesting\n",
      "Batch:  5 \taccuracy:  \tTesting\n",
      "Batch:  6 \taccuracy:  \tTesting\n",
      "Batch:  7 \taccuracy:  \tTesting\n",
      "Batch:  8 \taccuracy:  \tTesting\n",
      "Batch:  9 \taccuracy:  \tTesting\n",
      "Batch:  10 \taccuracy:  \tTesting\n"
     ]
    }
   ],
   "source": [
    "model, list_train_loss, list_val_loss, acc, roc_auc = experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9567233384853169, 0.9081321121287815)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")\n",
    "\n",
    "acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 512\n",
    "args.output_dim = 1\n",
    "args.n_layers = 3\n",
    "args.dropout_rate = 0.5\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.01\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 \tbatch:  0 \tTraining\n",
      "Epoch:  0 \tbatch:  1 \tTraining\n",
      "Epoch:  0 \tbatch:  2 \tTraining\n",
      "Epoch:  0 \tbatch:  3 \tTraining\n",
      "Epoch:  0 \tbatch:  4 \tTraining\n",
      "Epoch:  0 \tbatch:  5 \tTraining\n",
      "Epoch:  0 \tbatch:  6 \tTraining\n",
      "Epoch:  0 \tbatch:  7 \tTraining\n",
      "Epoch:  0 \tbatch:  8 \tTraining\n",
      "Epoch:  0 \tbatch:  9 \tTraining\n",
      "Epoch:  0 \tbatch:  10 \tTraining\n",
      "Epoch:  0 \tbatch:  11 \tTraining\n",
      "Epoch:  0 \tbatch:  12 \tTraining\n",
      "Epoch:  0 \tbatch:  13 \tTraining\n",
      "Epoch:  0 \tbatch:  14 \tTraining\n",
      "Epoch:  0 \tbatch:  15 \tTraining\n",
      "Epoch:  0 \tbatch:  16 \tTraining\n",
      "Epoch:  0 \tbatch:  17 \tTraining\n",
      "Epoch:  0 \tbatch:  18 \tTraining\n",
      "Epoch:  0 \tbatch:  19 \tTraining\n",
      "Epoch:  0 \tbatch:  20 \tTraining\n",
      "Epoch:  0 \tbatch:  21 \tTraining\n",
      "Epoch:  0 \tbatch:  22 \tTraining\n",
      "Epoch:  0 \tbatch:  23 \tTraining\n",
      "Epoch:  0 \tbatch:  24 \tTraining\n",
      "Epoch:  0 \tbatch:  25 \tTraining\n",
      "Epoch:  0 \tbatch:  26 \tTraining\n",
      "Epoch:  0 \tbatch:  27 \tTraining\n",
      "Epoch:  0 \tbatch:  28 \tTraining\n",
      "Epoch:  0 \tbatch:  29 \tTraining\n",
      "Epoch:  0 \tbatch:  30 \tTraining\n",
      "Epoch:  0 \tbatch:  31 \tTraining\n",
      "Epoch:  0 \tbatch:  32 \tTraining\n",
      "Epoch:  0 \tbatch:  33 \tTraining\n",
      "Epoch:  0 \tbatch:  34 \tTraining\n",
      "Epoch:  0 \tbatch:  35 \tTraining\n",
      "Epoch:  0 \tbatch:  36 \tTraining\n",
      "Epoch:  0 \tbatch:  37 \tTraining\n",
      "Epoch:  0 \tbatch:  38 \tTraining\n",
      "Epoch:  0 \tbatch:  39 \tTraining\n",
      "Epoch:  0 \tbatch:  40 \tTraining\n",
      "Epoch:  0 \tbatch:  41 \tTraining\n",
      "Epoch:  0 \tbatch:  42 \tTraining\n",
      "Epoch:  0 \tbatch:  43 \tTraining\n",
      "Epoch:  0 \tbatch:  44 \tTraining\n",
      "Epoch:  0 \tbatch:  45 \tTraining\n",
      "Epoch:  0 \tbatch:  46 \tTraining\n",
      "Epoch:  0 \tbatch:  47 \tTraining\n",
      "Epoch:  1 \tbatch:  0 \tTraining\n",
      "Epoch:  1 \tbatch:  1 \tTraining\n",
      "Epoch:  1 \tbatch:  2 \tTraining\n",
      "Epoch:  1 \tbatch:  3 \tTraining\n",
      "Epoch:  1 \tbatch:  4 \tTraining\n",
      "Epoch:  1 \tbatch:  5 \tTraining\n",
      "Epoch:  1 \tbatch:  6 \tTraining\n",
      "Epoch:  1 \tbatch:  7 \tTraining\n",
      "Epoch:  1 \tbatch:  8 \tTraining\n",
      "Epoch:  1 \tbatch:  9 \tTraining\n",
      "Epoch:  1 \tbatch:  10 \tTraining\n",
      "Epoch:  1 \tbatch:  11 \tTraining\n",
      "Epoch:  1 \tbatch:  12 \tTraining\n",
      "Epoch:  1 \tbatch:  13 \tTraining\n",
      "Epoch:  1 \tbatch:  14 \tTraining\n",
      "Epoch:  1 \tbatch:  15 \tTraining\n",
      "Epoch:  1 \tbatch:  16 \tTraining\n",
      "Epoch:  1 \tbatch:  17 \tTraining\n",
      "Epoch:  1 \tbatch:  18 \tTraining\n",
      "Epoch:  1 \tbatch:  19 \tTraining\n",
      "Epoch:  1 \tbatch:  20 \tTraining\n",
      "Epoch:  1 \tbatch:  21 \tTraining\n",
      "Epoch:  1 \tbatch:  22 \tTraining\n",
      "Epoch:  1 \tbatch:  23 \tTraining\n",
      "Epoch:  1 \tbatch:  24 \tTraining\n",
      "Epoch:  1 \tbatch:  25 \tTraining\n",
      "Epoch:  1 \tbatch:  26 \tTraining\n",
      "Epoch:  1 \tbatch:  27 \tTraining\n",
      "Epoch:  1 \tbatch:  28 \tTraining\n",
      "Epoch:  1 \tbatch:  29 \tTraining\n",
      "Epoch:  1 \tbatch:  30 \tTraining\n",
      "Epoch:  1 \tbatch:  31 \tTraining\n",
      "Epoch:  1 \tbatch:  32 \tTraining\n",
      "Epoch:  1 \tbatch:  33 \tTraining\n",
      "Epoch:  1 \tbatch:  34 \tTraining\n",
      "Epoch:  1 \tbatch:  35 \tTraining\n",
      "Epoch:  1 \tbatch:  36 \tTraining\n",
      "Epoch:  1 \tbatch:  37 \tTraining\n",
      "Epoch:  1 \tbatch:  38 \tTraining\n",
      "Epoch:  1 \tbatch:  39 \tTraining\n",
      "Epoch:  1 \tbatch:  40 \tTraining\n",
      "Epoch:  1 \tbatch:  41 \tTraining\n",
      "Epoch:  1 \tbatch:  42 \tTraining\n",
      "Epoch:  1 \tbatch:  43 \tTraining\n",
      "Epoch:  1 \tbatch:  44 \tTraining\n",
      "Epoch:  1 \tbatch:  45 \tTraining\n",
      "Epoch:  1 \tbatch:  46 \tTraining\n",
      "Epoch:  1 \tbatch:  47 \tTraining\n",
      "Epoch:  2 \tbatch:  0 \tTraining\n",
      "Epoch:  2 \tbatch:  1 \tTraining\n",
      "Epoch:  2 \tbatch:  2 \tTraining\n",
      "Epoch:  2 \tbatch:  3 \tTraining\n",
      "Epoch:  2 \tbatch:  4 \tTraining\n",
      "Epoch:  2 \tbatch:  5 \tTraining\n",
      "Epoch:  2 \tbatch:  6 \tTraining\n",
      "Epoch:  2 \tbatch:  7 \tTraining\n",
      "Epoch:  2 \tbatch:  8 \tTraining\n",
      "Epoch:  2 \tbatch:  9 \tTraining\n",
      "Epoch:  2 \tbatch:  10 \tTraining\n",
      "Epoch:  2 \tbatch:  11 \tTraining\n",
      "Epoch:  2 \tbatch:  12 \tTraining\n",
      "Epoch:  2 \tbatch:  13 \tTraining\n",
      "Epoch:  2 \tbatch:  14 \tTraining\n",
      "Epoch:  2 \tbatch:  15 \tTraining\n",
      "Epoch:  2 \tbatch:  16 \tTraining\n",
      "Epoch:  2 \tbatch:  17 \tTraining\n",
      "Epoch:  2 \tbatch:  18 \tTraining\n",
      "Epoch:  2 \tbatch:  19 \tTraining\n",
      "Epoch:  2 \tbatch:  20 \tTraining\n",
      "Epoch:  2 \tbatch:  21 \tTraining\n",
      "Epoch:  2 \tbatch:  22 \tTraining\n",
      "Epoch:  2 \tbatch:  23 \tTraining\n",
      "Epoch:  2 \tbatch:  24 \tTraining\n",
      "Epoch:  2 \tbatch:  25 \tTraining\n",
      "Epoch:  2 \tbatch:  26 \tTraining\n",
      "Epoch:  2 \tbatch:  27 \tTraining\n",
      "Epoch:  2 \tbatch:  28 \tTraining\n",
      "Epoch:  2 \tbatch:  29 \tTraining\n",
      "Epoch:  2 \tbatch:  30 \tTraining\n",
      "Epoch:  2 \tbatch:  31 \tTraining\n",
      "Epoch:  2 \tbatch:  32 \tTraining\n",
      "Epoch:  2 \tbatch:  33 \tTraining\n",
      "Epoch:  2 \tbatch:  34 \tTraining\n",
      "Epoch:  2 \tbatch:  35 \tTraining\n",
      "Epoch:  2 \tbatch:  36 \tTraining\n",
      "Epoch:  2 \tbatch:  37 \tTraining\n",
      "Epoch:  2 \tbatch:  38 \tTraining\n",
      "Epoch:  2 \tbatch:  39 \tTraining\n",
      "Epoch:  2 \tbatch:  40 \tTraining\n",
      "Epoch:  2 \tbatch:  41 \tTraining\n",
      "Epoch:  2 \tbatch:  42 \tTraining\n",
      "Epoch:  2 \tbatch:  43 \tTraining\n",
      "Epoch:  2 \tbatch:  44 \tTraining\n",
      "Epoch:  2 \tbatch:  45 \tTraining\n",
      "Epoch:  2 \tbatch:  46 \tTraining\n",
      "Epoch:  2 \tbatch:  47 \tTraining\n",
      "Epoch:  3 \tbatch:  0 \tTraining\n",
      "Epoch:  3 \tbatch:  1 \tTraining\n",
      "Epoch:  3 \tbatch:  2 \tTraining\n",
      "Epoch:  3 \tbatch:  3 \tTraining\n",
      "Epoch:  3 \tbatch:  4 \tTraining\n",
      "Epoch:  3 \tbatch:  5 \tTraining\n",
      "Epoch:  3 \tbatch:  6 \tTraining\n",
      "Epoch:  3 \tbatch:  7 \tTraining\n",
      "Epoch:  3 \tbatch:  8 \tTraining\n",
      "Epoch:  3 \tbatch:  9 \tTraining\n",
      "Epoch:  3 \tbatch:  10 \tTraining\n",
      "Epoch:  3 \tbatch:  11 \tTraining\n",
      "Epoch:  3 \tbatch:  12 \tTraining\n",
      "Epoch:  3 \tbatch:  13 \tTraining\n",
      "Epoch:  3 \tbatch:  14 \tTraining\n",
      "Epoch:  3 \tbatch:  15 \tTraining\n",
      "Epoch:  3 \tbatch:  16 \tTraining\n",
      "Epoch:  3 \tbatch:  17 \tTraining\n",
      "Epoch:  3 \tbatch:  18 \tTraining\n",
      "Epoch:  3 \tbatch:  19 \tTraining\n",
      "Epoch:  3 \tbatch:  20 \tTraining\n",
      "Epoch:  3 \tbatch:  21 \tTraining\n",
      "Epoch:  3 \tbatch:  22 \tTraining\n",
      "Epoch:  3 \tbatch:  23 \tTraining\n",
      "Epoch:  3 \tbatch:  24 \tTraining\n",
      "Epoch:  3 \tbatch:  25 \tTraining\n",
      "Epoch:  3 \tbatch:  26 \tTraining\n",
      "Epoch:  3 \tbatch:  27 \tTraining\n",
      "Epoch:  3 \tbatch:  28 \tTraining\n",
      "Epoch:  3 \tbatch:  29 \tTraining\n",
      "Epoch:  3 \tbatch:  30 \tTraining\n",
      "Epoch:  3 \tbatch:  31 \tTraining\n",
      "Epoch:  3 \tbatch:  32 \tTraining\n",
      "Epoch:  3 \tbatch:  33 \tTraining\n",
      "Epoch:  3 \tbatch:  34 \tTraining\n",
      "Epoch:  3 \tbatch:  35 \tTraining\n",
      "Epoch:  3 \tbatch:  36 \tTraining\n",
      "Epoch:  3 \tbatch:  37 \tTraining\n",
      "Epoch:  3 \tbatch:  38 \tTraining\n",
      "Epoch:  3 \tbatch:  39 \tTraining\n",
      "Epoch:  3 \tbatch:  40 \tTraining\n",
      "Epoch:  3 \tbatch:  41 \tTraining\n",
      "Epoch:  3 \tbatch:  42 \tTraining\n",
      "Epoch:  3 \tbatch:  43 \tTraining\n",
      "Epoch:  3 \tbatch:  44 \tTraining\n",
      "Epoch:  3 \tbatch:  45 \tTraining\n",
      "Epoch:  3 \tbatch:  46 \tTraining\n",
      "Epoch:  3 \tbatch:  47 \tTraining\n",
      "Epoch:  4 \tbatch:  0 \tTraining\n",
      "Epoch:  4 \tbatch:  1 \tTraining\n",
      "Epoch:  4 \tbatch:  2 \tTraining\n",
      "Epoch:  4 \tbatch:  3 \tTraining\n",
      "Epoch:  4 \tbatch:  4 \tTraining\n",
      "Epoch:  4 \tbatch:  5 \tTraining\n",
      "Epoch:  4 \tbatch:  6 \tTraining\n",
      "Epoch:  4 \tbatch:  7 \tTraining\n",
      "Epoch:  4 \tbatch:  8 \tTraining\n",
      "Epoch:  4 \tbatch:  9 \tTraining\n",
      "Epoch:  4 \tbatch:  10 \tTraining\n",
      "Epoch:  4 \tbatch:  11 \tTraining\n",
      "Epoch:  4 \tbatch:  12 \tTraining\n",
      "Epoch:  4 \tbatch:  13 \tTraining\n",
      "Epoch:  4 \tbatch:  14 \tTraining\n",
      "Epoch:  4 \tbatch:  15 \tTraining\n",
      "Epoch:  4 \tbatch:  16 \tTraining\n",
      "Epoch:  4 \tbatch:  17 \tTraining\n",
      "Epoch:  4 \tbatch:  18 \tTraining\n",
      "Epoch:  4 \tbatch:  19 \tTraining\n",
      "Epoch:  4 \tbatch:  20 \tTraining\n",
      "Epoch:  4 \tbatch:  21 \tTraining\n",
      "Epoch:  4 \tbatch:  22 \tTraining\n",
      "Epoch:  4 \tbatch:  23 \tTraining\n",
      "Epoch:  4 \tbatch:  24 \tTraining\n",
      "Epoch:  4 \tbatch:  25 \tTraining\n",
      "Epoch:  4 \tbatch:  26 \tTraining\n",
      "Epoch:  4 \tbatch:  27 \tTraining\n",
      "Epoch:  4 \tbatch:  28 \tTraining\n",
      "Epoch:  4 \tbatch:  29 \tTraining\n",
      "Epoch:  4 \tbatch:  30 \tTraining\n",
      "Epoch:  4 \tbatch:  31 \tTraining\n",
      "Epoch:  4 \tbatch:  32 \tTraining\n",
      "Epoch:  4 \tbatch:  33 \tTraining\n",
      "Epoch:  4 \tbatch:  34 \tTraining\n",
      "Epoch:  4 \tbatch:  35 \tTraining\n",
      "Epoch:  4 \tbatch:  36 \tTraining\n",
      "Epoch:  4 \tbatch:  37 \tTraining\n",
      "Epoch:  4 \tbatch:  38 \tTraining\n",
      "Epoch:  4 \tbatch:  39 \tTraining\n",
      "Epoch:  4 \tbatch:  40 \tTraining\n",
      "Epoch:  4 \tbatch:  41 \tTraining\n",
      "Epoch:  4 \tbatch:  42 \tTraining\n",
      "Epoch:  4 \tbatch:  43 \tTraining\n",
      "Epoch:  4 \tbatch:  44 \tTraining\n",
      "Epoch:  4 \tbatch:  45 \tTraining\n",
      "Epoch:  4 \tbatch:  46 \tTraining\n",
      "Epoch:  4 \tbatch:  47 \tTraining\n",
      "Epoch:  5 \tbatch:  0 \tTraining\n"
     ]
    }
   ],
   "source": [
    "model, list_train_loss, list_val_loss, acc, roc_auc = experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")\n",
    "\n",
    "acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 256\n",
    "args.output_dim = 1\n",
    "args.n_layers = 3\n",
    "args.dropout_rate = 0.5\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.01\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, list_train_loss, list_val_loss, acc, roc_auc = experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")\n",
    "\n",
    "acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 128\n",
    "args.output_dim = 1\n",
    "args.n_layers = 3\n",
    "args.dropout_rate = 0.5\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.01\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, list_train_loss, list_val_loss, acc, roc_auc = experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")\n",
    "\n",
    "acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 64\n",
    "args.output_dim = 1\n",
    "args.n_layers = 3\n",
    "args.dropout_rate = 0.5\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.01\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, list_train_loss, list_val_loss, acc, roc_auc = experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")\n",
    "\n",
    "acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 32\n",
    "args.output_dim = 1\n",
    "args.n_layers = 3\n",
    "args.dropout_rate = 0.5\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.01\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 10\n",
    "args.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, list_train_loss, list_val_loss, acc, roc_auc = experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")\n",
    "\n",
    "acc, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as hidden dimension decreases exponentially from 1024 to 32, the train loss graph does not change, but the validation loss graph approaches to the train loss graph. The accuracy and roc_auc value is similar. This means that as hidden dimension decreases, the overfitting-ness decreases. Hidden dimension of 1024 has too many parameters, so it just memorizes the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
