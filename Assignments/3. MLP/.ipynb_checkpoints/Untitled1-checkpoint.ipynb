{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.n_bits = 2048\n",
    "args.n_splits = 5\n",
    "args.test_size = 0.15\n",
    "args.val_size = 0.15\n",
    "args.shuffle = True\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "tox_types = ['nr-ahr', 'nr-ar-lbd', \n",
    "             'nr-ar', 'nr-aromatase', \n",
    "             'nr-er-lbd', 'nr-er', \n",
    "             'nr-ppar-gamma', 'sr-are', \n",
    "             'sr-atad5', 'sr-hse', \n",
    "             'sr-mmp', 'sr-p53']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_partition = dict()\n",
    "for tox_type in tox_types:\n",
    "    args.tox_type = 'tox21/'+tox_type\n",
    "    smiles, toxs = make_dataset(args)\n",
    "    dict_partition[args.tox_type] = partition(smiles, toxs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_result = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(args):\n",
    "    layers = list()\n",
    "    layers.append(nn.Linear(args.input_dim, args.hidden_dim))\n",
    "    layers.append(nn.ReLU())\n",
    "    \n",
    "    for i in range(args.n_layer-2):\n",
    "        layers.append(nn.Linear(args.hidden_dim, args.hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        if args.dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(args.dropout_rate))\n",
    "            \n",
    "    layers.append(nn.Linear(args.hidden_dim, args.output_dim))\n",
    "    layers.append(nn.Sigmoid())\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, criterion, args):\n",
    "    dict_train_loss = dict()\n",
    "    \n",
    "    data_iter = DataLoader(partition['train'], \n",
    "                           batch_size=args.batch_size, \n",
    "                           shuffle=args.shuffle)\n",
    "    \n",
    "    for epoch in range(args.epoch):\n",
    "        train_loss_epoch = 0\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            fps = torch.tensor(batch[0], device=args.device)\n",
    "            toxs = torch.tensor(batch[1], device=args.device)\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_toxs = model(fps)\n",
    "            pred_toxs.require_grad = False\n",
    "            \n",
    "            train_loss = criterion(pred_toxs, toxs)\n",
    "            train_loss_epoch += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        dict_train_loss[(epoch+1)*args.batch_size/len(data_iter)] = train_loss.item()\n",
    "    \n",
    "    return model, pd.Series(dict_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate(model, parition, criterion, args):\n",
    "    dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(args):\n",
    "    dict_train_loss = dict()\n",
    "    dict_val_loss = dict()\n",
    "    \n",
    "    model = construct_model(args)\n",
    "    model.to(args.device)\n",
    "    \n",
    "    optimizer = args.optim(model.parameters(), \n",
    "                           lr=args.lr, \n",
    "                           weight_decay=args.l2_coef)\n",
    "    \n",
    "    data_train = DataLoader(args.partition['train'],\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=args.shuffle)\n",
    "    \n",
    "    data_val = DataLoader(args.partition['val'],\n",
    "                          batch_size=args.batch_size,\n",
    "                          shuffle=args.shuffle)\n",
    "    \n",
    "    data_test = DataLoader(args.partition['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=args.shuffle)\n",
    "    \n",
    "    for epoch in range(args.epoch):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for i, batch in enumerate(data_train):\n",
    "            fps = torch.tensor(batch[0], device=args.device)\n",
    "            toxs = torch.tensor(batch[1], device=args.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_toxs = model(fps)\n",
    "            pred_toxs.require_grad = False\n",
    "            \n",
    "            train_loss = criterion(pred_toxs, toxs)\n",
    "            epoch_train_loss += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        dict_train_loss[epoch] = train_loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(data_val):\n",
    "                fps = torch.tensor(batch[0], device=args.device)\n",
    "                toxs = torch.tensor(batch[1], device=args.device)\n",
    "\n",
    "                pred_toxs = model(fps)\n",
    "                \n",
    "                val_loss = criterion(pred_toxs, toxs)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "                \n",
    "        dict_val_loss[epoch] = val_loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    output = list()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_test):\n",
    "            fps = torch.tensor(batch[0], device=args.device)\n",
    "            toxs = torch.tensor(batch[1], device=args.device)\n",
    "            \n",
    "            pred_toxs = model(fps)\n",
    "            \n",
    "            output.append([0 if x<0.5 else 1 for x in pred_toxs])\n",
    "        \n",
    "        output = np.concatenate(output, axis=0)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-994a6ef30cb0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-994a6ef30cb0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def experiment(partition)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "args.exp_name = 'exp_hidden_dim'\n",
    "args.input_dim = 2048\n",
    "args.output_dim = 1\n",
    "args.n_layer = 3\n",
    "args.dropout_rate = 0.0\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 100\n",
    "args.batch_size = 128\n",
    "args.device = 'cpu'\n",
    "\n",
    "exp_result[args.exp_name] = list()\n",
    "hidden_dims = [64, 128, 256, 1024]\n",
    "\n",
    "for tox_type in tox_types[:1]:\n",
    "    for hidden_dim in hidden_dims:\n",
    "        args.tox_type = tox_type\n",
    "        args.hidden_dim = hidden_dim\n",
    "        args.partition = dict_partition[args.tox_type]\n",
    "        experiemnt(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_toxs = [0.1, 0.1, 0.8]\n",
    "output = [0 if x<0.5 else 1 for x in pred_toxs]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_module' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c4b75f2e1d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdict_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-6092af12df05>\u001b[0m in \u001b[0;36mconstruct_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_module' is not defined"
     ]
    }
   ],
   "source": [
    "args.exp_name = 'exp_hidden_dim'\n",
    "args.input_dim = 2048\n",
    "args.output_dim = 1\n",
    "args.n_layer = 3\n",
    "args.dropout_rate = 0.0\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.BCELoss()\n",
    "args.epoch = 100\n",
    "args.batch_size = 128\n",
    "args.device = 'cpu'\n",
    "\n",
    "args.hidden_dim = 128\n",
    "\n",
    "dict_train_loss = dict()\n",
    "dict_val_loss = dict()\n",
    "\n",
    "model = construct_model(args)\n",
    "model.to(args.device)\n",
    "\n",
    "optimizer = args.optim(model.parameters(), \n",
    "                       lr=args.lr, \n",
    "                       weight_decay=args.l2_coef)\n",
    "\n",
    "data_train = DataLoader(args.partition['train'],\n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "data_val = DataLoader(args.partition['val'],\n",
    "                      batch_size=args.batch_size,\n",
    "                      shuffle=args.shuffle)\n",
    "\n",
    "data_test = DataLoader(args.partition['test'],\n",
    "                       batch_size=args.batch_size,\n",
    "                       shuffle=args.shuffle)\n",
    "\n",
    "for epoch in range(args.epoch):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for i, batch in enumerate(data_train):\n",
    "        fps = torch.tensor(batch[0], device=args.device)\n",
    "        toxs = torch.tensor(batch[1], device=args.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_toxs = model(fps)\n",
    "        pred_toxs.require_grad = False\n",
    "\n",
    "        train_loss = criterion(pred_toxs, toxs)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    dict_train_loss[epoch] = train_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            fps = torch.tensor(batch[0], device=args.device)\n",
    "            toxs = torch.tensor(batch[1], device=args.device)\n",
    "\n",
    "            pred_toxs = model(fps)\n",
    "\n",
    "            val_loss = criterion(pred_toxs, toxs)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "\n",
    "    dict_val_loss[epoch] = val_loss.item()\n",
    "\n",
    "model.eval()\n",
    "output = list()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(data_test):\n",
    "        fps = torch.tensor(batch[0], device=args.device)\n",
    "        toxs = torch.tensor(batch[1], device=args.device)\n",
    "\n",
    "        pred_toxs = model(fps)\n",
    "\n",
    "        output.append([0 if x<0.5 else 1 for x in pred_toxs])\n",
    "\n",
    "    output = np.concatenate(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
