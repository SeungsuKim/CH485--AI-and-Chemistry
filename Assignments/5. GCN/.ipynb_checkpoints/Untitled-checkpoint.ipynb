{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#from utils import read_ZINC_smiles, smiles_to_onehot, partition, OneHotLogPDataSet\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paser = argparse.ArgumentParser()\n",
    "args = paser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.val_size = 0.15\n",
    "args.test_size = 0.15\n",
    "args.shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2f5dbc9be90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ZINC_smiles(file_name, num_mol):\n",
    "    f = open(file_name, 'r')\n",
    "    contents = f.readlines()\n",
    "\n",
    "    smi_list = []\n",
    "    logP_list = []\n",
    "\n",
    "    for i in tqdm_notebook(range(num_mol), desc='Reading Data'):\n",
    "        smi = contents[i].strip()\n",
    "        m = Chem.MolFromSmiles(smi)\n",
    "        smi_list.append(smi)\n",
    "        logP_list.append(MolLogP(m))\n",
    "\n",
    "    logP_list = np.asarray(logP_list).astype(float)\n",
    "\n",
    "    return smi_list, logP_list\n",
    "\n",
    "\n",
    "def smiles_to_onehot(smi_list):\n",
    "    def smiles_to_vector(smiles, vocab, max_length):\n",
    "        while len(smiles) < max_length:\n",
    "            smiles += \" \"\n",
    "        vector = [vocab.index(str(x)) for x in smiles]\n",
    "        one_hot = np.zeros((len(vocab), max_length), dtype=int)\n",
    "        for i, elm in enumerate(vector):\n",
    "            one_hot[elm][i] = 1\n",
    "        return one_hot\n",
    "\n",
    "    vocab = np.load('./vocab.npy')\n",
    "    smi_total = []\n",
    "\n",
    "    for i, smi in tqdm_notebook(enumerate(smi_list), desc='Converting to One Hot'):\n",
    "        smi_onehot = smiles_to_vector(smi, list(vocab), 120)\n",
    "        smi_total.append(smi_onehot)\n",
    "\n",
    "    return np.asarray(smi_total)\n",
    "\n",
    "def convert_to_graph(smiles_list):\n",
    "    adj = []\n",
    "    adj_norm = []\n",
    "    features = []\n",
    "    maxNumAtoms = 50\n",
    "    for i in tqdm_notebook(smiles_list, desc='Converting to Graph'):\n",
    "        # Mol\n",
    "        iMol = Chem.MolFromSmiles(i.strip())\n",
    "        #Adj\n",
    "        iAdjTmp = Chem.rdmolops.GetAdjacencyMatrix(iMol)\n",
    "        # Feature\n",
    "        if( iAdjTmp.shape[0] <= maxNumAtoms):\n",
    "            # Feature-preprocessing\n",
    "            iFeature = np.zeros((maxNumAtoms, 58))\n",
    "            iFeatureTmp = []\n",
    "            for atom in iMol.GetAtoms():\n",
    "                iFeatureTmp.append( atom_feature(atom) ) ### atom features only\n",
    "            iFeature[0:len(iFeatureTmp), 0:58] = iFeatureTmp ### 0 padding for feature-set\n",
    "            features.append(iFeature)\n",
    "\n",
    "            # Adj-preprocessing\n",
    "            iAdj = np.zeros((maxNumAtoms, maxNumAtoms))\n",
    "            iAdj[0:len(iFeatureTmp), 0:len(iFeatureTmp)] = iAdjTmp + np.eye(len(iFeatureTmp))\n",
    "            adj.append(np.asarray(iAdj))\n",
    "    features = np.asarray(features)\n",
    "\n",
    "    return features, adj\n",
    "    \n",
    "def atom_feature(atom):\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "                                      ['C', 'N', 'O', 'S', 'F', 'H', 'Si', 'P', 'Cl', 'Br',\n",
    "                                       'Li', 'Na', 'K', 'Mg', 'Ca', 'Fe', 'As', 'Al', 'I', 'B',\n",
    "                                       'V', 'Tl', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
    "                                       'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'Mn', 'Cr', 'Pt', 'Hg', 'Pb']) +\n",
    "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    [atom.GetIsAromatic()])    # (40, 6, 5, 6, 1)\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    #print list((map(lambda s: x == s, allowable_set)))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "class GCNDataset(Dataset):\n",
    "    def __init__(self, list_feature, list_adj, list_logP):\n",
    "        self.list_feature = list_feature\n",
    "        self.list_adj = list_adj\n",
    "        self.list_logP = list_logP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_feature)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.list_feature[index], self.list_adj[index], self.list_logP[index]\n",
    "\n",
    "\n",
    "def partition(list_feature, list_adj, list_logP, args):\n",
    "    num_total = list_feature.shape[0]\n",
    "    num_train = int(num_total * (1 - args.test_size - args.val_size))\n",
    "    num_val = int(num_total * args.val_size)\n",
    "    num_test = int(num_total * args.test_size)\n",
    "\n",
    "    feature_train = list_feature[:num_train]\n",
    "    adj_train = list_adj[:num_train]\n",
    "    logP_train = list_logP[:num_train]\n",
    "    feature_val = list_feature[num_train:num_train + num_val]\n",
    "    adj_val = list_adj[num_train:num_train + num_val]\n",
    "    logP_val = list_logP[num_train:num_train + num_val]\n",
    "    feature_test = list_feature[num_total - num_test:]\n",
    "    adj_test = list_adj[num_train:num_train + num_val]\n",
    "    logP_test = list_logP[num_total - num_test:]\n",
    "\n",
    "    train_set = GCNDataset(feature_train, adj_train, logP_train)\n",
    "    val_set = GCNDataset(feature_val, adj_val, logP_val)\n",
    "    test_set = GCNDataset(feature_test, adj_test, logP_test)\n",
    "\n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34c59e487114be0b45efe15debfbc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading Data', max=20000, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3cc64f014b41feabf1687b00918c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting to Graph', max=20000, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_smi, list_logP = read_ZINC_smiles('ZINC.smiles', 2000)\n",
    "list_feature, list_adj = convert_to_graph(list_smi)\n",
    "args.dict_partition = partition(list_feature, list_adj, list_logP, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedSkipConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, new_dim, out_dim, activation):\n",
    "        super(GatedSkipConnection, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.new_dim = new_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.linear_in = nn.Linear(in_dim, out_dim)\n",
    "        self.linear_new = nn.Linear(new_dim, out_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_x, new_x):        \n",
    "        z = self.gate_coefficient(input_x, new_x)\n",
    "        \n",
    "        if (self.in_dim != self.out_dim):\n",
    "            input_x = self.linear_in(input_x)\n",
    "        if (self.new_dim != self.out_dim):\n",
    "            new_x = self.linear_new(new_x)\n",
    "            \n",
    "        out = torch.mul(new_x, z) + torch.mul(input_x, 1.0-z)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def gate_coefficient(self, input_x, new_x):\n",
    "        X1 = self.linear_in(input_x)\n",
    "        X2 = self.linear_new(new_x)\n",
    "        gate_coefficient = self.sigmoid(X1 + X2)\n",
    "        \n",
    "        return gate_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim, activation, sc='no'):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "        self.sc = sc\n",
    "\n",
    "        self.linear = nn.Linear(self.in_dim, \n",
    "                                self.hidden_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.gated_skip_connection = GatedSkipConnection(self.in_dim,\n",
    "                                                         self.hidden_dim,\n",
    "                                                         self.hidden_dim, \n",
    "                                                         self.activation)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        out = self.linear(x)\n",
    "        out = torch.matmul(adj, out)\n",
    "        \n",
    "        if (self.sc == 'gsc'):\n",
    "            out = self.gated_skip_connection(x, out)\n",
    "        elif (self.sc == 'no'):\n",
    "            out = self.activation(out)\n",
    "        else:\n",
    "            out = self.activation(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadOut(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, activation):\n",
    "        super(ReadOut, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim= out_dim\n",
    "        \n",
    "        self.linear = nn.Linear(self.in_dim, \n",
    "                                self.out_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, activation=None):\n",
    "        super(Predictor, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.linear = nn.Linear(self.in_dim,\n",
    "                                self.out_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        if self.activation != None:\n",
    "            out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogPPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_layer, \n",
    "                 in_dim, \n",
    "                 hidden_dim_1, \n",
    "                 hidden_dim_2,\n",
    "                 out_dim,\n",
    "                 sc='no'):\n",
    "        super(LogPPredictor, self).__init__()\n",
    "        \n",
    "        self.n_layer = n_layer\n",
    "        self.graph_convolution_1 = GraphConvolution(in_dim, hidden_dim_1, nn.ReLU(), sc)\n",
    "        self.graph_convolution_2 = GraphConvolution(hidden_dim_1, hidden_dim_1, nn.ReLU(), sc)\n",
    "        self.readout = ReadOut(hidden_dim_1, hidden_dim_2, nn.Sigmoid())\n",
    "        self.predictor_1 = Predictor(hidden_dim_2, hidden_dim_2, nn.ReLU())\n",
    "        self.predictor_2 = Predictor(hidden_dim_2, hidden_dim_2, nn.Tanh())\n",
    "        self.predictor_3 = Predictor(hidden_dim_2, out_dim)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        out = self.graph_convolution_1(x, adj)\n",
    "        for i in range(self.n_layer-1):\n",
    "            out = self.graph_convolution_2(out, adj)\n",
    "        out = self.readout(out)\n",
    "        out = self.predictor_1(out)\n",
    "        out = self.predictor_2(out)\n",
    "        out = self.predictor_3(out)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 10\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.001\n",
    "args.optim = optim.Adam\n",
    "args.criterion = nn.MSELoss()\n",
    "args.epoch = 10\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f69134312244b6db932e0199a78a69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_gpu = lambda x=True: torch.set_default_tensor_type(torch.cuda.DoubleTensor if torch.cuda.is_available() and x else torch.FloatTensor)\n",
    "use_gpu()\n",
    "\n",
    "print(args.device)\n",
    "\n",
    "model = LogPPredictor(1, 58, 64, 128, 1, 'gsc')\n",
    "model.to(args.device)\n",
    "model.cuda()\n",
    "\n",
    "list_train_loss = list()\n",
    "list_val_loss = list()\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "optimizer = args.optim(model.parameters(),\n",
    "                       lr=args.lr,\n",
    "                       weight_decay=args.l2_coef)\n",
    "\n",
    "data_train = DataLoader(args.dict_partition['train'], \n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "data_val = DataLoader(args.dict_partition['val'],\n",
    "                     batch_size=args.batch_size,\n",
    "                     shuffle=args.shuffle)\n",
    "\n",
    "for epoch in tqdm_notebook(range(args.epoch), desc='Epoch'):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_feature = torch.tensor(batch[0])\n",
    "        list_adj = torch.tensor(batch[1])\n",
    "        list_logP = torch.tensor(batch[2])\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        list_pred_logP.require_grad = False\n",
    "        train_loss = args.criterion(list_pred_logP, list_logP)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    list_train_loss.append(epoch_train_loss/len(data_train))\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_feature = torch.tensor(batch[0])\n",
    "            list_adj = torch.tensor(batch[1])\n",
    "            list_logP = torch.tensor(batch[2])\n",
    "            list_logP = list_logP.view(-1,1)\n",
    "            list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "\n",
    "\n",
    "            list_pred_logP = model(list_feature, list_adj)\n",
    "            val_loss = args.criterion(list_pred_logP, list_logP)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "        \n",
    "    list_val_loss.append(epoch_val_loss/len(data_val))\n",
    "    \n",
    "data_test = DataLoader(args.dict_partition['test'],\n",
    "                       batch_size=args.batch_size,\n",
    "                       shuffle=args.shuffle)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logP_total = list()\n",
    "    pred_logP_total = list()\n",
    "    for i, batch in enumerate(data_val):\n",
    "        list_feature = torch.tensor(batch[0])\n",
    "        list_adj = torch.tensor(batch[1])\n",
    "        list_logP = torch.tensor(batch[2])\n",
    "        logP_total += list_logP.tolist()\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "\n",
    "        \n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        \n",
    "        pred_logP_total += list_pred_logP.tolist()\n",
    "    \n",
    "    mse = mean_squared_error(logP_total, pred_logP_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAESCAYAAADnvkIDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3XlcVPX++PHXmXNmhllAFkEwxTXcwEytWxlamZWmtz3J5Hp/XbOb1e2m2eL1qqlXsbIsy6xbXytLs5vdbL2VLWqUVhYlLli576yyzMBs5/cHOkgiIjCMA+/n48EDZuYs7/MB5j3nsyq6rusIIYQQv2MIdgBCCCHOTJIghBBC1EgShBBCiBpJghBCCFEjSRBCCCFqJAlCCCFEjSRBiHrZu3cv5557brDDOC3dunVjxIgRXHPNNdW+9u7dG5BzFRQU1Gnb1atX8+STTwLwzDPPsGrVqkaPJ1DS09P53//+d8rtvF4vd9xxB/n5+U0QlWgsWrADEKIpvfLKK0RHRwc7DL/S0lIef/xx3nzzTQDWr19P165dgxxV41NVlbFjx/LII4/w9NNPBzscUUeSIESjKykp4ZFHHmHr1q0oikJqaioTJkxA0zSefvppPv30U4xGI1FRUcyZM4e4uLiTPn/8MQcNGsTHH39MbGwsADfddBN33303NpuNjIwMfD4fAHfccQdXXnnlacW8fv16Hn/8cdq2bcv27dsJCwsjIyODLl261Ho9P/30E7NmzcLpdGI0GnnggQe48MILAViwYAE//fQTRUVF/OUvf+HWW2894bxLly7l4osvxmKx8Prrr5Odnc2jjz6KqqpccMEFNZ53165dpKWl8eqrr9KjRw8eeOABNE3joYceIj09/YRzXHXVVdx5552kpKQwbtw4MjMzOXz4MGPHjmXUqFG8/fbbvPXWWzidTux2O0uWLKm2v8PhYPr06ezatYuioiJsNhuPP/44nTt3BuCzzz7jpZdeIi8vjwsvvJBZs2axf/9+br31Vrp06cK+fftYsmQJ5513HtOmTWPLli306NHjtH4/Ikh0Iephz549ep8+fWp87YEHHtBnzpyp+3w+vaKiQr/tttv0559/Xt+/f7/et29fvaKiQtd1XX/ppZf0Tz/99KTP13TcF198Udd1Xf/111/1Sy65RPd6vfqf/vQn/f3339d1Xde3bNmiT58+vca4kpKS9OHDh+t//OMf/V/jx4/XdV3X161bp3fv3l3/7rvvdF3X9aVLl+rXXXddrdfjcrn0AQMG6F988YWu67q+ceNGffjw4brX69WTkpL0l156Sdd1Xd+0aZOenJysu1yuE2K67rrr9HXr1vkfjx49Wv/oo49qPa+u6/ry5cv1ESNG6G+++aY+YsQI3el01njNv7/+JUuW+GNNTk7Wy8vL9RUrVujnnXeeXlJSUuN+H330kT5z5kz/43/+85/6jBkz/PHeeeedusfj0R0Ohz5gwAD9u+++0/fs2aMnJSX5y/OYmTNn6k899dQpYxVnBrmDEI1uzZo1LFu2DEVRMJlMpKWl8corrzB27Fi6d+/Oddddx8CBAxk4cCAXXnghPp+vxud/76abbuKRRx7hL3/5CytWrOCGG27AYDAwdOhQZsyYweeff85FF13EhAkTThpbbVVM3bt3p3///gDccMMNzJgxg8LCwpNez4ABAzAYDFxyySUAJCcn89577/mPN3z4cAB69OiBy+WitLSUqKioaufcsWMHHTp0OK1yHDduHDfffDNfffUVs2bNYuXKlYSFhVFcXFzrHQTA4MGDAejVqxculwuHwwFUtpnY7fYa47jqqqto3749S5YsYdeuXXz77bfV2p+GDRuGqqpYLBY6duxIfn4+8fHxaJpGnz59qh2rXbt2/PTTTzWeR5x5JEGIRufz+VAUpdpjj8eDwWDgtddeY+PGjXzzzTfMnj2b1NRUHnjggZM+f7z+/fvj8Xj4+eefef/991m+fDkAaWlpXHrppWRmZrJ27VqeeeYZ/ve//2E2m08rblVVa3zuZNejqmq15wG2bdvmr3rRtMp/r2Pb6DVMe6Yoir9q7PdOdl4Al8vFrl27CA8PZ8uWLXTs2JGIiAhWrlxZ6zUeK5Pfx2S1Wv3b/OMf/yA7OxuoLFtd13nzzTe59dZbGTFiBJGRkdUa9o9d57HjHjumyWSq9tqxbQ0G6RsTKuQ3JRrdxRdfzGuvvYau67hcLt58800uuugitm7dyvDhw+nSpQt33HEHf/7zn9m4ceNJn6/JTTfdxMyZM+nWrRsJCQlA5ZvYli1buP7665k5cybFxcXk5uaedtxbt25l69atACxfvpxzzz2XiIiIk15P586dURSFzMxMADZt2sSYMWNO+oZfk44dO7J7927/Y1VV/UngZOcFePTRRzn77LN56aWXmDVrFvv27Tvt6z2Zf/3rX6xcuZKVK1dyyy238NVXX3Hddddx00030alTJz7//HO8Xm+9jr13715/AhVnPrmDEPXmcDhO6Or6xhtvMGXKFGbNmsWIESNwu92kpqby17/+FZPJxNChQ7nhhhuwWq2EhYUxZcoUunfvXuPzNbn22mt54okneOKJJ/zP3X///cyePZv58+ejKAp333037dq1q3H/MWPGnPAJdsKECYSFhdG6dWvmz5/Pvn37iI6O5tFHHwWo9XoWLFjA7NmzefTRRzEajSxYsACTyVTnMrzqqqtYu3YtF1xwAQCXXXYZTzzxBG63+6Tn/fLLL/n000957733iIiIYMyYMUycOJHXXnvthE/sjeG2225j6tSpvPXWWwD06dOHbdu21etYmZmZzJ8/vzHDEwGk6DXd9wrRwqxfv56ZM2fy/vvvN+l5S0tLufnmm1mxYgUWi6VJz93U1q9fz+uvvy7dXEOIVDEJEUR2u50JEybw3HPPBTuUgPJ6vbz44osnvTMUZya5gxBCCFEjuYMQQghRI0kQQgghahTSvZi8Xm+9u9upqlrvfZsbKYvqpDyqk/Ko0hzK4nR62YV8gqjv7JAxMTEys+RRUhbVSXlUJ+VRpTmUxbHxQ3UhVUxCCCFqJAlCCCFEjSRBCCGEqFFIt0EIIYLL6/VSXFzsnz+qucvPzz+tubaCSdM0IiIiapyEss7HaMR4hBAtTHFxMWazmcjIyBNmtm2OQqUXk67rOJ1OiouLT5hi/nRIFZMQot48Hg8Wi6VFJIdQoigKFoulwXd2kiCEEA0iyeHM1Bi/lxaZIL7afoQDR8qDHYYQQpzRWmQbxLwv9zBgr5P7B8YHOxQhRAMsXLiQnJwcCgoKqKioICEhgcjISB555JFT7vvLL7/w9ddfM2bMmFNuu3jxYqKjo7n++usbI+yQ0SITRNfWFn7ccwSQBCFEKBs/fjwAH330Ebt37+aOO+6o875nn302Z599dqBCaxZaZIJITrDx1Y79HCn30CqsRRaBEI3uwy35vL+pcaehGN4rhmE9Yk57vx9//JEXXngBTdMYMWIEJpOJd955x79e9iOPPMKOHTt49913mTZtGrfeeivJycns2bOHqKgoZsyYUafuocuXL+fzzz9HVVXOOecc7rjjDjZu3MjChQvRNI3w8HCmTJlCfn4+GRkZaJqGqqo8/PDDxMbGnvZ1NbUW2QaRkmADYNOBsiBHIoQIFJfLxYIFC7jiiivYu3cvGRkZPPXUUyQmJvLdd99V2/bAgQP85S9/YeHChRw5csS/Nnlttm/fzpdffsmzzz7Ls88+y969e/n666/56quvGDhwIE899RRDhw6lpKSE77//nqSkJObNm8fo0aMpKSkJ1GU3qhb58blHGyuqQWHjgTIu6tQq2OEI0SwM61G/T/uB0r59e//PkZGRzJkzB4vFwu7du+nZs2e1bVu1akVcXBwAsbGxuFyuUx7/2HGOrQPeu3dvdu7cyejRo1myZAkTJkygdevW9OzZk2HDhrFs2TIeeOABbDYbY8eObcQrDZwWeQdhMar0iLezUe4ghGi2jnXzLC0t5eWXX2bq1KlMmjQJs9ncKMdPTExk8+bNeDwedF3np59+on379nz66adcddVVzJ8/n06dOvHee++RmZlJ7969eeKJJ7jkkktYtmxZo8QQaAG5g/D5fEyfPp2cnBxMJhOzZs2iQ4cO/tdff/113n77bRRF4a677uLSSy9F13UGDhxIx44dAejTpw8TJ04MRHiVx28fyYof9uHx6WgG6cctRHNls9lITk5m3LhxhIWFER4eTl5eHvHxp9dJZenSpXz44Yfouo7VamX+/Plceuml3HPPPfh8PlJSUrj44ovZsmULGRkZWCwWNE3j/vvvx+fz8a9//QtVVTEYDNx1110ButrGFZA1qT/55BM+//xzMjIyyMrK4vnnn/cvyl5QUEB6ejrvvPMOFRUVXH311Xz55Zfs3r2bOXPmsGjRojqfx+Vy1Xtu9m/2uZjwVjavjOpOUqy1XsdoLprDHPeNScqjutrKIzc3NyQaWxtLqEy1cUxNv5+grwexYcMGUlNTgco7gezsbP9r0dHRrFy5EqPRSF5eHhERESiKwqZNmzh06BDp6encfvvtbN++PRCh+fVpHwlAtlQzCSFEjQJSxVRaWordbvc/VlUVj8fjb8zRNI3XXnuNBQsWkJ6eDlQ2DI0bN46hQ4fy/fffM2nSJFasWFHreVRVJSamfo1iqqoSazeRU+Cp9zGaC03TWnwZHE/Ko7rayiM/P79Bs4WGGkVRQup6DQZDg/6WA5Ig7HY7ZWVVn8x9Pp8/ORwzevRobr75Zm6//XbWrVvHOeec4y/4/v37c+jQIXRdr3U+kYYuOdqrjZUNOwtafHWCVKlUJ+VRXW3l4fP5QqrKpaFCrYrJ5/Od8LsLehVT3759WbNmDQBZWVkkJSX5X9u+fTt33303uq5jNBoxmUwYDAaeeeYZXnnlFQC2bt1K27ZtAz4JWHKCjX1HKihwuAN6HiGECEUBuYMYMmQImZmZpKWloes6s2fPZvHixSQmJjJ48GC6d+/OyJEjURSF1NRUzj//fLp168akSZNYvXo1qqoyZ86cQIRWzbEBc9kHyhjYJTLg5xNCiFASkF5MTaUhvZhiYmLYfyiXy5/7ibRz47jr4rMaObrQIVUq1Ul5VCe9mKqEWhXTGdmLKVSYNQPd4izSk0mIEPW3v/2NH374odpzCxYs4P33369x+wMHDnDnnXcClfMxud3Vq5fXr19fa+1FRUWF/9gfffQRmZmZ9Y79+FjOVC06QQCkJNjZfKgMjzdkb6SEaLGGDx/Oxx9/7H/sdrv5+uuvGTx48Cn3nTZtGkaj8bTOV1BQwAcffADA0KFDGTBgwOkFHGJa5FxMx0tOsPHGj4fZluugZ7wt2OEIEdKi302v8fmCPy4BICJzNlr+lhNeL75oMp7WPbDkvI0l578n7HcygwYN4qWXXqK8vJywsDAyMzPp378/FouFrKwsf8eX8vJyJk+eXK035ciRI3n11Vc5ePAgc+fOJSwsDIvF4u+i//bbb7N27Vo8Hg82m42ZM2fy6quvsmvXLl555RV8Ph/R0dFcc801LFy4kI0bNwIwePBgbrzxRubMmYPJZOLgwYPk5+fz0EMPVeuwczK//PILTz31FKqqYjKZuP/++/1rXJSVlVFRUcEdd9zBueeey5w5c9i/fz8ul4uRI0dy2WWXnfL4p0PuII4mheyDUs0kRKgxm80MGDCAtWvXApXVPiNGjABg586d/OMf/+DJJ59kwIABfPnllzUe46WXXuK2227jiSeeoFevXkBl99Di4mLmzZvHggUL8Hq9bN26lT/96U906NCh2iJDX3/9NQcOHGDhwoUsWLCAzz77zD/Qt02bNjz22GNcf/31vPfee3W6pscee4x7772Xp556imuuuYZnn32W/fv3U1BQwOzZs5kyZQoVFRU4HA6ysrKYOXMmc+fOxefz1bcYT6rF30HEhZtoYzey8UAZN/cJdjRChLZTfeIvHjC51ted3a7H2e30Vm0bPnw4zz33HOeeey4lJSX+T+mtW7fm6aefxmKxkJeXR3Jyco3779y5k+7duwOQnJzMrl27MBgMGI1GZs6cicViITc3F4/HU+P+u3fvpnfv3iiKgqZp9OzZk507dwL4FySKjY3132GcSn5+vn+/c845hxdeeIFOnTpx7bXXMnPmTDweD9dffz1Wq5V7772Xxx9/HIfDwZAhQ+pcZnXV4u8gAFLa2qWhWogQ1blzZ5xOJytWrGDYsGH+5x977DEeeughHn74YVq3bn3S/RMTE9m0aRMAOTk5APz222989dVXTJs2jb/97W/+T+cGg4Hfd/xMTEz0v/l7PB6ys7Np165dva8nJiaG3377DagcR9a+fXu2b9+Ow+EgIyODhx9+mKeffpr8/HxycnKYNWuWfx67kyWx+mrxdxAAyfE2Vm0r5HCpizi7KdjhCCFO09ChQ1m0aBHLly/3P3fFFVdw5513Eh4eTlRUFHl5eTXue9999/HII4+wfPlyWrVqhclk4qyzziIsLIxx48ZhMpmIiYkhLy+PlJQU3G43zz//PCZT5XvFRRddRFZWFuPHj8fj8XDJJZfUqa0BYMeOHYwbN87/ePz48UyaNImnnnoKXddRVZUHHniAmJgYXn75ZT755BM0TeO2224jOjqagoICxo4di8ViYeTIkSfMWNFQLXocxLF9Nx0sY+zyHP41rBOXnR3VmCGGBOn3X52UR3UyDqKKjINogZJiLZhURaqZhBDiOJIgAKNqoEcbq6wwJ4QQx5EEcVRKgp2cXAcVnsbvKiZEcxbCtdTNWmP8XiRBHJWcYMPt1ck57Ah2KEKEDE3TcDqdkiTOMLqu43Q6G9xoLb2Yjjp+wFzvtvZTbC2EAIiIiKC4uLja+i/NmcFgCMiAtEDQNI2IiIiGHaORYgl50TYjZ7UySUO1EKdBVVWiolpOz7+W1sNNqpiOkxxvY+OBMrldFkIIJEFUk5JgJ6/MzcESV7BDEUKIoJMEcZzkoyvMSXdXIYSQBFFNl9YWLEaDtEMIIQSSIKrRDAo9ZcCcEEIAkiBOkJxg45c8B+Xu0OjKJoQQgSIJ4ndSEux4fbDlsNxFCCFaNkkQv5N8dMDcxv2SIIQQLZskiN9pZdFIjDLLEqRCiBZPEkQNUmTAnBBCBCZB+Hw+pk6dysiRI0lPT2fXrl3VXn/99de54YYbuPHGG/niiy8AKC8v55577mHUqFHcfvvtFBQUBCK0Oklpa6fI6WHvkYqgxSCEEMEWkASxatUqXC4Xy5cvZ+LEiWRkZPhfKygoYOnSpbzxxhu8/PLLTJ8+HV3XWbZsGUlJSSxdupRrr72WhQsXBiK0OvG3Q0h3VyFECxaQyfo2bNhAamoqAH369CE7O9v/WnR0NCtXrkTTNPbt20dERASKorBhwwbGjh0LwMCBA+uUIFRVJSYmpl4xapp20n2jonTs5l/4tdBb7+OHktrKoiWS8qhOyqNKSyuLgCSI0tJS7PaqKbNVVcXj8fjnJtc0jddee40FCxaQnp7u3yc8PBwAm81GSUnJKc/j9XobZU3qmvRqY+H7HfktYubGljZD5alIeVQn5VGlOZRF0Nekttvt1eaH9/l8JyxcMXr0aNauXct3333HunXrqu1TVlbW4HnMGyo5wcZv+U7KXKGzQLkQQjSmgCSIvn37smbNGgCysrJISkryv7Z9+3buvvtudF3HaDRiMpkwGAz07duX1atXA7BmzRr69esXiNDqLCXBjk+HzdLdVQjRQgWkimnIkCFkZmaSlpaGruvMnj2bxYsXk5iYyODBg+nevTsjR45EURRSU1M5//zzSUlJ4cEHH+SWW27BaDQyb968QIRWZ73ibShUNlSflxjcuxkhhAgGRQ/hzv4ulytgbRAAt762mTZ2E09c27Ve5wgVzaFetTFJeVQn5VGlOZRF0NsgmouUBBvZB8vwhW4OFUKIepMEUYvkeDslFV52F5YHOxQhhGhykiBqkdJWBswJIVouSRC1SIw0ExGmSoIQQrRIkiBqoSgKyfE2WYJUCNEiSYI4hZQEGzsKyiku9wQ7FCGEaFKSIE4hOaFyypBNMmBOCNHCSII4hZ5trBgUaagWQrQ8kiBOwWpS6dLaIu0QQogWRxJEHaQk2Nh0qAyvTwbMCSFaDkkQdZCSYMPh8rEj3xnsUIQQoslIgqiDlKMN1RuloVoI0YJIgqiDthEmoiyaNFQLIVoUSRB1oChK5cR9kiCEEC2IJIg6SkmwsaeogiKnDJgTQrQMkiDq6NiAuY0HSoMciRBCNA1JEHXUvY0V1YBUMwkhWgxJEHUUphlIirVKQ7UQosWQBHEaUhJsbDnkwOOVAXNCiOZPEsRpSEmwUe7x8WueDJgTQjR/kiBOQ3L8sQFz0lAthGj+JEGchjbhRmLtRmmoFkK0CJIgTsOxFeakoVoI0RJogTioz+dj+vTp5OTkYDKZmDVrFh06dPC//vLLL/PBBx8AMGjQIO6++250XWfgwIF07NgRgD59+jBx4sRAhNcgKQk2vvi1iLwyN61txmCHI4QQAROQBLFq1SpcLhfLly8nKyuLjIwMnnvuOQD27NnDu+++y3/+8x8URWHUqFFcfvnlWCwWevXqxaJFiwIRUqM5NnFf9oFSLukaFeRohBAicAJSxbRhwwZSU1OByjuB7Oxs/2vx8fG8+OKLqKqKwWDA4/FgNpvZtGkThw4dIj09ndtvv53t27cHIrQGS4q1YFQVqWYSQjR7AbmDKC0txW63+x+rqorH40HTNIxGI9HR0ei6zqOPPkrPnj3p1KkTeXl5jBs3jqFDh/L9998zadIkVqxYUet5VFUlJiamXjFqmlbvfVPaRrA1t6Le+59pGlIWzZGUR3VSHlVaWlkEJEHY7XbKyqo+Yft8PjSt6lQVFRVMnjwZm83GtGnTAEhOTkZVVQD69+/PoUOH0HUdRVFOeh6v10t+fn69YoyJian3vt1izaz4KZeDh3MxqqHfzt+QsmiOpDyqk/Ko0hzKIiEhoc7bBuTdrW/fvqxZswaArKwskpKS/K/pus748ePp1q0bM2bM8CeFZ555hldeeQWArVu30rZt21qTQzD1TrDh8upsy5UBc0KI5isgdxBDhgwhMzOTtLQ0dF1n9uzZLF68mMTERHw+H99++y0ul4u1a9cCMGHCBMaNG8ekSZNYvXo1qqoyZ86cQITWKI7N7Prz/lJ6xduCHI0QQgRGQBKEwWBgxowZ1Z7r0qWL/+eNGzfWuN8LL7wQiHAaXWubkYQIE9myBKkQohkL/Qr0IJEBc0KI5k4SRD2lJNjILXVzqMQV7FCEECIgJEHUU4qsMCeEaOYkQdRT19YWzJoMmBNCNF+SIOpJUxV6trHJzK5CiGZLEkQDJCfYyMl1UO7xBTsUIYRodJIgGiAlwYbXBzmHHMEORQghGp0kiAZIPjpIThqqhRDNkSSIBoiyGmnXysxGGTAnhGiGJEE0UEpbGxv3l6HrerBDEUKIRiUJooGS420UOj3sL5YBc0KI5kUSRAP1Tqhsh5DurkKI5kYSRAN1irFgNRn4WRqqhRDNjCSIBlINMmBOCNE8SYJoBCkJNn7Nc+JweYMdihBCNJo6JYjvvvuONWvWsHr1ai6//HLee++9QMcVUlISbPh02CID5oQQzUidEsRjjz1Gx44defXVV1m2bBlvvPFGoOMKKb1kwJwQohmqU4Iwm83ExMSgaRqxsbG4XNKl83gRYRodo8NkZlchRLNSpwRht9v5f//v/zF06FBef/11EhISAh1XyElJsJF9UAbMCSGajzqtSf3UU0+xe/duunbtyi+//MJNN90U6LhCTnK8jfc25bO7qIIOUWHBDkcIIRqsTncQu3btoqSkhJ9++olZs2axYcOGQMcVclJkwJwQopmpU4KYNm0aJpOJ5557jvvuu49nnnkm0HGFnA7RYYSbVWmoFkI0G3VKEJqmcfbZZ+N2u+nTpw9er/T3/z2DotAr3iYN1UKIZqNObRCKojBx4kQGDhzIhx9+iMViqXV7n8/H9OnTycnJwWQyMWvWLDp06OB//eWXX+aDDz4AYNCgQdx9992Ul5czadIk8vPzsdlszJ07l+jo6AZcWtNLSbDx4rpiSiu82M1qsMMRQogGqdMdxJNPPsmNN97ImDFjiImJ4cknn6x1+1WrVuFyuVi+fDkTJ04kIyPD/9qePXt49913eeONN1i+fDlfffUVW7duZdmyZSQlJbF06VKuvfZaFi5c2LArC4LkBBs6sEnWhxBCNAN1ShAmk4l169Yxbtw4Pvvss1Nuv2HDBlJTUwHo06cP2dnZ/tfi4+N58cUXUVUVg8GAx+PBbDZX22fgwIF888039bmeoOrVxoaCNFQLIZqHOlUxTZ48mfPOO48//vGPfPvttzz00EMsWrTopNuXlpZit9v9j1VVxePxoGkaRqOR6OhodF3n0UcfpWfPnnTq1InS0lLCw8MBsNlslJSUnDIuVVWJiYmpyyWcQNO0eu97MjFAUhs7W/NcjX7sQApEWYQyKY/qpDyqtLSyqFOCKCwsJD09HYAePXrw8ccf17q93W6nrKzqU7TP50PTqk5VUVHB5MmTsdlsTJs27YR9ysrKiIiIOGVcXq+X/Pz8ulzCCWJiYuq9b216xIbx6bYCcvPyMChKox8/EAJVFqFKyqM6KY8qzaEsTmegc52qmCoqKsjNzQUgLy8Pn89X6/Z9+/ZlzZo1AGRlZZGUlOR/Tdd1xo8fT7du3ZgxYwaqqvr3Wb16NQBr1qyhX79+db6IM0lKWxtlLh878suDHYoQQjRIne4g7r33XtLS0ggPD6e0tJQ77rij1u2HDBlCZmYmaWlp6LrO7NmzWbx4MYmJifh8Pr799ltcLhdr164FYMKECdxyyy08+OCD3HLLLRiNRubNm9fwqwuClKMT92UfLKNL69p7ewkhxJlM0U9j8qCCggKioqK46aabeOuttwIZV524XK4zropJ13WG/XsjAzq1YsqQDqfe4QzQHG6bG5OUR3VSHlWaQ1mcThVTne4gjjk2LkEmpDs5RVFIjrfJiGohRMir14pySog0vgZLcoKN3YUVHHF6gh2KEELUW613EBMmTDghGei6zp49ewIaVKhZEV4zAAAgAElEQVTzT9x3sIwBnVoFORohhKifWhNEWlraaT0vKvVoY0VVKgfMSYIQQoSqWhPE+eef31RxNCsWo8rZsVZphxBChLR6tUGIU0tOsLH5kAOPTxr0hRChSRJEgKQk2HC6fWzPdwY7FCGEqBdJEAFyrKF6436ZuE8IEZokQQRIfLiJGKtGtkz9LYQIUZIgAkRRFFIS7NJQLYQIWZIgAig5wca+Iy4KytzBDkUIIU6bJIgA8rdDSDWTECIESYIIoG5xVjSDIivMCSFCkiSIADJrBrrFWSRBCCFCkiSIAEtJsLP5UBlub+2LLAkhxJlGEkSAJSfYcHl1fsmVAXNCiNAiCSLAjq0wt1GqmYQQIUYSRIDFhZtoYzfKgDkhRMiRBNEEUtra2bhfBswJIUKLJIgmkBxv41Cpm8OlrmCHIoQQdSYJogkkH1thTtohhBAhRBJEE0iKtWBSFWmoFkKEFEkQTcCoGujRxip3EEKIkCIJoomkJNjZethBhUcGzAkhQkNAEoTP52Pq1KmMHDmS9PR0du3adcI2BQUFXHHFFVRUVACg6zqpqamkp6eTnp7OvHnzAhFa0CQn2PD4dHIOO4IdihBC1IkWiIOuWrUKl8vF8uXLycrKIiMjg+eee87/+tq1a5k3bx55eXn+53bv3k2vXr1YtGhRIEIKumMD5rIPltG7rT3I0QghxKkFJEFs2LCB1NRUAPr06UN2dna11w0GA4sXL+aGG27wP7dp0yYOHTpEeno6YWFhPPzww3Tu3LnW86iqSkxMTL1i1DSt3vvWR0wMtI/6lZx8d5Oety6auizOdFIe1Ul5VGlpZRGQBFFaWordXvUpWVVVPB4PmlZ5ugEDBpywT2xsLOPGjWPo0KF8//33TJo0iRUrVtR6Hq/XS35+fr1ijImJqfe+9dUzLozvdxaQl5eHoihNeu7aBKMszmRSHtVJeVRpDmWRkJBQ520DkiDsdjtlZVU9dnw+nz85nExycjKqqgLQv39/Dh06hK7rZ9QbaUOlJNj5OKeQgyUuEiLMwQ5HCCFqFZBG6r59+7JmzRoAsrKySEpKOuU+zzzzDK+88goAW7dupW3bts0qOUDVgDkZDyGECAUBuYMYMmQImZmZpKWloes6s2fPZvHixSQmJjJ48OAa9xk3bhyTJk1i9erVqKrKnDlzAhFaUHVpbcFiNLDxQBlXdIsOdjhCCFErRdd1PdhB1JfL5QqpNgiAu1dso8zlY/Et3Zv83CfTHOpVG5OUR3VSHlWaQ1mcThuEDJRrYskJNn7JdeB0e4MdihBC1EoSRBNLSbDj1WHLIRkwJ4Q4s0mCaGLJ8TKzqxAiNEiCaGKtLBqJUWbpySSEOONJggiClHgb2QfLCOH+AUKIFkASRBCktLVT5PSwt6gi2KEIIcRJSYIIgmPtEBsPSjWTEOLMJQkiCDrFhGEzGZq+oVrXUSqKwe0EQMvPwZb1EoZ1z4KnvGljEUKc8QIyklrUzqAoJMfbGq+hWtdRKopQHbkYHLm44vuDZsay9S3Me9b6n1fLDqN4Kygc/DjlXYdjPPwTEesfAyCy09cUDZkPinxmEEJUkgQRJMkJNhZ/e5CyCi82s1rzRroPQ3kRBsdh1LJcDI7DKB4njuTRAER+8jeMudmojlwUn9u/2+GbP8Qb1RmtaAfGgm14rXG4486h3BqLzxaHO6YnAM6uIyjvMozWuz/E8tlUvOseo+TCBwN+7UKI0CAJoin5vKD7QDXSJ9ZAT7bz9efbuSzBQytvAQbHYbzhZ1HW53aUihLavHohis9T7RC6asbR61ZQFHy2OFzaefissXiPvvl7rbF47ZVD6UsumETJBZNOHo/Rgg74zv8rZQdzsP+8GE+rjjh7jgxgIQghQoUkiJPxeVDcDv+XwVOG4nbgSjgfFAXzzs/RindX20bxlFHW53Y8UV2xbHkTW/brKJ6j+7vLUDzllPS7m9L+d9PftJMR5imwm8ovoMLYChIrF1rSTXZKzxmLzxpzNAHE4bPG4bW2hqOz3BYPmNI416ooFF80GRQDrrMubJxjCiFCXotMEOqRXaiZ/ySqtPDom3sZiseBJ7IzRUOeAiD+pT4nfHoHODD2Z1BN2Da9jnlvJgC6akI3WvFpVpzdboQo0E3heCPa4zNa0Y1WdK3yu6vt+QAosd0ouPJZ9rnD+XiPxorf4EAJRG7XuHL1Xob3iqHr+X9vukIxqBQP+EdlbG4HaukBPFFdmu78QogzTouczVXLz6H1qnvxGMyVb95GKz6jFU9UV0rPuxcAW9a/wWCs/gZvsuGK7wcGDaW8EBQVXbOAamzwtXh8Out3FfPB5nzWbj+Cx6fTPc7K8J4xDOkWRURY4HL572eojPzkb5gO/kD+dcvxhp8VsPOeqZrDjJ2NScqjSnMoi9OZzbVFJgg4s3/RRU4PH28t4P3N+fya58SkKgzqEsnVPWPo3z4c1dC4Cyn9viy0wl+JeecWvLY25F+zFN0c0ajnO9OdyX8bwSDlUaU5lEXQlxwVDRNp0Rh5bhw394llW66T9zfn8/HWAj7dVkic3ciwnjFc3SOGdpGBWbbUE9WVwisWEP3h7UR9cg8Fw/4Nqikg5xJCnLnkDiJEVHh8rN1+hA8257N+VzE60OcsO8N7xnDZ2ZFYjCfpKlsHJysLy7aVRH7xII6kazhySYa/cby5C7W/jUCT8qjSHMpC7iCaIbNm4PKkKC5PiuJwiYsPtxTwweZ8Zn26iye+3MPgpCiu7hlD7wRbo63l7Uy6BrVkH+qRXeDzNEpbixAidEiCCEFx4Sb+fH48Y85rw8/7y3hvcz6rthXy3qZ8EiPNXN0zhqE9oom1N7xaqLTvnZU/KAqKqxTdZG/wMYUQoUHmVQhhiqJwzll2pgzpwPtjU5gypAPRViPPfb2fa/8vm4krf+XzXwpxeXwNOQkoCsZDWcQtuxzT3m8a7wKEEGc0uYNoJqwmlat7xnB1zxj2FJbzwZZ8PtxSwD8+3EGrMJUru0dzdc8YkmKt9Tq+J7ILXkssUZ/eQ/41S/FEJzXyFQghzjTSSN2MeX063+0p4f1NeazZfgS3Vycp1sLwnjFc0S2aVpbKzwd1LQtDyX5avzMS3WAk/9o38NniAn0JQdES/jZOh5RHleZQFjIOog6awy/6dBwp9/BpTiHvb84j57ATo6qQ2rkVw3vGMPTcThQVFtTpOFreZmJWjsYb2ZH8Py5BN9oCHHnTa2l/G6ci5VGlOZRF0BOEz+dj+vTp5OTkYDKZmDVrFh06dKi2TUFBAWlpabz33nuYzWbKy8uZNGkS+fn52Gw25s6dS3R0dK3nkQRRP7/kOvxjK46Ue4m1m+jVxkr3Nla6x1V+Hbu7qIl592qiPr2Xgiufw9Wu+c3d1JL/Nmoi5VGlOZRF0Lu5rlq1CpfLxfLly8nKyiIjI4PnnnvO//ratWuZN28eeXl5/ueWLVtGUlIS99xzDx988AELFy5kypRGmoxOVHN2rJX7Blm5++KzyNxxhMzdTrJ2F/Llb0X+bRIiTHSPs9KjjZVuR5PGsek+KhIHcfiWVfisrYN1Cc2P7vOvxWHZ9g7GQz/hOusCyjtfGeTAREsWkASxYcMGUlMrZyXt06cP2dnZ1V43GAwsXryYG264odo+Y8eOBWDgwIEsXLjwlOdRVZWYmJh6xahpWr33bU5uiItl5AANj8dDsdPNpgMlZO8rJvtAMdn7ivni16qk0T7KQvJZEaS0jaBX21h6WWxErctAt8bgu+DuIF5F4wr034ay/weU/F9Q8n9Fyf8F8n9DKdqJ++9bwWRD2/slyo7V2DYvw3vRvXgHTQ7qQk7yv1KlpZVFQBJEaWkpdntVf3lVVfF4PGha5ekGDBhQ4z7h4eEA2Gw2SkpKTnker9crVUyN4PiySGoFSa3Cub5nOHAWR8o95Bx2sPWQg62HHWTtLuSj7EMAKPj4t/VHLvdl8t4uMHQfTrdY68kXQAoRDf7b8HlRS/ahHdmBVrQdtWgHiqeCI5fNBSDurT+jlh5AV1S8rRLxtOqE56wBlOYdQje3goFzYZCBVl/NwPr1U7gObObIpXPRjfXrgdZQ8r9SpTmURdCrmOx2O2VlVctp+nw+f3Koyz5lZWVERLSsCeLOVK3CNM5PjOD8xKrfR5GzMmlsOeRg+aFJxB7I54pfZzNqM2zQu5EYZfa3ZXRvYyUp1orNFNpJoyZKRTFa0Q60IzvQDSbKuw5DqSimzasDqq3w5wuLxB2dBLoOikLh4Hn4wiLxhreveXS6VjnH1pGBM3BHdSVi3VzcG1+lrO9fm+rShAAClCD69u3LF198wbBhw8jKyiIp6dR95vv27cvq1avp3bs3a9asoV+/foEITTSCSIvGHzpE8IcOEUA8inMx/DeNpeXz+b+uz/DNkTCy9pXySU4hAArQITqsKmnEWUmKszRo/qgmc/RuAMWAN6IdWuFvRKydhla0E9VZ1Ybmik2mvOswdHMEpX3G4g1vhyeyE55WndAtUdUO6Y7vW7dzKwqO3mNwxybjjutd+ZS7rFn2HBNnpoD2Ytq2bRu6rjN79mzWrFlDYmIigwcP9m932WWX8dFHH2E2m3E6nTz44IPk5uZiNBqZN28esbGxtZ5HejE1jsYoC/XILmLeScPduheFV78IQEGZm62HHWw5rooqr6zyk7VBgY7RYXSLs9IjrrIhPCnWSpgxuIP7jbkbiTqYievAJrSinWhHdqL43Di638iRQbMwlB4katV9eCI7VyaAyM54Ijue/G6gEWl5W4j+4DaKL55KeZehAT3X8eR/pUpzKIugd3NtKpIgGkdjlYWWuwmfPQGf5eTdk3NLXWw97PBXUW097KDAUblyn0GBDlFhJMVaSDqaMJJiLQFdLAkAXUfxONCNNsy71xD18Xi8Ee0r3/xbdcIT2Ql3bDKemG6BjeMUDM58oj65B9PBHyjpfw+lfcc3yQy78r9SpTmUhSSIOmgOv+jG0thlYXDkYd20lNL+d5+y942u6+SWuf13GNtyHWzLdZJbWlWHHx9uIinO4k8Y3eKsxNqMDZ+1Vtcx7fua8A3P4jNFUDh0Eeg6Ma1s5Bc7GnbsQPG6aLXmn1i3rcTZZRhFl8wGLSygp5T/lSrNoSyC3kgtWjbzzs8I/2EhireCkgsm1bqtoijE2U3E2U0M7BLpf77Q4WZbrtOfMLYddrD2tyMc+zQTZdEq7zRirf7k0S7SjKEuSUPXMe3NJHzDM5gOZeG1tcF57nB/IzJGC3CGJgjVxJFLMvBEdSV8/RNEO3IpGPFqi1mrQzQtSRCi0Tl73IyxIAf7Ty/hDW+Ho9ctp32MKKuRP3QwHm0Ir1Tm8vLr0aSRc/T7sh8P4/FVpg2r0UDX1pXVU92OJo5O0WEY1ePuYnSdqI/GEbZnLV57Akcunoaj+w2htWKeolDW53Y8rTpV9paS5CACRBKEaHyKQvFFk1FL9hOROROvPYGKDpc0+LA2k8o5Z9k556yqMTZur4/t+eXV7jQ+2JzPW+5cADSDQudoM9fYN6O260fHhFj6tU2louNgHN2uD63E8DsVnS73/xy+fh6uuHOqPSdEQ0mCEIFh0Ci6fB4x76YTuWoCeTf+F2+rDqfe7zQZVQPdjvaCOsbr09l7pIJth8pgx5dcuP8Vzi7dxsw9o8nwDkMhmfZRZrrt2ndcNZWVyFrmnzqjuZ2Y9q/HlvUiJX+YQNk5Y+WuQjSKEP2PEKFAN9oouGoRll/exRvRvsnOqyqQdORr+m5eiCk3G0/4WRT1eYRr2g6nW4Hbf6ex8UAZn24r9O8XZzeSFGula3weeFyYNQWzZiDMaCBMq/w69th89HG1nzUDmhqEN2ajhfwRrxL55WQi1s9DK/yVIwNnhvTdkTgzSIIQAeWzxVHWp3KOLeOB7/FEJ6GbAztK3piXTfTH4/GEt6No0CycZ18DqpFYIDYSUjtXNYYfcXqqqqeOfv9x3z6cbi++evTvUw1UJZIaEsiJCUbx/3x8MjJrBmLtRhIjw+o2NkQLo2jwPDxRXQj/fgFa8R4Kr3im1i7HQpyKJAjRJAzOAqI/vB133DkUDHuhcT/d6jrmnZ9h3rOW4tTpuGNTKLhqERXtBpxy8Fori8Z5iRGcd9xUIjExMeTl5eHx6ZR7fFR4dMrdvqM/+yh3H/1+7OvoY/9zbt2/7bHtyz0+iso9JzxX7vbhPUUiig830TE6jA5RYZXfo810jAoj0qJV7+qrKJT2uwtPZGfsP76AbgiBkerijCYJQjQJnyWa4tRpRH7xEK3WTOXIJXMaXk+u+zDv/IzwDc9izN+KJ6IDSnkRuiWqwY3iiqJgVBWMqoFwc8PCPBWPVz8h4ZR7fBwscbGroJxdheXsLCgna18p5cetLx4RplYljeO+J3S6ivJOV4BBxVB2CK1gG672qYG9CNEsSYIQTcaZdC1qyT7Cv1+AN7xd5UC6ejLvXk34+icwFuTgadWBokvn4ux6NRhC709aUxU0VT1hFtxe8dXnXPLpOodKXOwqrGBXQWXS2FVYzlfbj/Ces2rwlklVaB9ppkN0GPeUPs05hZ+wPeXvqP3/QlgznDRRBE7o/TeJkFbadzxq8V7CNzyDN/wsnN2uq/vOug+8LtDC0Ap+RfFWUHTpozi7DgvJxHC6DIpCQoSZhAgzF3So3o5zpNzjv9s4dsex7bCT0cU387iWz9CNT7D0xx9ZGDaOdjHhp66uEgJJEKKpKQpHBj6C4i7Da4uv2z66j7DtH2PfsJCKDpdQ8oeJlKWkU9b7zyD17EDltOy929rp3dZe7fkKj4+9heeQveFpRu16hX5qPpPL7mflPlPdqqsipCdUSyYJQjQ91UTRFU9X/qz7MDjy8NniTtzO561MDD8sxFj4K+7ILrhjk/3HEKdm1gx0ibXBVQ9TtK0XSav/wf/1z6G012gOl7jZWVh+yuqquHAzEWYDUVaNKIuRaKtGlNVIlEUjyqoRbal83MqioRnkLqQ5kQQhgiri6zmYd35G/rVvVE8Sbiet/3szxsJfcEd1pXDwE5XrM8sdQ705k/6IKzYZb2QnDIpCW7WQ+A5taqyu2n20mmp3YQUlHgMHi8rILXWTc9hJodON13fi8RUq70SirEeTiKV6IomyGP0JJdpqxGoySLXWGU4ShAgqR9K1WLauIPp/fyV/+CuYDnxLRYfLwGihInEgpf3GVyaGIK7J3Jx4ozoDYNq/nugPb6f4wodw9BpVbZtWYRopCXZSEiqrq34/g6mu65RUeCl0eih0eCh0uP0/Fxz38y95TgodJZRUeGuMxaQqJyaR4xNJteSiVZ9TSzQJSRAiqDyxvSga8iRR/7uTuNcGYvA4yR/2b1ztU085E6yoP3frXlScdRGtvpqBVvgrxRdNrnNDv6IoRIRpRIRpdIg69fZur48ip4dCp4eC3yWU43/eUVBOgcON6yQDQzSDgsV43Mh2owGLZvjdc2q1x5bjv/t/Viv3Pe44YZoBVarHTiAJQgRdReIgjgyciSXnvzhS0nG1GxDskJo93WSn8MpnCV8/D/vP/4d2ZBeFlz8ZkFHuRtVArN1ErP3U7Ua6ruNw+ShwuisTyNHkUeR043BXjhFxHh2Y6Dz6c6nLS26Z2//csW1OdyC8SVX8SacygahViehogomyHwav6+hjtTJBmarvYzlue4vRgEVTgzMFSyOQBYOElMXvtLTysGx9i1Zrp+OOO4f8P752wgDGUCwPXddxeXV/sij3eI9+r0ogx5KJ/7mj21S4fTiP2+7YNk63jwqvjsPlocJzem+bx+5+fp84jn8cZjRg/d3djeW4pFO1n4G4cBNmrX5VbrJgkBCizpzdb8QbkQgolcnh2MJJwaDrmPZ9g+o4jKHsMGrZIQyOwxgqiim6/Al8lhjwVIBW+/B2RVH8ky22sjReeMeSpffoNCxVScRbdYdTLQl5q+5qPFXPHXu9yOnBWeLD6fL69ztZFdvx+rWz88wNSY13YSchCUIIgavt+ZU/6D4iV02kov0AnN1vbJyDu50oPhe6uRWKsxDrL+9Uvvk7DmMoO4RalovPGkP+NUtBUYj69O8YXMUA+EzheG1t8Fla4wurbPCI/vAvqGWHccX3xRXfD1d8P7yRnZo0qakGBZtJxRaAkeken06F24fjWCKpVnVWmXA6xzRi1quFJAghhJ/iKcfgKiZy9RS0wl8p+UMtHQW8LgyOPFTHYbz2BHy2NhgPZWHdvAy1LBeD4zBq2WEMrmIc3W7gyCX/wuApI+KbuehaGF5rHF5rHO7YXngiO/sPW3D1S/jMEfissehG6wmnLe98FeZ96zDvXo112zuVoYRFkXf9CnzhbTGUHapMJiE6VkYzKGjmE6deCUoswQ5ACHHm0I1WCoY+T8Q3Gdh/fhmtaAeGniNQ2gxAD4vCuvFVrDn/rfzkX17g3+/IgH/gSE7H4CzAvP9bvNY4PJGdcLX9A15bHO7YFAC89rYc/PO36Kbwk37id8el1BqjI3k0juTRoOuoR3ZgOvgDxsM/47NXjsyP/Ox+TId/xhXXu/IOI6Ef7jbnopvstR5XnEgaqYWUxe9IeVSyblpGROYsFN1L3h9fx53QD+vmNzDv+hKvLQ6frQ1eaxw+WxzumO74bG2CHTIA5p2fY9q/HtPBDRjztqDoXnTFQO7N7+ON7IxWsA2fuVW94m0OfxtBb6T2+XxMnz6dnJwcTCYTs2bNokOHquUm33zzTd544w00TePOO+/k0ksvpaioiCuvvJKkpMqGl8svv5wxY8YEIjwhRB04et1CeafLiWoVgbuisrrD0TMNR8+0IEdWu4qOl1HR8TIAFHcZxkM/YzqchTei8j0oInMW5v3f4gk/y9+G4U7oV1nNJQMyqwlIgli1ahUul4vly5eTlZVFRkYGzz33HAC5ubksWbKEFStWUFFRwahRoxgwYACbN29m+PDh/POf/wxESEKIevBZYyEiBkL0U7NutOFqdyGudhf6nyu+8CFM+7/DdHAD5r2ZWH95F4DcG9/BE9Md44ENoCiV834Fuh3D50Vxl2JwlYDP61+3PezXDzCUF6G4SjC4yyq/u0ooGvQv0MICG9NxApIgNmzYQGpq5QIlffr0ITs72//azz//zLnnnovJZMJkMpGYmMjWrVvJzs5m06ZNjB49mujoaKZMmUJcXA0TuAkhRAN4WvfE07onjt5jKtsxindjOrgBT9TZAIR/vwDz/nXoqhlXXAruo3cZroT+QEzVgbxuFFflm7viKsFrb4tuiUIr/BXT3q8xuEqPe70UV9vzcfS6BbVoBzHv//nom7/Dfzh3VFfybn4fqLzLUcsr10vXDUZ8Jju6KRzF7UQP9QRRWlqK3V7VIKSqKh6PB03TKC0tJTw83P+azWajtLSUzp07k5yczEUXXcS7777LrFmzePrpp2s9j6qqxMTE1LrNyWiaVu99mxspi+qkPKpr9uXRujV07ou/v9RN/4d777cY9qzHuHc9pp9ewv7j87hv+wxV60Tcd3Mx/PwGisdZ7TCeEc/ia3czhj0foX09GwBds4A5HMwRGM9KwRITA2E+6DoY3RyBxxzhfx17nL+cvbd9ivfYvlqYv0G/qVcYD0iCsNvtlJWV+R/7fD40TavxtbKyMsLDw+nduzcWS2Xf3iFDhpwyOQB4vV5ppG4EUhbVSXlU1/LKwwCtL6j8OhcUtwPj4Z9xqW2I8Xgoi+yJsect6OZw/yd7nykcd0QvfPn5KPGDYMw36Eb7iWui5+dXHv+CqTWf2l/OdvACFQ7AUfO29RT0Ruq+ffvyxRdfMGzYMLKysvwNzwC9e/dm/vz5VFRU4HK5+O2330hKSuLBBx/kiiuuYNiwYXzzzTf06tUrEKEJIcRp0Y1WXGdd4H9cfvYIys8eUev21DB+IxQFJEEMGTKEzMxM0tLS0HWd2bNns3jxYhITExk8eDDp6emMGjUKXde57777MJvNTJw4kcmTJ7Ns2TIsFguzZs0KRGhCCCHqSMZBCCmL35HyqE7Ko0pzKIvTqWKSTr9CCCFqJAlCCCFEjSRBCCGEqJEkCCGEEDWSBCGEEKJGkiCEEELUKKS7uQohhAgcuYMQQghRI0kQQgghaiQJQgghRI0kQQghhKiRJAghhBA1kgQhhBCiRpIghBBC1KhFJQifz8fUqVMZOXIk6enp7Nq1K9ghBZXb7WbSpEmMGjWKG2+8kc8++yzYIQVdfn4+gwYN4rfffgt2KEH3/PPPM3LkSK6//nr+85//BDucoHK73UycOJG0tDRGjRrVYv4+WlSCWLVqFS6Xi+XLlzNx4kQyMjKCHVJQvfvuu0RGRrJ06VL+/e9/M3PmzGCHFFRut5upU6cSFtZ0i8KfqdavX8+PP/7IsmXLWLJkCQcPHgx2SEG1evVqPB4Pb7zxBnfddRfz588PdkhNokUliA0bNpCamgpAnz59yM7ODnJEwXXVVVdx7733+h+rqhrEaIJv7ty5pKWlERcXF+xQgu6rr74iKSmJu+66i7/+9a9ccsklwQ4pqDp16oTX68Xn81FaWoqmBWQxzjNOy7jKo0pLS7Hb7f7Hqqri8XhazC/792w2G1BZLn/729/4+9//HuSIguftt98mOjqa1NRUXnjhhWCHE3SFhYXs37+fRYsWsXfvXu68807+97//oShKsEMLCqvVyr59+xg6dCiFhYUsWrQo2CE1iRZ1B2G32ykrK/M/9vl8LTY5HHPgwAH+9Kc/cc011zBixMkXYm/uVqxYwddff016ejpbtmzhwQcfJDc3N9hhBU1kZCQXX3wxJpOJzp07YzabKSgoCHZYQfPyyy9z8cUX8/HHH7Ny5UoeeughKioqgh1WwLWoBNG3b1/WrFkDQFZWFklJSUGOKLjy8vK47bbbmDRpEjfeeGOwwwmq119/nddee40lS5bQo0cP5s6dS2xsbLDDCpp+/fqxdu1adF3n0KFDOAUVMCAAAAKzSURBVJ1OIiMjgx1W0ERERBAeHg5Aq1at8Hg8eL3eIEcVeC3q4/OQIUPIzMwkLS0NXdeZPXt2sEMKqkWLFlFcXMzChQtZuHAhAP/+97+lkVZw6aWX8t1333HjjTei6zpTp05t0W1Uf/7zn5k8eTKjRo3C7XZz3333YbVagx1WwMl030IIIWrUoqqYhBBC1J0kCCGEEDWSBCGEEKJGkiCEEELUSBKEEEKIGrWobq5C1Mf69ev5+9//TteuXf3PRUVF8fTTTzfouA899BDDhg1j4MCBDQ1RiICQBCFEHVxwwQU8+eSTwQ5DiCYlCUKIekpPT6dTp07s2LEDXdd58skniY2NJSMjgw0bNgAwfPhwxowZw86dO5kyZQput5uwsDB/slm+fDkvvvgipaWlTJ8+nd69ewfzkoSoRhKEEHWwbt060tPT/Y8HDRoEVE7fMmPGDF5//XWef/55BgwYwN69e3nzzTfxeDyMGjWKCy64gPnz5zNu3DgGDhzIhx9+yObNmwHo1asX48eP5+233+btt9+WBCHOKJIghKiDmqqYVq9ezQUXXABUJorPP/+c+Ph4+vfvj6IoGI1GzjnnHH777Td27NjBueeeC8CwYcMAeP/99+nVqxcArVu3pry8vAmvSIhTk15MQjTAsTVFfvjhB7p27UqXLl381Utut5sff/yRDh060KVLFzZu3AhULtS0ZMkSgBY7fbYIDXIHIUQd/L6KCaD8/7dzhzYQw0AQRQcm0DUYupF0YJQ2DC1juwBTd+A+wtNLJJNrYMHppFPIfxXsotEs2OfRnFNjDO37rlqrnHO6rksxRq21dByHQghKKSnnrN67tm1Ta033fb+0DfAdnvUBPzrPU6UUee/fHgX4C05MAAATDQIAYKJBAABMBAQAwERAAABMBAQAwERAAABMH613L5diF5jAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e27372ba2746ae87899603daab9895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.cuda.FloatTensor but found type torch.cuda.DoubleTensor for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e00612c59b29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mlist_pred_logP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_adj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mlist_pred_logP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_pred_logP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_logP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-382709aabc48>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_convolution_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layer\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_convolution_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-bfda491aa2ea>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of type torch.cuda.FloatTensor but found type torch.cuda.DoubleTensor for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "model = LogPPredictor(1, 58, 64, 128, 1, 'gsc')\n",
    "model.to(args.device)\n",
    "\n",
    "list_train_loss = list()\n",
    "list_val_loss = list()\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "optimizer = args.optim(model.parameters(),\n",
    "                       lr=args.lr,\n",
    "                       weight_decay=args.l2_coef)\n",
    "\n",
    "data_train = DataLoader(args.dict_partition['train'], \n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "data_val = DataLoader(args.dict_partition['val'],\n",
    "                     batch_size=args.batch_size,\n",
    "                     shuffle=args.shuffle)\n",
    "\n",
    "for epoch in tqdm_notebook(range(args.epoch), desc='Epoch'):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_feature = torch.tensor(batch[0])\n",
    "        list_adj = torch.tensor(batch[1])\n",
    "        list_logP = torch.tensor(batch[2])\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        list_pred_logP.require_grad = False\n",
    "        train_loss = args.criterion(list_pred_logP, list_logP)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    list_train_loss.append(epoch_train_loss/len(data_train))\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_feature = torch.tensor(batch[0])\n",
    "            list_adj = torch.tensor(batch[1])\n",
    "            list_logP = torch.tensor(batch[2])\n",
    "            list_logP = list_logP.view(-1,1)\n",
    "            list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "\n",
    "\n",
    "            list_pred_logP = model(list_feature, list_adj)\n",
    "            val_loss = args.criterion(list_pred_logP, list_logP)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "        \n",
    "    list_val_loss.append(epoch_val_loss/len(data_val))\n",
    "    \n",
    "data_test = DataLoader(args.dict_partition['test'],\n",
    "                       batch_size=args.batch_size,\n",
    "                       shuffle=args.shuffle)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logP_total = list()\n",
    "    pred_logP_total = list()\n",
    "    for i, batch in enumerate(data_val):\n",
    "        list_feature = torch.tensor(batch[0])\n",
    "        list_adj = torch.tensor(batch[1])\n",
    "        list_logP = torch.tensor(batch[2])\n",
    "        logP_total += list_logP.tolist()\n",
    "        list_logP = list_logP.view(-1,1)\n",
    "        list_feature, list_adj, list_logP = list_feature.to(args.device), list_adj.to(args.device), list_logP.to(args.device)\n",
    "\n",
    "        \n",
    "        list_pred_logP = model(list_feature, list_adj)\n",
    "        \n",
    "        pred_logP_total += list_pred_logP.tolist()\n",
    "    \n",
    "    mse = mean_squared_error(logP_total, pred_logP_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((list_train_loss, list_val_loss))\n",
    "data = np.transpose(data)\n",
    "epochs = np.arange(args.epoch)\n",
    "df_loss = pd.DataFrame(data, epochs, [\"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "grid = sns.lineplot(data=df_loss)\n",
    "grid.set_title(\"Loss vs Epoch (tox=nr-ahr)\")\n",
    "grid.set_ylabel(\"Loss\")\n",
    "grid.set_xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(10), desc='1', leave=True, position=1):\n",
    "    for j in tqdm_notebook(range(100), desc='2', leave=False, position=2):\n",
    "        sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
