{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.val_size = 0.1\n",
    "args.test_size = 0.1\n",
    "args.shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a4245c250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ZINC_smiles(file_name, num_mol):\n",
    "    f = open(file_name, 'r')\n",
    "    contents = f.readlines()\n",
    "\n",
    "    smi_list = []\n",
    "    logP_list = []\n",
    "\n",
    "    for i in tqdm_notebook(range(num_mol), desc='Reading Data'):\n",
    "        smi = contents[i].strip()\n",
    "        m = Chem.MolFromSmiles(smi)\n",
    "        smi_list.append(smi)\n",
    "        logP_list.append(MolLogP(m))\n",
    "\n",
    "    logP_list = np.asarray(logP_list).astype(float)\n",
    "\n",
    "    return smi_list, logP_list\n",
    "\n",
    "def smiles_to_onehot(list_smiles):\n",
    "    def smiles_to_vector(smiles, vocab, max_length):\n",
    "        while len(smiles) < max_length:\n",
    "            smiles += \" \"\n",
    "        vector = [vocab.index(str(x)) for x in smiles]\n",
    "        onehot = np.zeros((max_length, len(vocab)), dtype=float)\n",
    "        for i, elm in enumerate(vector):\n",
    "            onehot[i][elm] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    vocab = np.load('./vocab.npy')\n",
    "    onehot_total = list()\n",
    "    length_total = list()\n",
    "    for smiles in tqdm_notebook(list_smiles, desc='Converting Data'):\n",
    "        onehot = smiles_to_vector(smiles, list(vocab), 120)\n",
    "        onehot_total.append(onehot)\n",
    "        length_total.append(len(smiles))\n",
    "    \n",
    "    return np.asarray(onehot_total), np.asarray(length_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, list_smiles, list_length, list_logP):\n",
    "        self.list_smiles = list_smiles\n",
    "        self.list_length = list_length\n",
    "        self.list_logP = list_logP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_smiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.list_smiles[index], self.list_length[index], self.list_logP[index]\n",
    "    \n",
    "\n",
    "def partition(list_onehot, list_length, list_logP, args):\n",
    "    num_total = list_onehot.shape[0]\n",
    "    num_val = int(num_total * args.val_size)\n",
    "    num_test = int(num_total * args.test_size)\n",
    "    num_train = num_total - (num_val + num_test)\n",
    "\n",
    "    onehot_train = list_onehot[:num_train]\n",
    "    length_train = list_length[:num_train]\n",
    "    logP_trian = list_logP[:num_train]\n",
    "\n",
    "    onehot_val = list_onehot[num_train:num_train+num_val]\n",
    "    length_val = list_length[num_train:num_train+num_val]\n",
    "    logP_val = list_logP[num_train:num_train+num_val]\n",
    "\n",
    "    onehot_test = list_onehot[num_total-num_test:]\n",
    "    length_test = list_length[num_total-num_test:]\n",
    "    logP_test = list_logP[num_total-num_test:]\n",
    "\n",
    "    train_set = RNNDataset(onehot_train, length_train, logP_trian)\n",
    "    val_set = RNNDataset(onehot_val, length_val, logP_val)\n",
    "    test_set = RNNDataset(onehot_test, length_test, logP_test)\n",
    "\n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334e89f1685a46e896ab694dc1c802a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading Data', max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58514677f3844312bb65716a3d17ac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting Data', max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_smiles, list_logP = read_ZINC_smiles(\"ZINC.smiles\", 10000)\n",
    "list_onehot, list_length = smiles_to_onehot(list_smiles)\n",
    "dict_partition = partition(list_onehot, list_length, list_logP, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, batch_size, num_layer=1, dropout=0):\n",
    "        super(RNNBlock, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layer = num_layer\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hidden_dim, num_layer, dropout)\n",
    "        self.h_in = nn.Parameter(torch.randn(num_layer, batch_size, hidden_dim))\n",
    "        self.c_in = nn.Parameter(torch.randn(num_layer, batch_size, hidden_dim))\n",
    "\n",
    "    def forward(self, onehot, length):\n",
    "        #batch_size = onehot.shape[0]\n",
    "        \n",
    "        #h_in = nn.Parameter(torch.randn(self.num_layer, batch_size, self.hidden_dim).cuda())\n",
    "        #c_in = nn.Parameter(torch.randn(self.num_layer, batch_size, self.hidden_dim).cuda())\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(onehot, length, batch_first=True)\n",
    "        \n",
    "        output, (h_out, c_out) = self.lstm(packed, (self.h_in, self.c_in))\n",
    "        #unpacked, unpacked_length = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        #vectors = list()\n",
    "        #for i, vector in enumerate(unpacked):\n",
    "        #    vectors.append(unpacked[i, unpacked_length[i]-1, :].view(1, -1))\n",
    "        #out = nn.Parameter(torch.cat(vectors, 0).cuda())\n",
    "        return output, (h_out, c_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, act=None):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        nn.init.xavier_normal_(self.linear.weight)\n",
    "        self.activation = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        if self.activation != None:\n",
    "            out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(RNNNet, self).__init__()\n",
    "\n",
    "        self.rnnBlock = RNNBlock(args.in_dim, args.hidden_dim, args.num_layer, args.dropout)\n",
    "        self.pred1 = Predictor(args.hidden_dim, args.pred_dim1, act=nn.ReLU())\n",
    "        self.pred2 = Predictor(args.pred_dim1, args.pred_dim2, act=nn.ReLU())\n",
    "        self.pred3 = Predictor(args.pred_dim2, args.out_dim)\n",
    "\n",
    "    def forward(self, onehot, length):\n",
    "        out = self.rnnBlock(onehot, length)\n",
    "        out = self.pred1(out)\n",
    "        out = self.pred2(out)\n",
    "        out = self.pred3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train, Validate, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, optimizer, criterion, data_train, bar, args):\n",
    "    for i, batch in enumerate(data_train):\n",
    "        list_onehot = torch.tensor(batch[0]).cuda().float()\n",
    "        list_length = torch.tensor(batch[1]).cuda()\n",
    "        list_logP = torch.tensor(batch[2]).cuda().float()\n",
    "        # Sort onehot tensor with respect to the sequence length.\n",
    "        list_length, list_index = torch.sort(list_length, descending=True)\n",
    "        list_length.cuda()\n",
    "        list_index.cuda()\n",
    "        list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).cuda().float()\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, criterion, data_val, bar, args):\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_val):\n",
    "            list_onehot = torch.tensor(batch[0]).cuda().float()\n",
    "            list_length = torch.tensor(batch[1]).cuda()\n",
    "            list_logP = torch.tensor(batch[2]).cuda().float()\n",
    "\n",
    "            # Sort onehot tensor with respect to the sequence length.\n",
    "            list_length, list_index = torch.sort(list_length, descending=True)\n",
    "            list_length.cuda()\n",
    "            list_index.cuda()\n",
    "            list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).cuda().float()\n",
    "\n",
    "            model.eval()\n",
    "            list_pred_logP = model(list_onehot, list_length).squeeze().cuda()\n",
    "            list_pred_logP.require_grad = False\n",
    "\n",
    "            val_loss = criterion(list_pred_logP, list_logP)\n",
    "            val_mae = mean_absolute_error(list_pred_logP.tolist(), list_logP.tolist())\n",
    "            epoch_val_loss += val_loss.item()\n",
    "            epoch_val_mae += val_mae\n",
    "\n",
    "            bar.update(len(list_onehot))\n",
    "\n",
    "    epoch_val_loss /= len(data_val)\n",
    "    epoch_val_mae /= len(data_val)\n",
    "    \n",
    "    return model, epoch_val_loss, epoch_val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, data_test, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_logP_total = list()\n",
    "        logP_total = list()\n",
    "        for i, batch in enumerate(data_test):\n",
    "            list_onehot = torch.tensor(batch[0]).cuda().float()\n",
    "            list_length = torch.tensor(batch[1]).cuda()\n",
    "            list_logP = torch.tensor(batch[2]).cuda().float()\n",
    "\n",
    "            # Sort onehot tensor with respect to the sequence length.\n",
    "            list_length, list_index = torch.sort(list_length, descending=True)\n",
    "            list_length.cuda()\n",
    "            list_index.cuda()\n",
    "            list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index]).cuda().float()\n",
    "\n",
    "            list_pred_logP = model(list_onehot, list_length).squeeze().cuda()\n",
    "\n",
    "            pred_logP_total += list_pred_logP.tolist()\n",
    "            logP_total += list_logP.tolist()\n",
    "\n",
    "        mae = mean_absolute_error(logP_total, pred_logP_total)\n",
    "        std = np.std(np.array(logP_total) - np.array(pred_logP_total))\n",
    "\n",
    "    return mae, std, logP_total, pred_logP_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dict_partition, device, bar, args):\n",
    "    time_start = time.time()\n",
    "\n",
    "    model = RNNNet(args)\n",
    "    model.cuda()\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, 'Undefined Optimizer Type'\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "    list_train_mae = list()\n",
    "    list_val_mae = list()\n",
    "\n",
    "    data_train = DataLoader(dict_partition['train'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "    data_val = DataLoader(dict_partition['val'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        scheduler.step()\n",
    "        \n",
    "        model, train_loss, train_mae = train(model, device, optimizer, criterion, data_train, bar, args)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_train_mae.append(train_mae)\n",
    "\n",
    "        mode, val_loss, val_mae = validate(model, device, criterion, data_val, bar, args)\n",
    "        list_val_loss.append(val_loss)\n",
    "        list_val_mae.append(val_mae)\n",
    "\n",
    "    data_test = DataLoader(dict_partition['test'], batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    mae, std, logP_total, pred_logP_total = test(model, device, data_test, args)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_required = time_end - time_start\n",
    "\n",
    "    args.list_train_loss = list_train_loss\n",
    "    args.list_val_loss = list_val_loss\n",
    "    args.list_train_mae = list_train_mae\n",
    "    args.list_val_mae = list_val_mae\n",
    "    args.logP_total = logP_total\n",
    "    args.pred_logP_total = pred_logP_total\n",
    "    args.mae = mae\n",
    "    args.std = std\n",
    "    args.time_required = time_required\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(df_result, var1, var2):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    df_mae = df_result.pivot(var1, var2, 'mae')\n",
    "    df_std = df_result.pivot(var1, var2, 'std')\n",
    "    df_mae = df_mae[df_mae.columns].astype(float)\n",
    "    df_std = df_std[df_std.columns].astype(float)\n",
    "    \n",
    "    hm_mae = sns.heatmap(df_mae, ax=ax[0], annot=True, fmt='f', linewidths=.5, cmap='YlGnBu')\n",
    "    hm_std = sns.heatmap(df_std, ax=ax[1], annot=True, fmt='f', linewidths=.5, cmap='YlGnBu')\n",
    "    \n",
    "    fig.suptitle('Performance depends on ' + var1 + ' vs ' + var2)\n",
    "    hm_mae.set_title('MAE depends on ' + var1 + ' vs ' + var2)\n",
    "    hm_std.set_title('Std depends on ' + var1 + ' vs ' + var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_bar(df_result, var1, var2):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    bar_mae = sns.barplot(x=var1, y='mae', hue=var2, data=df_result, ax=ax[0])\n",
    "    bar_std = sns.barplot(x=var1, y='std', hue=var2, data=df_result, ax=ax[1])\n",
    "    \n",
    "    bar_mae.set_title('MAE depends on ' + var1 + ' vs ' + var2)\n",
    "    bar_std.set_title('Std depends on ' + var1 + ' vs ' + var2)\n",
    "    fig.suptitle('Performance depends on ' + var1 + ' vs ' + var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(df_result, var1, var2, ylim):\n",
    "    def plot(x, ylim=1.0, **kwargs):\n",
    "        plt.plot(x[0], **kwargs)\n",
    "        plt.ylim(0.0, ylim)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\n",
    "    g.map(plot, 'list_train_loss', ylim=ylim, label='Train Loss')\n",
    "    g.map(plot, 'list_val_loss', ylim=ylim, color='r', label='Validation Loss')\n",
    "    g.fig.suptitle('Loss vs Epochs depends on ' + var1 + ' vs ' + var2, size=16)\n",
    "    g.fig.subplots_adjust(top=.9)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df_result, var1, var2):\n",
    "    def scatter(x, y, **kwargs):\n",
    "        plt.scatter(x[0], y[0], alpha=0.3, s=2)\n",
    "    def identity(x, y, **kwargs):\n",
    "        plt.plot(x[0], x[0], alpha=0.4, color='black')\n",
    "    \n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\n",
    "    g.map(scatter, 'logP_total', 'pred_logP_total')\n",
    "    g.map(identity, 'logP_total', 'logP_total')\n",
    "    g.fig.suptitle('Truth Distribution depends on ' + var1 + ' vs ' + var2, size=16)\n",
    "    g.fig.subplots_adjust(top=.9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0\n",
    "args.optim = 'Adam'\n",
    "args.epoch = 5\n",
    "args.num_layer = 1\n",
    "args.dropout = 0\n",
    "args.in_dim = 32\n",
    "args.hidden_dim = 64\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.out_dim = 1\n",
    "args.step_size = 10\n",
    "args.gamma = 1\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedbb0277dd542b38715cafc9fb16386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_result = dict()\n",
    "n_iter = args.epoch*(len(dict_partition['train'])+len(dict_partition['val']))\n",
    "bar = tqdm_notebook(total=n_iter, file=sys.stdout, position=0)\n",
    "\n",
    "args.exp_name = \"test\"\n",
    "result = vars(experiment(dict_partition, device, bar, args))\n",
    "dict_result[args.exp_name] = copy.deepcopy(result)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bar.close()\n",
    "\n",
    "df_result = pd.DataFrame(dict_result).transpose()\n",
    "df_result.to_json('test.JSON', orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.0262372623\n",
      "Std: 1.3049317558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f68dbfe8d68>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = pd.read_json('test.JSON', orient='table')\n",
    "\n",
    "print(\"MAE: \" + str(df_result['mae'][0]))\n",
    "print(\"Std: \" + str(df_result['std'][0]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 5)\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "ax[0].plot(df_result['list_train_loss'][0], label='Train Loss')\n",
    "ax[0].plot(df_result['list_val_loss'][0], label='Validation Loss')\n",
    "ax[0].set_ylim([0, 4])\n",
    "ax[0].legend()\n",
    "ax[1].scatter(df_result['logP_total'][0], df_result['pred_logP_total'][0], alpha=0.3, s=2)\n",
    "ax[1].plot(df_result['logP_total'][0], df_result['logP_total'][0], color='black', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test    [1.6838671714, 1.6848644167, 1.688664391600000...\n",
       "Name: list_val_loss, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['list_val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'c', 'C', '(', ')', 'O', '1', '2', 'N', '=', '[', ']', '@', '3', 'H', 'n', '4', 'F', '+', 'S', 'l', 's', '/', 'o', '-', '5', '#', 'B', 'r', '\\\\', '6', 'I']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(np.load('./vocab.npy'))\n",
    "smiles = \"C(=O)Cl\"\n",
    "smiles_onehot = [vocab.index(str(x)) for x in smiles]\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "[22 20 23 26 30 24 33 33 24 29 21 22 22 24 37 30 27 34 37 41 33 30 28 27\n",
      " 32 26 30 28 26 26 28 32 26 25 29 37 21 24 21 26 36 33 30 29 33 23 31 29\n",
      " 34 35 40 25 29 34 26 32 17 25 25 30 17 38 27 26 31 36 37 27 30 27 33 31\n",
      " 27 12 17 30 22 27 24 31 25 37 29 31 32 27 29 27 15 35 11 36 32 28 35 28\n",
      " 29 29 20 31 31 30 31 28 31 26 29 28 27 17 23 16 24 34 30 32 27 28 17 30\n",
      " 25 32 26 26 24 19 25 31 25 24 34 25 30 19 27 30 27 27 24 31 25 22 31 31\n",
      " 31 31 23 37 27 26 25 30 21 24 29 33 38 20 33 24 33 22 26 28 25 28 31 26\n",
      " 23 32 21 34 35 30 19 35 31 30 35 36 29 30 21 33 36 28 28 30 29 26 29 22\n",
      " 21 19 23 36 33 33 27 24 33 26 30 32 31 35 38 25 25 25 22 32 14 27 26 31\n",
      " 36 32 31 33 32 35 28 22 25 26 33 14 30 15 14 22 28 27 32 31 31 27 24 28\n",
      " 26 26 22 16 29 28 28 31 35 34 24 29 29 21 35 36 24 27 23 20 22 16 21 26\n",
      " 24 30 30 35 33 33 27 28 21 25 32 28 26 25 31 27 28 29 19 26 25 37 24 32\n",
      " 23 24 31 31 26 18 25 28 29 29 32 30 22 26 31 30 30 29 35 36 29 26 30 22\n",
      " 25 24 25 28 27 37 28 28 33 34 30 27 23 36 24 27 25 34 18 24 31 29 30 23\n",
      " 26 34 29 30 32 27 22 23 23 24 36 33 30 27 29 30 30 31 31 27 32 35 38 25\n",
      " 29 23 25 31 27 17 22 26 16 30 30 31 36 34 27 25 26 25 26 30 15 22 22 26\n",
      " 28 30 22 27 37 23 28 27 30 25 29 27 29 25 35 29 27 28 28 21 24 31 29 36\n",
      " 19 29 20 19 28 28 27 21 31 20 16 24 33 34 25 27 33 27 27 26 28 34 34 32\n",
      " 31 27 26 25 27 19 31 27 24 30 25 28 22 16 23 31 28 28 31 32 32 29 22 27\n",
      " 30 22 31 30 24 35 25 27 26 29 22 31 28 28 26 29 30 21 31 24 27 35 29 35\n",
      " 39 27 29 27 22 23 22 21 32 23 29 33 26 31 33 46 35 29 33 22 26 30 34 33\n",
      " 35 31 27 35 20 21 16 29 12 31 21 16 31 31 23 29 26 34 31 31 32 24 22 18\n",
      " 35 17 37 26 33 20 26 28 33 24 36 23 22 30 23 24 21 16 24 24 24 30 30 34\n",
      " 31 30 32 31 27 28 33 29 25 28 27 30 31 31 27 32 30 31 29 28 34 37 37 29\n",
      " 31 33 27 27 17 28 30 21 30 35 23 29 26 27 25 21 22 20 31 28 28 32 22 21\n",
      " 39 35 37 27 32 35 31 33 30 23 28 24 26 31 36 23 23 36 31 28 33 25 28 25\n",
      " 22 19 21 24 23 30 27 24 27 29 33 31 31 27 35 25 24 25 34 18 21 22 30 27\n",
      " 26 34 33 35 24 31 26 20 25 25 22 25 27 15 23 15 19 29 31 26 25 29 30 22\n",
      " 30 19 18 21 27 23 24 29 36 25 17 30 31 23 21 26 28 32 32 25 36 35 22 27\n",
      " 23 27 27 27 29 20 24 25 33 28 24 29 31 24 28 23 34 30 28 26 28 29 22 29\n",
      " 19 27 19 30 28 26 24 30 23 31 29 28 31 28 35 22 19 28 31 24 27 30 36 31\n",
      " 24 26 30 31 30 24 35 36 27 29 22 17 19 25 31 27 34 26 34 27 27 35 25 32\n",
      " 25 29 23 23 33 34 27 26 32 23 21 24 24 27 32 34 29 32 33 26 30 35 31 27\n",
      " 31 32 35 40 27 29 28 25 21 26 26 34 41 32 33 26 20 25 17 28 23 22 30 31\n",
      " 23 14 26 29 25 24 32 22 31 37 22 27 28 26 20 28 26 15 23 32 30 22 25 22\n",
      " 31 29 29 32 21 35 33 27 23 31 30 31 20 30 29 29 31 28 31 26 29 26 21 23\n",
      " 28 22 18 30 27 26 26 23 34 28 33 26 29 29 23 31 30 17 27 27 26 22 21 24\n",
      " 29 25 24 31 22 34 33 30 28 24 33 23 28 27 24 28 28 25 24 20 25 30 36 31\n",
      " 34 28 15 27 32 24 14 27 24 31 33 29 29 26 23 30 28 27 33 19 25 23 25 34\n",
      " 29 33 30 26 30 31 15 35 40 25 25 29 29 31 26 20 24 21 30 26 33 34 41 26\n",
      " 32 24 27 31 22 20 27 32 26 31 22 26 26 30 29 22 30 29 33 35 26 30 22 23\n",
      " 23 37 26 31 28 32 30 41 22 23 30 17 28 29 30 25]\n"
     ]
    }
   ],
   "source": [
    "print(list_onehot[1])\n",
    "print(list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22., 20., 23., 26., 30.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " tensor([30., 26., 23., 22., 20.]),\n",
       " tensor([4, 3, 2, 0, 1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_onehot = torch.Tensor(list_onehot[:5])\n",
    "tensor_length = torch.Tensor(list_length[:5])\n",
    "print(tensor_length)\n",
    "tensor_length, tensor_index = torch.sort(tensor_length, descending=True)\n",
    "tensor_onehot, tensor_length, tensor_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor_onehot = tensor_onehot.tolist()\n",
    "tensor_onehot = torch.Tensor([tensor_onehot.tolist()[i] for i in tensor_index])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(2, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.Tensor([[[1, 2], [2, 3], [3, 4], [4, 5]]])\n",
    "lstm(input1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.Tensor([[[1], [2], [3], [4], [5]]])\n",
    "\n",
    "lstm(input2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 128\n",
    "args.in_dim = 32\n",
    "args.hidden_dim = 64\n",
    "args.out_dim = 1\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.num_layer = 2\n",
    "args.dropout = 0\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNNet(args)\n",
    "model.cuda()\n",
    "\n",
    "data_train = DataLoader(dict_partition['train'],\n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=args.shuffle)\n",
    "\n",
    "for i, batch in enumerate(data_train):\n",
    "    if i==0:\n",
    "        list_onehot = torch.tensor(batch[0]).cuda()\n",
    "        list_length = torch.tensor(batch[1]).cuda()\n",
    "        list_logP = torch.tensor(batch[2]).cuda().view(-1, 1).float()\n",
    "        \n",
    "        # Sort onehot tensor with respect to the sequence length.\n",
    "        list_length, list_index = torch.sort(list_length, descending=True)\n",
    "        list_onehot = torch.Tensor([list_onehot.tolist()[i] for i in list_index])\n",
    "\n",
    "        list_pred_logP = model(list_onehot, list_length).to(device)\n",
    "        list_pred_logP.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_logP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0005, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "mse(list_pred_logP, list_logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0005, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_logP = list_pred_logP.squeeze()\n",
    "list_logP = list_logP.squeeze()\n",
    "mse(list_pred_logP, list_logP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3664387083612617"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.array(list_pred_logP.tolist())-np.array(list_logP.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4918543050880544"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.array(list_pred_logP.tolist()), np.array(list_logP.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
